{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"OpenCTI Documentation Space","text":"<p>Welcome to the OpenCTI Documentation space. Here you will be able to find all documents, meeting notes and presentations about the platform.</p> <p>Release notes</p> <p>Please, be sure to also take a look at the OpenCTI releases notes, they may contain important information about releases and deployments.</p>"},{"location":"#introduction","title":"Introduction","text":"<p>OpenCTI is an open source platform allowing organizations to manage their cyber threat intelligence knowledge and observables. It has been created in order to structure, store, organize and visualize technical and non-technical information about cyber threats.</p>"},{"location":"#getting-started","title":"Getting started","text":"<ul> <li> <p> Deployment &amp; Setup</p> <p>Learn how to deploy and configure the platform as well as launch connectors to get the first data in OpenCTI.</p> <p> Deploy now</p> </li> <li> <p> User Guide</p> <p>Understand how to use the platform, explore the knowledge, import and export information, create dashboard, etc.</p> <p> Explore</p> </li> <li> <p> Administration</p> <p>Know how to administrate OpenCTI, create users and groups using RBAC / segregation, put retention policies and custom taxonomies.</p> <p> Customize</p> </li> </ul> <p>Need more help?</p> <p>We are doing our best to keep this documentation complete, accurate and up to date. </p> <p>If you still have questions or you find something which is not sufficiently explained, join the Filigran Community on Slack.</p>"},{"location":"#latest-blog-posts","title":"Latest blog posts","text":"<p>All tutorials are published directly on the Medium blog, this section provides a comprehensive list of the most important ones.</p> <ul> <li> <p>Introducing malware analysis: enhance your cybersecurity triage with OpenCTI <sub><sup>Jul 22, 2023</sup></sub></p> <p>As a cybersecurity analyst, you understand the importance of quickly identifying and analyzing suspicious or malicious files, URLs, and network traffic...</p> <p> Read</p> </li> <li> <p>OpenCTI case management is ready for takeoff: what is available and what\u2019s next <sub><sup>Jul 3, 2023</sup></sub></p> <p>As part of our 2023 strategic roadmap, we\u2019ve worked since January on the case management system within the OpenCTI platform. This initiative comes from 2 simple statements...</p> <p> Read</p> </li> <li> <p>Progressive rollout of the OpenCTI Enterprise Edition: why, what and how? <sub><sup>June 10, 2023</sup></sub></p> <p>We are thrilled to announce that, from OpenCTI 5.8, Filigran is now providing some customers with an Enterprise Edition of the platform, whether on-premise...</p> <p> Read</p> </li> </ul>"},{"location":"#additional-resources","title":"Additional resources","text":"<p>Below, you will find external resources which may be useful along your OpenCTI journey.</p> <p> OpenCTI Ecosystem List of available connectors and integrations to expand platform usage.</p> <p> Training Courses Training courses for analysts and administrators in the Filigran training center.</p> <p> Performances tests &amp; metrics Regular performance tests based on default configuration and datasets.</p> <p></p>"},{"location":"administration/enterprise/","title":"Enterprise edition","text":"<p>Filigran</p> <p>Filigran is providing an Enterprise Edition of the platform, whether on-premise or in the SaaS.</p>"},{"location":"administration/enterprise/#what-is-opencti-ee","title":"What is OpenCTI EE?","text":"<p>OpenCTI Enterprise Edition is based on the open core concept. This means that the source code of OCTI EE remains open source and included in the main GitHub repository of the platform but is published under a specific license. As precised in the GitHub license file:</p> <p>The OpenCTI Community Edition is licensed under the Apache License, Version 2.0 (the \u201cApache License\u201d). The OpenCTI Enterprise Edition is licensed under the OpenCTI Non-Commercial License (the \u201cNon-Commercial License\u201d). The source files in this repository have a header indicating which license they are under. If no such header is provided, this means that the file is belonging to the Community Edition under the Apache License, Version 2.0.</p> <p>We write a complete article to explain the enterprise edition, feel free to read it to have more information</p>"},{"location":"administration/enterprise/#ee-activation","title":"EE Activation","text":"<p>Enterprise edition is easy to activate. You need to go the the platform settings and click on the Activate button.</p> <p></p> <p>Then you will need to agree to the Filigran EULA. </p> <p></p> <p>As a reminder:</p> <ul> <li>OpenCTI EE is free-to-use for development, testing and research purposes as well as for non-profit organizations.</li> <li>OpenCTI EE is included for all Filigran SaaS customers without additional fee.</li> <li>For all other usages, OpenCTI EE is reserved to organizations that have entered in a Filigran Enterprise agreement.</li> </ul>"},{"location":"administration/enterprise/#available-features","title":"Available features","text":""},{"location":"administration/enterprise/#activity-monitoring","title":"Activity monitoring","text":"<p>Audit logs help you answer \"who did what, where, and when?\" within your data with the maximum level of transparency. Please read Activity monitoring page to get all information.</p>"},{"location":"administration/enterprise/#more-to-come","title":"More to come","text":"<p>More feature will be available in OpenCTI in the future. Features like: - Automation scenarios and playbooks engine. - Generative AI for correlation and content generation. - Supervised machine learning for natural language processing.</p>"},{"location":"administration/entities/","title":"Customize entities","text":""},{"location":"administration/entities/#introduction","title":"Introduction","text":"<p>The following chapter aims at giving the reader an understanding of possible options by entity type. Customize entities can be done in \u00ab Settings \u00bb \u2192 \u00ab Customization \u00bb.</p> <p></p>"},{"location":"administration/entities/#hidden-in-interface","title":"Hidden in interface","text":"<p>This configuration hides a specific entity type across the entire platform. It is a powerfull way to simplify the interface and focus on your domain expertise. For example, if you are not interested in disinformation campaign, you can hide related entities like Narratives and Channels from the menus.</p> <p>You can define which Entities to hide platform-wide from \u00ab Settings \u00bb \u2192 \u00ab Customization \u00bb, and also from \u00ab Settings \u00bb \u2192 \u00ab Parameters \u00bb giving you a list of hidden entities.</p> <p>You can also define hidden entities for specific users Roles, from \u00ab Settings \u00bb \u2192 \u00ab Security \u00bb \u2192 \u00ab Roles \u00bb and editing a Role.</p> <p>An overview is available in Parameters &gt; Hidden entity types.</p>"},{"location":"administration/entities/#automatic-references-at-file-upload","title":"Automatic references at file upload","text":"<p>This configuration enables an entity to automatically construct an external reference from the uploaded file.</p>"},{"location":"administration/entities/#enforce-references","title":"Enforce references","text":"<p>This configuration enables the requirement of a reference message on an entity creation or modification. This option is helpfull if you want to keep a strong consistency and traceability of your Knowledge and is well suited for manual creation and update.</p>"},{"location":"administration/entities/#workflow","title":"Workflow","text":"<p>For now, OpenCTI have a simple workflow approach.</p> <p>The available status for an entity is first defined by a collection of status templates (that can be defined from \u00ab Settings \u00bb \u2192 \u00ab Taxonomies \u00bb \u2192 \u00ab Status Template \u00bb).</p> <p>Then, a workflow can be defined by ordering a sequence of status template. </p> <p></p>"},{"location":"administration/entities/#attributes","title":"Attributes","text":"<p>In an Entity, each attribute offers some customization options : - Become mandatory if not already defined as such in the stix standard - Have a default value to facilitate the creation of an entity via the creation forms - Define the different thresholds and corresponding label for scalable attribute</p> <p></p>"},{"location":"administration/introduction/","title":"Introduction","text":"<p>This guide aims to give you a full overview of the OpenCTI features and workflows. The platform can be used in various contexts to handle threats management use cases from a technical to a more strategic level.</p>"},{"location":"administration/introduction/#administrative-settings","title":"Administrative Settings","text":"<p>The OpenCTI Administrative settings console allows administrators to configure many options dynamically within the system. As an Administrator, you can access this settings console, by clicking the settings link. </p> <p>The Settings Console allows for configuration of various aspects of the system.</p>"},{"location":"administration/introduction/#general-configuration","title":"General Configuration","text":"<ul> <li>Platform Title (Default: OpenCTI - Cyber Threat Intelligence Platform)</li> <li>Platform Favicon</li> <li>Platform General Sender email (Default: admin@opencti.io) </li> <li>Platform Default Theme (Default: Dark)</li> <li>Language (Default: Automatic Detection)</li> <li>Hidden Entity Types (Default: None)</li> </ul>"},{"location":"administration/introduction/#authentication-strategies-display","title":"Authentication Strategies Display","text":"<ul> <li>This section will show configured and enabled/disabled strategies. The configuration is done in the config/default.json file or via ENV variables detected at launch.</li> </ul>"},{"location":"administration/introduction/#platform-messages","title":"Platform Messages","text":"<ul> <li>Platform Login Message (optional) - if configured this will be displayed on the login page. This is usually used to have a welcome type message for users before login.</li> <li>Platform Consent Message (optional) - if configured this will be displayed on the login page. This is usually used to display some type of consent message for users to agree to before login. If enabled, a user must check the checkbox displayed to allow login.</li> <li>Platform Consent Confirm Text (optional) - This is displayed next to the platform consent checkbox, if Platform Consent Message is configured. Users must agree to the checkbox before the login prompt will be displayed. This message can be configured, but by default reads: I have read and comply with the above statement</li> </ul>"},{"location":"administration/introduction/#dark-theme-color-scheme","title":"Dark Theme Color Scheme","text":"<p>Various aspects of the Dark Theme can be dynamically configured in this section.</p>"},{"location":"administration/introduction/#light-theme-color-scheme","title":"Light Theme Color Scheme","text":"<p>Various aspects of the Light Theme can be dynamically configured in this section.</p>"},{"location":"administration/introduction/#tools-configuration-display","title":"Tools Configuration Display","text":"<p>This section will give general status on the various tools and enabled components of the currently configured OpenCTI deployment.</p>"},{"location":"administration/merging/","title":"Merging and de-duplication","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"administration/ontologies/","title":"Custom taxonomies","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"administration/parameters/","title":"Parameters","text":""},{"location":"administration/parameters/#description","title":"Description","text":"<p>This part of the interface wil let you configure global platform settings, like title, favicon, etc.</p> <p>It will also give you important information about the platform.</p>"},{"location":"administration/parameters/#configuration","title":"Configuration","text":"<p>Configure global platform settings, like title, favicon, etc.</p>"},{"location":"administration/parameters/#opencti-platform","title":"OpenCTI Platform","text":"<p>Important information about the platform.</p> <p>It's also the place to activate the Enterprise edition</p>"},{"location":"administration/parameters/#platform-announcement","title":"Platform Announcement","text":"<p>This section gives you the possibility to set and display Announcements in the platform. Those announcements will be visible to every user in the platform, on top of the interface.</p> <p>They can be used to inform all your users' community of important information, like a scheduled downtime, an incoming upgrade, or even an important tips regarding the usage of the platform.</p> <p></p> <p>An Announcement can be accompanied by a \"Dismiss\u201d button. When click by a user, it makes the message disappear for this user.</p> <p></p> <p>This option can be deactivated to have a permanent Announcement.</p> <p></p> <p>\u26a0\ufe0f Only one Announcement is displayed at a time. Dismissible Announcement are displayed first, then the latest not dismissible Announcement.</p>"},{"location":"administration/policies/","title":"Policies","text":""},{"location":"administration/policies/#platform-main-organization","title":"Platform main organization","text":"<p>Allow to set a main organization for the entire platform.</p> <p>All the pieces of knowledge must be shared with the organization of the user wishing to access it or this user need to be inside the main organization.</p>"},{"location":"administration/policies/#authentication-strategies","title":"Authentication Strategies","text":"<p>There are several authentication strategies to connect to the platform.</p> <p>Please see the Authentication section for further details.</p>"},{"location":"administration/policies/#local-password-policies","title":"Local Password Policies","text":"<p>Allow to define the password policy according to several criteria in order to strengthen the security of your platform, namely: minimum/maximum number of characters, number of digits, etc.</p>"},{"location":"administration/policies/#login-messages","title":"Login Messages","text":"<p>Allow to define login, consent and consent confirm message to customize and highlight your platform's security policy</p>"},{"location":"administration/policies/#platform-banner-configuration","title":"Platform Banner Configuration","text":"<p>Allow OpenCTI deployments to have a custom banner message (top and bottom) and colored background for the message (Green, Red, or Yellow). Can be used to add a disclaimer or system purpose that will be displayed at the top and bottom of the OpenCTI instances pages.</p> <p>This configuration has two parameters:</p> <ul> <li>Platform Banner Level - (Default: OFF) Options available for the banner background are Green, Red, and Yellow.</li> <li>Platform Banner Text - (Default: Blank) If you turn on the banners, you should add a message to this area to be   displayed within the banner.</li> </ul> <p></p>"},{"location":"administration/reasoning/","title":"Reasoning engine","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"administration/retentions/","title":"Indicators lifecycle","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"administration/segregation/","title":"Data segregation","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"administration/sourcing/","title":"Sourcing knowledge","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"administration/users/","title":"Users and Role Based Access Control","text":""},{"location":"administration/users/#introduction","title":"Introduction","text":"<p>In OpenCTI, the RBAC system not only related to what users can do or cannot do in the platform (aka. <code>Capabilities</code>) but also to the system of data segregation. Also, platform behaviour such as default home dashboards, default triggers and digests as well as default hidden menus or entities can be defined across groups and organizations.</p>"},{"location":"administration/users/#high-level-design","title":"High level design","text":""},{"location":"administration/users/#roles","title":"Roles","text":"<p>Roles are used in the platform to grant the given groups with some capabilities to define what users in those groupes can do or cannot do.</p>"},{"location":"administration/users/#list-of-capabilities","title":"List of capabilities","text":"Capability Description <code>Bypass all capabilities</code> Just bypass everything including data segregation and enforcements. <code>Access knowledge</code> Access in read-only to all the knowledge in the platform. <code>Access to collaborative creation</code> Create notes and opinions (and modify its own) on entities and relations. <code>Create / Update knowledge</code> Create and update existing entities and relationships. <code>Restrict organization access</code> Share entities and relationships with other organizations. <code>Delete knowledge</code> Delete entities and relationships. <code>Upload knowledge files</code> Upload files in the <code>Data</code> and <code>Content</code> section of entities. <code>Download knowledge export</code> Download the exports generated in the entities (in the <code>Data</code> section). <code>Ask for knowledge enrichment</code> Trigger an enrichment for a given entity. <code>Access exploration</code> Access to workspaces whether custom dashboards or investigations. <code>Create / Update exploration</code> Create and update existing workspaces whether custom dashboards or investigations. <code>Delete exploration</code> Delete workspaces whether custom dashboards or investigations. <code>Access connectors</code> Read information in the <code>Data &gt; Connectors</code> section. <code>Manage connector state</code> Reset the connector state to restart ingestion from the beginning. <code>Access Taxii feed</code> Access and consume TAXII collections. <code>Manage Taxii collections</code> Create, update and delete TAXII collections. <code>Access administration</code> Access and manage overall parameters of the platform in <code>Settings &gt; Parameters</code>. <code>Manage credentials</code> Access and manage roles, groups, users, organizations and security policies. <code>Manage marking definitions</code> Update and delete marking definitions. <code>Manage labels &amp; Attributes</code> Update and delete labels, custom taxonomies, workflow and case templates. <code>Connectors API usage: register, ping, export push ...</code> Connectors specific permissions for register, ping, push export files, etc. <code>Connect and consume the platform streams (/stream, /stream/live)</code> List and consume the OpenCTI live streams. <code>Bypass mandatory references if any</code> If external references enforced in a type of entity, be able to bypass the enforcement."},{"location":"administration/users/#manage-roles","title":"Manage roles","text":"<p>You can manage the roles in <code>Settings &gt; Security &gt; Roles</code>.</p> <p>To create a role, just click on the <code>+</code> button:</p> <p></p> <p>Then you will be able to define the capabilities of the role:</p> <p></p>"},{"location":"administration/users/#users","title":"Users","text":"<p>You can manage the users in <code>Settings &gt; Security &gt; Users</code>. If you are using Single-Sign-On (SSO), the users in OpenCTI are automatically created upon login.</p> <p>To create a user, just click on the <code>+</code> button:</p> <p></p>"},{"location":"administration/users/#manage-a-user","title":"Manage a user","text":"<p>When access to a user, it is possible to:</p> <ul> <li>Visualize information including the token</li> <li>Modify it, reset 2FA if necessary</li> <li>Manage its sessions</li> <li>Manage its triggers and digests</li> <li>Visualize the history and operations</li> </ul> <p></p>"},{"location":"administration/users/#groups","title":"Groups","text":"<p>Groups is the main vehicule to manage permissions and data segregation as well as platform customization for the given users part of this group. You can manage the groups in <code>Settings &gt; Security &gt; Groups</code>.</p> <p>Here is the description of the group available parameters.</p> Parameter Description <code>Auto new markings</code> If a new marking definition is created, this group will automatically be granted to it. <code>Default membership</code> If a new user is created (manually or upon SSO), it will be added to this group. <code>Roles</code> Roles and capabilities granted to the users belonging to this group. <code>Default dashboard</code> Customize the home dashboard for the users belonging to this group. <code>Default markings</code> In <code>Settings &gt; Customization &gt; Entity types</code>, if default marking definitions is enabled, default markings of the group is used. <code>Allowed markings</code> Grant access to the group to the defined marking definitions, more details in data segregation. <code>Triggers and digests</code> Define defaults triggers and digests for the users belonging to this group. <p></p>"},{"location":"administration/users/#manage-a-group","title":"Manage a group","text":"<p>When managing a group, you can define the members and all above configurations.</p> <p></p>"},{"location":"administration/users/#organizations","title":"Organizations","text":"<p>Users can belong to organizations, which is an additional layer of data segregation and customization.</p>"},{"location":"administration/audit/configuration/","title":"Configuration","text":"<p>Enterprise edition</p> <p>Activity unified interface and logging are available under the \"Filigran entreprise edition\" license.</p> <p>Please read the dedicated page to have all information</p> <p>As explained in overview page, all administration actions are listen by default.  However, all knowledge are not listened by default due to performance impact on the platform. </p> <p>For this reason you need to explicitly activate extended listening on user / group or organization.</p> <p></p> <p>Listening will start just after the configuration. Every past events will not be taken into account.</p>"},{"location":"administration/audit/events/","title":"Events","text":"<p>Enterprise edition</p> <p>Activity unified interface and logging are available under the \"Filigran entreprise edition\" license.</p> <p>Please read the dedicated page to have all information</p>"},{"location":"administration/audit/events/#description","title":"Description","text":"<p>OpenCTI activity capability is the way to unified whats really happen in the platform. In events section you will have access to the UI that will answer to \"who did what, where, and when?\" within your data with the maximum level of transparency. </p> <p></p>"},{"location":"administration/audit/events/#include-knowledge","title":"Include knowledge","text":"<p>By default, the events screen only show you the administration actions done by the users.</p> <p>If you want to see also the information about the knowledge, you can simply activate the filter in the bar to get the complete overview of all user actions.</p> <p>Don't hesitate to read again the overview page to have a better understanding of the difference between Audit, Basic/Extended knowledge.</p>"},{"location":"administration/audit/overview/","title":"Overview","text":""},{"location":"administration/audit/overview/#overview","title":"Overview","text":"<p>Enterprise edition</p> <p>Activity unified interface and logging are available under the \"Filigran entreprise edition\" license.</p> <p>Please read the dedicated page to have all information</p> <p>OpenCTI activity capability is the way to unified whats really happen in the platform. With this feature you will be able to answer \"who did what, where, and when?\" within your data with the maximum level of transparency.  Enabling activity helps your security, auditing, and compliance entities monitor platform for possible vulnerabilities or external data misuse.</p>"},{"location":"administration/audit/overview/#categories","title":"Categories","text":"<p>The activity group 3 different concepts that need to be explains.</p>"},{"location":"administration/audit/overview/#basic-knowledge","title":"Basic knowledge","text":"<p>The basic knowledge refers to all stix data knowledge inside OpenCTI. Every create/update/delete actions on that knowledge is accessible through the history. That basic activity is handled by the history manager and can be also found directly on each entity.</p>"},{"location":"administration/audit/overview/#extended-knowledge","title":"Extended knowledge","text":"<p>The extended knowledge refers to extra information data to track specific user activity. As this kind of tracking is expensive, the tracking will only be done for specific user/group/organization explicitly configured.</p>"},{"location":"administration/audit/overview/#audit-knowledge","title":"Audit knowledge","text":"<p>Audit is focusing on user administration or security actions. Audit will produces console/logs files along with user interface elements.</p> <pre><code>{\n\"auth\": \"&lt;User information&gt;\",\n\"category\": \"AUDIT\",\n\"level\": \"&lt;info | error&gt;\",\n\"message\": \"&lt;human readable explanation&gt;\",\n\"resource\": {\n\"type\": \"&lt;authentication | mutation&gt;\",\n\"event_scope\": \"&lt;depends on type&gt;\",\n\"event_access\": \"&lt;administration&gt;\",\n\"data\": \"&lt;contextual data linked to the event type&gt;\",\n\"version\": \"&lt;version of audit log format&gt;\"\n},\n\"timestamp\": \"&lt;event date&gt;\",\n\"version\": \"&lt;platform version&gt;\"\n}\n</code></pre>"},{"location":"administration/audit/overview/#architecture","title":"Architecture","text":"<p>OpenCTI use different mechanisms to be able to publish actions (audit) or data modification (history)</p>"},{"location":"administration/audit/overview/#audit-knowledge_1","title":"Audit knowledge","text":"<p>Administration or security actions</p> <p>With Enterprise edition activated, Administration and security actions are always written; you can't configure, exclude, or disable them</p> <p> Supported</p> <p> Not supported for now</p> <p> Not applicable</p>"},{"location":"administration/audit/overview/#ingestion","title":"Ingestion","text":"Create Delete Edit Remote OCTI Streams"},{"location":"administration/audit/overview/#data-sharing","title":"Data sharing","text":"Create Delete Edit CSV Feeds TAXII Feeds Stream Feeds"},{"location":"administration/audit/overview/#connectors","title":"Connectors","text":"Create Delete Edit Connectors  State reset Works"},{"location":"administration/audit/overview/#parameters","title":"Parameters","text":"Create Delete Edit Platform parameters"},{"location":"administration/audit/overview/#security","title":"Security","text":"Create Delete Edit Roles Groups Users Sessions Policies"},{"location":"administration/audit/overview/#customization","title":"Customization","text":"Create Delete Edit Entity types Rules engine Retention policies"},{"location":"administration/audit/overview/#taxonomies","title":"Taxonomies","text":"Create Delete Edit Status templates Case templates + tasks"},{"location":"administration/audit/overview/#accesses","title":"Accesses","text":"Listen Login (success or fail) Logout Unauthorized access"},{"location":"administration/audit/overview/#extended-knowledge_1","title":"Extended knowledge","text":"<p>Extended knowledge</p> <p>Extented knowledge activity are written only if you activate the feature for a subset of users / groups or organizations</p>"},{"location":"administration/audit/overview/#data-management","title":"Data management","text":"<p>Some history actions are already included in the \"basic knowledge\". (basic marker) </p> Read Create Delete Edit Platform knowledge basic basic basic Background tasks Knowledge Knowledge files basic basic Global data import files Analyst workbenches files Triggers Workspaces Investigations User profile"},{"location":"administration/audit/overview/#user-actions","title":"User actions","text":"Supported Ask for file import Ask for data enrichment Ask for export generation Execute global search"},{"location":"administration/audit/triggers/","title":"Activity triggers","text":"<p>Enterprise edition</p> <p>Activity unified interface and logging are available under the \"Filigran entreprise edition\" license.</p> <p>Please read the dedicated page to have all information</p>"},{"location":"administration/audit/triggers/#description","title":"Description","text":"<p>Having all the history in the user interface (events) its sometimes not enough to have a proactive monitoring. For this reason you can configure some specific triggers to receive notifications on audit events. You can configure like personal triggers, lives one that will be sent directly or digest depending on your needs. </p>"},{"location":"administration/audit/triggers/#configuration","title":"Configuration","text":"<p>In this kind of trigger you will have to configure different options: - Notification target: User interface or email - Recipients: who will receive the notification - Filters: a set of filters to get only events that really interested you. (who is responsible for this event, kind of events, ...)</p>"},{"location":"administration/audit/triggers/#event-structure","title":"Event structure","text":"<p>In order to correctly configure the filters, here's a definition of the event structure</p> <ul> <li>Event type: <code>authentication</code></li> <li> <p>Event scopes: <code>login</code> and <code>logout</code> </p> </li> <li> <p>Event type: <code>read</code></p> <ul> <li>Event scopes: <code>read</code> and <code>unauthorized</code> </li> </ul> </li> <li> <p>Event type: <code>file</code></p> <ul> <li>Event scopes: <code>read</code>, <code>create</code> and <code>delete</code></li> </ul> </li> <li> <p>Event type: <code>mutation</code></p> <ul> <li>Event scopes: <code>unauthorized</code>, <code>update</code>, <code>create</code> and <code>delete</code></li> </ul> </li> <li> <p>Event type: <code>command</code></p> <ul> <li>Event scopes: <code>search</code>, <code>enrich</code>, <code>import</code> and <code>export</code></li> </ul> </li> </ul>"},{"location":"deployment/authentication/","title":"Authentication","text":""},{"location":"deployment/authentication/#introduction","title":"Introduction","text":"<p>OpenCTI supports several authentication providers. If you configure multiple strategies, they will be tested in the order you declared them.</p> <p>Activation</p> <p>You need to configure/activate only that you really want to propose to your users in term of authentication</p> <p>The product proposes two kind of authentication strategy:</p> <ul> <li>Form (asking user for a user/password)</li> <li>Buttons (click with authentication on an external system)</li> </ul>"},{"location":"deployment/authentication/#supported-strategies","title":"Supported Strategies","text":"<p>Under the hood we technically use the strategies provided by PassportJS. We integrate a subset of the strategies available with passport we if you need more we can theatrically integrate all the passport strategies.</p>"},{"location":"deployment/authentication/#local-users-form","title":"Local users (form)","text":"<p>This strategy used the OpenCTI database as user management.</p> <p>OpenCTI use this strategy as the default but its not the one we recommend for security reason.</p> <pre><code>\"local\": {\n\"strategy\": \"LocalStrategy\",\n\"config\": {\n\"disabled\": false\n}\n}\n</code></pre> <p>Production deployment</p> <p>Please use the LDAP/Auth0/OpenID/SAML strategy for production deployment.</p>"},{"location":"deployment/authentication/#ldap-form","title":"LDAP (form)","text":"<p>This strategy can be used to authenticate your user with your company LDAP and is based on Passport - LDAPAuth.</p> <pre><code>\"ldap\": {\n\"strategy\": \"LdapStrategy\",\n\"config\": {\n\"url\": \"ldaps://mydc.domain.com:686\",\n\"bind_dn\": \"cn=Administrator,cn=Users,dc=mydomain,dc=com\",\n\"bind_credentials\": \"MY_STRONG_PASSWORD\",\n\"search_base\": \"cn=Users,dc=mydomain,dc=com\",\n\"search_filter\": \"(cn={{username}})\",\n\"mail_attribute\": \"mail\",\n// \"account_attribute\": \"givenName\",\n// \"firstname_attribute\": \"cn\",\n// \"lastname_attribute\": \"cn\",\n\"account_attrgroup_search_filteribute\": \"givenName\",\n\"allow_self_signed\": true\n}\n}\n</code></pre> <p>If you would like to use LDAP groups to automatically associate LDAP groups and OpenCTI groups/organizations:</p> <pre><code>\"ldap\": {\n\"config\": {\n...\n\"group_search_base\": \"cn=Groups,dc=mydomain,dc=com\",\n\"group_search_filter\": \"(member={{dn}})\",\n\"groups_management\": { // To map LDAP Groups to OpenCTI Groups\n\"group_attribute\": \"cn\",\n\"groups_mapping\": [\"LDAP_Group_1:OpenCTI_Group_1\", \"LDAP_Group_2:OpenCTI_Group_2\", ...]\n},\n\"organizations_management\": { // To map LDAP Groups to OpenCTI Organizations\n\"organizations_path\": \"cn\",\n\"organizations_mapping\": [\"LDAP_Group_1:OpenCTI_Organization_1\", \"LDAP_Group_2:OpenCTI_Organization_2\", ...]\n}\n}\n}\n</code></pre>"},{"location":"deployment/authentication/#saml-button","title":"SAML (button)","text":"<p>This strategy can be used to authenticate your user with your company SAML and is based on Passport - SAML.</p> <pre><code>\"saml\": {\n\"identifier\": \"saml\",\n\"strategy\": \"SamlStrategy\",\n\"config\": {\n\"issuer\": \"mytestsaml\",\n// \"account_attribute\": \"nameID\",\n// \"firstname_attribute\": \"nameID\",\n// \"lastname_attribute\": \"nameID\",\n\"entry_point\": \"https://auth.mydomain.com/auth/realms/mydomain/protocol/saml\",\n\"saml_callback_url\": \"http://localhost:4000/auth/saml/callback\",\n// \"private_key\": \"MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwg...\",\n\"cert\": \"MIICmzCCAYMCBgF2Qt3X1zANBgkqhkiG9w0BAQsFADARMQ8w...\"\n}\n}\n</code></pre> <p>For the SAML strategy to work:</p> <ul> <li>The <code>cert</code> parameter is mandatory (PEM format) because it is used to validate the SAML response.</li> <li>The <code>private_key</code> (PEM format) is optional and is only required if you want to sign the SAML client request.</li> </ul> <p>Certificates</p> <p>Be careful to put the <code>cert</code> / <code>private_key</code>  key in PEM format. Indeed, a lot of systems generally export the the keys in X509 / PCKS12 formats and so you will need to convert them.  Here is an example to extract PEM from PCKS12: <pre><code>openssl pkcs12 -in keystore.p12 -out newfile.pem -nodes\n</code></pre></p> <p>Here is an example of SAML configuration using environment variables:</p> <pre><code>- PROVIDERS__SAML__STRATEGY=SamlStrategy - \"PROVIDERS__SAML__CONFIG__LABEL=Login with SAML\"\n- PROVIDERS__SAML__CONFIG__ISSUER=mydomain\n- PROVIDERS__SAML__CONFIG__ENTRY_POINT=https://auth.mydomain.com/auth/realms/mydomain/protocol/saml\n- PROVIDERS__SAML__CONFIG__SAML_CALLBACK_URL=http://opencti.mydomain.com/auth/saml/callback\n- PROVIDERS__SAML__CONFIG__CERT=MIICmzCCAYMCBgF3Rt3X1zANBgkqhkiG9w0BAQsFADARMQ8w\n</code></pre> <p>OpenCTI support mapping SAML Roles/Groups on OpenCTI Groups. Here is an example:</p> <pre><code>\"saml\": {\n\"config\": {\n...,\n// Groups mapping\n\"groups_management\": { // To map SAML Groups to OpenCTI Groups\n\"group_attributes\": [\"Group\"],\n\"groups_mapping\": [\"SAML_Group_1:OpenCTI_Group_1\", \"SAML_Group_2:OpenCTI_Group_2\", ...]\n},\n\"groups_management\": { // To map SAML Roles to OpenCTI Groups\n\"group_attributes\": [\"Role\"],\n\"groups_mapping\": [\"SAML_Role_1:OpenCTI_Group_1\", \"SAML_Role_2:OpenCTI_Group_2\", ...]\n},\n// Organizations mapping\n\"organizations_management\": { // To map SAML Groups to OpenCTI Organizations\n\"organizations_path\": [\"Group\"],\n\"organizations_mapping\": [\"SAML_Group_1:OpenCTI_Organization_1\", \"SAML_Group_2:OpenCTI_Organization_2\", ...]\n},\n\"organizations_management\": { // To map SAML Roles to OpenCTI Organizations\n\"organizations_path\": [\"Role\"],\n\"organizations_mapping\": [\"SAML_Role_1:OpenCTI_Organization_1\", \"SAML_Role_2:OpenCTI_Organization_2\", ...]\n}\n}\n}\n</code></pre> <p>Here is an example of SAML Groups mapping configuration using environment variables:</p> <pre><code>- \"PROVIDERS__SAML__CONFIG__GROUPS_MANAGEMENT__GROUP_ATTRIBUTES=[\\\"Group\\\"]\"\n- \"PROVIDERS__SAML__CONFIG__GROUPS_MANAGEMENT__GROUPS_MAPPING=[\\\"SAML_Group_1:OpenCTI_Group_1\\\", \\\"SAML_Group_2:OpenCTI_Group_2\\\", ...]\"\n</code></pre>"},{"location":"deployment/authentication/#auth0-button","title":"Auth0 (button)","text":"<p>This strategy allows to use Auth0 Service to handle the authentication and is based on Passport - Auth0.</p> <pre><code>\"authzero\": {\n\"identifier\": \"auth0\",\n\"strategy\": \"Auth0Strategy\",\n\"config\": {\n\"clientID\": \"XXXXXXXXXXXXXXXXXX\",\n\"baseURL\": \"https://opencti.mydomain.com\",\n\"clientSecret\": \"XXXXXXXXXXXXXXXXXX\",\n\"callback_url\": \"https://opencti.mydomain.com/auth/auth0/callback\",\n\"domain\": \"mycompany.eu.auth0.com\",\n\"audience\": \"XXXXXXXXXXXXXXX\",\n\"scope\": \"openid email profile XXXXXXXXXXXXXXX\"\n}\n}\n</code></pre> <p>Here is an example of Auth0 configuration using environment variables:</p> <pre><code>- PROVIDERS__AUTHZERO__STRATEGY=Auth0Strategy\n- PROVIDERS__AUTHZERO__CONFIG__CLIENT_ID=${AUTH0_CLIENT_ID}\n- PROVIDERS__AUTHZERO__CONFIG__BASEURL=${AUTH0_BASE_URL}\n- PROVIDERS__AUTHZERO__CONFIG__CLIENT_SECRET=${AUTH0_CLIENT_SECRET}\n- PROVIDERS__AUTHZERO__CONFIG__CALLBACK_URL=${AUTH0_CALLBACK_URL}\n- PROVIDERS__AUTHZERO__CONFIG__DOMAIN=${AUTH0_DOMAIN}\n- PROVIDERS__AUTHZERO__CONFIG__SCOPE=\"openid email profile\"\n</code></pre>"},{"location":"deployment/authentication/#openid-connect-button","title":"OpenID Connect (button)","text":"<p>This strategy allows to use the OpenID Connect Protocol to handle the authentication and is based on Node OpenID Client that is more powerful than the passport one.</p> <pre><code>\"oic\": {\n\"identifier\": \"oic\",\n\"strategy\": \"OpenIDConnectStrategy\",\n\"config\": {\n\"label\": \"Login with OpenID\",\n\"issuer\": \"https://auth.mydomain.com/auth/realms/mydomain\",\n\"client_id\": \"XXXXXXXXXXXXXXXXXX\",\n\"client_secret\": \"XXXXXXXXXXXXXXXXXX\",\n\"redirect_uris\": [\"https://opencti.mydomain.com/auth/oic/callback\"]\n}\n}\n</code></pre> <p>Here is an example of OpenID configuration using environment variables:</p> <pre><code>- PROVIDERS__OPENID__STRATEGY=OpenIDConnectStrategy - \"PROVIDERS__OPENID__CONFIG__LABEL=Login with OpenID\"\n- PROVIDERS__OPENID__CONFIG__ISSUER=https://auth.mydomain.com/auth/realms/xxxx\n- PROVIDERS__OPENID__CONFIG__CLIENT_ID=XXXXXXXXXXXXXXXXXX\n- PROVIDERS__OPENID__CONFIG__CLIENT_SECRET=XXXXXXXXXXXXXXXXXX\n- \"PROVIDERS__OPENID__CONFIG__REDIRECT_URIS=[\\\"https://opencti.mydomain.com/auth/oic/callback\\\"]\"\n</code></pre> <p>OpenCTI support mapping OpenID Roles/Groups on OpenCTI Groups (everything is tied to a group in the platform). Here is an example:</p> <pre><code>\"oic\": {\n\"config\": {\n...,\n// Groups mapping\n\"groups_management\": { // To map OpenID Groups to OpenCTI Groups\n\"groups_scope\": \"groups\",\n\"groups_path\": [\"groups\", \"realm_access.groups\", \"resource_access.account.groups\"],\n\"groups_mapping\": [\"OpenID_Group_1:OpenCTI_Group_1\", \"OpenID_Group_2:OpenCTI_Group_2\", ...]\n},\n\"groups_management\": { // To map OpenID Roles to OpenCTI Groups\n\"groups_scope\": \"roles\",\n\"groups_path\": [\"roles\", \"realm_access.roles\", \"resource_access.account.roles\"],\n\"groups_mapping\": [\"OpenID_Role_1:OpenCTI_Group_1\", \"OpenID_Role_2:OpenCTI_Group_2\", ...]\n},\n// Organizations mapping  \n\"organizations_management\": { // To map OpenID Groups to OpenCTI Organizations\n\"organizations_scope\": \"groups\",\n\"organizations_path\": [\"groups\", \"realm_access.groups\", \"resource_access.account.groups\"],\n\"organizations_mapping\": [\"OpenID_Group_1:OpenCTI_Group_1\", \"OpenID_Group_2:OpenCTI_Group_2\", ...]\n},\n\"organizations_management\": { // To map OpenID Roles to OpenCTI Organizations\n\"organizations_scope\": \"roles\",\n\"organizations_path\": [\"roles\", \"realm_access.roles\", \"resource_access.account.roles\"],\n\"organizations_mapping\": [\"OpenID_Role_1:OpenCTI_Group_1\", \"OpenID_Role_2:OpenCTI_Group_2\", ...]\n},\n}\n}\n</code></pre> <p>Here is an example of OpenID Groups mapping configuration using environment variables:</p> <pre><code>- \"PROVIDERS__OPENID__CONFIG__GROUPS_MANAGEMENT__GROUPS_SCOPE=groups\"\n- \"PROVIDERS__OPENID__CONFIG__GROUPS_MANAGEMENT__GROUPS_PATH=[\\\"groups\\\", \\\"realm_access.groups\\\", \\\"resource_access.account.groups\\\"]\"\n- \"PROVIDERS__OPENID__CONFIG__GROUPS_MANAGEMENT__GROUPS_MAPPING=[\\\"OpenID_Group_1:OpenCTI_Group_1\\\", \\\"OpenID_Group_2:OpenCTI_Group_2\\\", ...]\"\n</code></pre>"},{"location":"deployment/authentication/#facebook-button","title":"Facebook (button)","text":"<p>This strategy can authenticate your users with Facebook and is based on Passport - Facebook</p> <pre><code>\"facebook\": {\n\"identifier\": \"facebook\",\n\"strategy\": \"FacebookStrategy\",\n\"config\": {\n\"client_id\": \"XXXXXXXXXXXXXXXXXX\",\n\"client_secret\": \"XXXXXXXXXXXXXXXXXX\",\n\"callback_url\": \"https://opencti.mydomain.com/auth/facebook/callback\"\n}\n}\n</code></pre>"},{"location":"deployment/authentication/#google-button","title":"Google (button)","text":"<p>This strategy can authenticate your users with Google and is based on Passport - Google</p> <pre><code>\"google\": {\n\"identifier\": \"google\",\n\"strategy\": \"GoogleStrategy\",\n\"config\": {\n\"client_id\": \"XXXXXXXXXXXXXXXXXX\",\n\"client_secret\": \"XXXXXXXXXXXXXXXXXX\",\n\"callback_url\": \"https://opencti.mydomain.com/auth/google/callback\"\n}\n}\n</code></pre>"},{"location":"deployment/authentication/#github-button","title":"GitHub (button)","text":"<p>This strategy can authenticate your users with GitHub and is based on Passport - GitHub</p> <pre><code>\"github\": {\n\"identifier\": \"github\",\n\"strategy\": \"GithubStrategy\",\n\"config\": {\n\"client_id\": \"XXXXXXXXXXXXXXXXXX\",\n\"client_secret\": \"XXXXXXXXXXXXXXXXXX\",\n\"callback_url\": \"https://opencti.mydomain.com/auth/github/callback\"\n}\n}\n</code></pre>"},{"location":"deployment/authentication/#client-certificate-button","title":"Client certificate (button)","text":"<p>This strategy can authenticate a user based on SSL client certificates. For this you need to configure your OCTI to start in HTTPS, for example:</p> <pre><code>\"port\": 443,\n\"https_cert\": {\n\"key\": \"/cert/server_key.pem\",\n\"crt\": \"/cert/server_cert.pem\",\n\"reject_unauthorized\":true\n}\n</code></pre> <p>And then add the <code>ClientCertStrategy</code>:</p> <pre><code>\"cert\": {\n\"strategy\":\"ClientCertStrategy\",\n\"config\": {\n\"label\":\"CLIENT CERT\"\n}\n}\n</code></pre> <p>Then when accessing for the first time OCTI, the browser will ask for the certificate you want to use.</p>"},{"location":"deployment/authentication/#automatically-create-group-on-sso","title":"Automatically create group on SSO","text":"<p>The variable auto_create_group can be added in the options of some strategies (LDAP, SAML and OpenID). If this variable is true, the groups of a user that logins will automatically be created if they don\u2019t exist.</p> <p>More precisely, if the user that tries to authenticate has groups that don\u2019t exist in OpenCTI but exist in the SSO configuration, there are two cases:</p> <ul> <li>if auto_create_group= true in the SSO configuration: the groups are created at the platform initialization and the user will be mapped on them.</li> <li>else: an error is raised.</li> </ul>"},{"location":"deployment/authentication/#example","title":"Example","text":"<p>We assum that Group1 exists in the platform, and newGroup doesn\u2019t exist. The user that tries to log in has the group newGroup. If auto_create_group = true in the SSO configuration, the group named newGroup will be created at the platform initialization and the user will be mapped on it. If auto_create_group = false or is undefined, the user can\u2019t login and an error is raised.</p> <pre><code>\"groups_management\": {\n\"group_attribute\": \"cn\",\n\"groups_mapping\": [\"SSO_GROUP_NAME1:group1\", \"SSO_GROUP_NAME_2:newGroup\", ...]\n},\n\"auto_create_group\": true\n</code></pre>"},{"location":"deployment/authentication/#examples","title":"Examples","text":""},{"location":"deployment/authentication/#ldap-then-fallback-to-local","title":"LDAP then fallback to local","text":"<p>In this example the users have a login form and need to enter login and password. The authentication is done on LDAP first, then locally if user failed to authenticate and finally fail if none of them succeded. Here is an example for the <code>production.json</code> file:</p> <pre><code>\"providers\": {\n\"ldap\": {\n\"strategy\": \"LdapStrategy\",\n\"config\": {\n\"url\": \"ldaps://mydc.mydomain.com:636\",\n\"bind_dn\": \"cn=Administrator,cn=Users,dc=mydomain,dc=com\",\n\"bind_credentials\": \"MY_STRONG_PASSWORD\",\n\"search_base\": \"cn=Users,dc=mydomain,dc=com\",\n\"search_filter\": \"(cn={{username}})\",\n\"mail_attribute\": \"mail\",\n\"account_attribute\": \"givenName\"\n}\n},\n\"local\": {\n\"strategy\": \"LocalStrategy\",\n\"config\": {\n\"disabled\": false\n}\n}\n}\n</code></pre> <p>If you use a container deployment, here is an example using environment variables:</p> <pre><code>- PROVIDERS__LDAP__STRATEGY=LdapStrategy\n- PROVIDERS__LDAP__CONFIG__URL=ldaps://mydc.mydomain.org:636\n- PROVIDERS__LDAP__CONFIG__BIND_DN=cn=Administrator,cn=Users,dc=mydomain,dc=com\n- PROVIDERS__LDAP__CONFIG__BIND_CREDENTIALS=XXXXXXXXXX\n- PROVIDERS__LDAP__CONFIG__SEARCH_BASE=cn=Users,dc=mydomain,dc=com\n- PROVIDERS__LDAP__CONFIG__SEARCH_FILTER=(cn={{username}})\n- PROVIDERS__LDAP__CONFIG__MAIL_ATTRIBUTE=mail\n- PROVIDERS__LDAP__CONFIG__ACCOUNT_ATTRIBUTE=givenName\n- PROVIDERS__LDAP__CONFIG__ALLOW_SELF_SIGNED=true\n- PROVIDERS__LOCAL__STRATEGY=LocalStrategy\n</code></pre>"},{"location":"deployment/clustering/","title":"Clustering","text":""},{"location":"deployment/clustering/#introduction","title":"Introduction","text":"<p>The OpenCTI platform technological stack has been designed to be able to scale horizontally. All dependencies such as Elastic or Redis can be deployed in cluster mode and performances can be drastically increased by deploying multiple platform and worker instances.</p>"},{"location":"deployment/clustering/#high-level-architecture","title":"High level architecture","text":"<p>Here is the high level architecture for customers and Filigran cloud platform to ensure both high availability and throughput.</p> <p></p>"},{"location":"deployment/clustering/#configuration","title":"Configuration","text":""},{"location":"deployment/clustering/#dependencies","title":"Dependencies","text":""},{"location":"deployment/clustering/#elasticsearch","title":"ElasticSearch","text":"<p>In the ElasticSearch configuration of OpenCTI, it is possible to declare all nodes.</p> <pre><code>- \"ELASTICSEARCH__URL=[\\\"https://user:pass@node1:9200\\\", \\\"https://user:pass@node2:9200\\\", ...]\"\n</code></pre> <p>Compatibility</p> <p>OpenCTI is also compatible with OpenSearch and AWS / GCP / Azure native search services based on the ElasticSearch query language.</p>"},{"location":"deployment/clustering/#redis","title":"Redis","text":"<p>Redis should be turned to cluster mode:</p> <pre><code>- REDIS__MODE=cluster\n- \"REDIS__HOSTNAMES=[\\\"node1:6379\\\", \\\"node2:6379\\\", ...]\"\n</code></pre> <p>Compatibility</p> <p>OpenCTI is also compatible with ElastiCache, MemoryStore and AWS / GCP / Azure native services based on the Redis protocol.</p>"},{"location":"deployment/clustering/#rabbitmq","title":"RabbitMQ","text":"<p>For the RabbitMQ cluster, you will need a TCP load balancer on top of the nodes since the configuration does not support multi-nodes for now:</p> <pre><code>- RABBITMQ__HOSTNAME=load-balancer-rabbitmq\n</code></pre> <p>Compatibility</p> <p>OpenCTI is also compatible with Amazon MQ, CloudAMQP and AWS / GCP / Azure native services based on the AMQP protocol.</p>"},{"location":"deployment/clustering/#s3-bucket-minio","title":"S3 bucket / MinIO","text":"<p>MinIO is an open source server able to serve S3 buckets. It can be deployed in cluster mode and is compatible with several storage backend. OpenCTI is compatible with any tool following the S3 standard.</p>"},{"location":"deployment/clustering/#platform","title":"Platform","text":"<p>As showed on the schema, best practices for cluster mode and to avoid any congestion in the technological stack are:</p> <ul> <li>Deploy platform(s) dedicated to end users and connectors registration</li> <li>Deploy platform(s) dedicated to workers / ingestion process<ul> <li>We recommend 3 to 4 workers maxiumum by OpenCTI instance.</li> <li>The ingestion platforms will never be accessed directly by end users.</li> </ul> </li> </ul> <p>When enabling clustering, the number of nodes is displayed in Settings &gt; Parameters.</p> <p></p>"},{"location":"deployment/clustering/#managers-and-schedulers","title":"Managers and schedulers","text":"<p>Also, since some managers like the rule engine, the task manager and the notification manager can take some resources in the OpenCTI NodeJS process, it is highly recommended to disable them in the frontend cluster. OpenCTI automatically handle the distribution and the launching of the engines across all nodes in the cluster except where they are explicitely disabled in the configuration.</p>"},{"location":"deployment/configuration/","title":"Configuration","text":"<p>The purpose of this section is to learn how to configure OpenCTI to have it tailored for your production and development needs. </p> <p>Here are the configuration keys, for both containers (environment variables) and manual deployment.</p> <p>Parameters equivalence</p> <p>The equivalent of a config variable in environment variables is the usage of a double underscores (<code>__</code>) for a level of config.</p> <p>For example: <pre><code>\"providers\": {\n\"ldap\": {\n\"strategy\": \"LdapStrategy\"\n}\n}\n</code></pre></p> <p>will become: <pre><code>PROVIDERS__LDAP__STRATEGY=LdapStrategy\n</code></pre></p> <p>If you need to put a list of elements for the key, it must have a special formatting. Here is an example for redirect URIs for OpenID config: <pre><code>\"PROVIDERS__OPENID__CONFIG__REDIRECT_URIS=[\\\"https://demo.opencti.io/auth/oic/callback\\\"]\"\n</code></pre></p>"},{"location":"deployment/configuration/#platform","title":"Platform","text":""},{"location":"deployment/configuration/#api-frontend","title":"API &amp; Frontend","text":""},{"location":"deployment/configuration/#basic-parameters","title":"Basic parameters","text":"Parameter Environment variable Default value Description app:port APP__PORT 4000 Listen port of the application app:base_path APP__BASE_PATH Specific URI (ie. /opencti) app:base_url APP__BASE_URL http://localhost:4000 Full URL of the platform (should include the <code>base_path</code> if any) app:request_timeout APP__REQUEST_TIMEOUT 1200000 Request timeout, in ms (default 20 minutes) app:session_timeout APP__SESSION_TIMEOUT 1200000 Idle timeout, in ms (default 20 minutes) app:session_idle_timeout APP__SESSION_IDLE_TIMEOUT 0 Session timeout, in ms (default 0 minute - disabled) app:admin:email APP__ADMIN__EMAIL admin@opencti.io Default login email of the admin user app:admin:password APP__ADMIN__PASSWORD ChangeMe Default password of the admin user app:admin:token APP__ADMIN__TOKEN ChangeMe Default token (must be a valid UUIDv4)"},{"location":"deployment/configuration/#ssl-tls","title":"SSL / TLS","text":"Parameter Environment variable Default value Description app:https_cert:ca APP__HTTPS_CERT__CA Empty list [] Certificate authority paths or content, only if the client uses a self-signed certificate. app:https_cert:key APP__HTTPS_CERT__KEY Certificate key path or content app:https_cert:crt APP__HTTPS_CERT__CRT Certificate crt path or content app:https_cert:reject_unauthorized APP__HTTPS_CERT__REJECT_UNAUTHORIZED If not false, the server certificate is verified against the list of supplied CAs"},{"location":"deployment/configuration/#logging","title":"Logging","text":""},{"location":"deployment/configuration/#errors","title":"Errors","text":"Parameter Environment variable Default value Description app:app_logs:logs_level APP__APP_LOGS__LOGS_LEVEL info The application log level app:app_logs:logs_files APP__APP_LOGS__LOGS_FILES <code>true</code> If application logs is logged into files app:app_logs:logs_console APP__APP_LOGS__LOGS_CONSOLE <code>true</code> If application logs is logged to console (useful for containers) app:app_logs:logs_max_files APP__APP_LOGS__LOGS_MAX_FILES 7 Maximum number of daily files in logs app:app_logs:logs_directory APP__APP_LOGS__LOGS_DIRECTORY ./logs File logs directory"},{"location":"deployment/configuration/#audit","title":"Audit","text":"Parameter Environment variable Default value Description app:audit_logs:logs_files APP__AUDIT_LOGS__LOGS_FILES <code>true</code> If audit logs is logged into files app:audit_logs:logs_console APP__AUDIT_LOGS__LOGS_CONSOLE <code>true</code> If audit logs is logged to console (useful for containers) app:audit_logs:logs_max_files APP__AUDIT_LOGS__LOGS_MAX_FILES 7 Maximum number of daily files in logs app:audit_logs:logs_directory APP__AUDIT_LOGS__LOGS_DIRECTORY ./logs Audit logs directory"},{"location":"deployment/configuration/#maps-references","title":"Maps &amp; references","text":"Parameter Environment variable Default value Description app:map_tile_server_dark APP__MAP_TILE_SERVER_DARK https://map.opencti.io/styles/luatix-dark/{z}/{x}/{y}.png The address of the OpenStreetMap provider with dark theme style app:map_tile_server_light APP__MAP_TILE_SERVER_LIGHT https://map.opencti.io/styles/luatix-light/{z}/{x}/{y}.png The address of the OpenStreetMap provider with light theme style app:reference_attachment APP__REFERENCE_ATTACHMENT <code>false</code> External reference mandatory attachment"},{"location":"deployment/configuration/#technical-customization","title":"Technical customization","text":"Parameter Environment variable Default value Description app:graphql:playground:enabled APP__GRAPHQL__PLAYGROUND__ENABLED <code>true</code> Enable the playground on /graphql app:graphql:playground:force_disabled_introspection APP__GRAPHQL_PLAYGROUND__FORCE_DISABLED_INTROSPECTION <code>false</code> Introspection is allowed to auth users but can be disabled in needed app:concurrency:retry_count APP__CONCURRENCY__RETRY_COUNT 200 Number of try to get the lock to work an element (create/update/merge, ...) app:concurrency:retry_delay APP__CONCURRENCY__RETRY_DELAY 100 Delay between 2 lock retry (in milliseconds) app:concurrency:retry_jitter APP__CONCURRENCY__RETRY_JITTER 50 Random jitter to prevent concurrent retry  (in milliseconds) app:concurrency:max_ttl APP__CONCURRENCY__MAX_TTL 30000 Global maximum time for lock retry (in milliseconds)"},{"location":"deployment/configuration/#dependencies","title":"Dependencies","text":""},{"location":"deployment/configuration/#elasticsearch","title":"ElasticSearch","text":"Parameter Environment variable Default value Description elasticsearch:url ELASTICSEARCH__URL http://localhost:9200 URL(s) of the ElasticSearch (supports http://user:pass@localhost:9200 and list of URLs) elasticsearch:username ELASTICSEARCH__USERNAME Username can be put in the URL or with this parameter elasticsearch:password ELASTICSEARCH__PASSWORD Password can be put in the URL or with this parameter elasticsearch:index_prefix ELASTICSEARCH__INDEX_PREFIX opencti Prefix for the indices elasticsearch:ssl:reject_unauthorized ELASTICSEARCH__SSL__REJECT_UNAUTHORIZED <code>true</code> Enable TLS certificate check elasticsearch:ssl:ca ELASTICSEARCH__SSL__CA Custom certificate path or content elasticsearch:ssl:ca_plain (depecated) ELASTICSEARCH__SSL__CA_PLAIN @depecated, use ca directly"},{"location":"deployment/configuration/#redis","title":"Redis","text":"Parameter Environment variable Default value Description redis:mode REDIS__MODE single Connect to redis \"single\" or \"cluster\" redis:namespace REDIS__NAMESPACE Namespace (to use as prefix) redis:hostname REDIS__HOSTNAME localhost Hostname of the Redis Server redis:hostnames REDIS__HOSTNAMES Hostnames definition for Redis cluster mode: a list of host/port objects. redis:port REDIS__PORT 6379 Port of the Redis Server redis:use_ssl REDIS__USE_SSL <code>false</code> Is the Redis Server has TLS enabled redis:username REDIS__USERNAME Username of the Redis Server redis:password REDIS__PASSWORD Password of the Redis Server redis:ca REDIS__CA Path of the CA certificate redis:trimming REDIS__TRIMMING 2000000 Number of elements to maintain in the stream. (0 = unlimited)"},{"location":"deployment/configuration/#rabbitmq","title":"RabbitMQ","text":"Parameter Environment variable Default value Description rabbitmq:hostname RABBITMQ__HOSTNAME localhost Hostname of the RabbitMQ server rabbitmq:port RABBITMQ__PORT 5672 Port of the RabbitMQ server rabbitmq:port_management RABBITMQ__PORT_MANAGEMENT 15672 Port of the RabbitMQ Management Plugin rabbitmq:username RABBITMQ__USERNAME guest RabbitMQ user rabbitmq:password RABBITMQ__PASSWORD guest RabbitMQ password rabbitmq:queue_type RABBITMQ__QUEUE_TYPE \"classic\" RabbitMQ Queue Type (\"classic\" or \"quorum\") - - - - rabbitmq:use_ssl RABBITMQ__USE_SSL <code>false</code> Use TLS connection rabbitmq:use_ssl_cert RABBITMQ__USE_SSL_CERT Path or cert content rabbitmq:use_ssl_key RABBITMQ__USE_SSL_KEY Path or key content rabbitmq:use_ssl_pfx RABBITMQ__USE_SSL_PFX Path or pfx content rabbitmq:use_ssl_ca RABBITMQ__USE_SSL_CA Path or cacert content rabbitmq:use_ssl_passphrase RABBITMQ__SSL_PASSPHRASE Passphrase for the key certificate rabbitmq:use_ssl_reject_unauthorized RABBITMQ__SSL_REJECT_UNAUTHORIZED <code>false</code> Reject rabbit self signed certificate - - - - rabbitmq:management_ssl RABBITMQ__MANAGEMENT_SSL <code>false</code> Is the Management Plugin has TLS enabled rabbitmq:management_ssl_reject_unauthorized RABBITMQ__SSL_REJECT_UNAUTHORIZED <code>true</code> Reject management self signed certificate"},{"location":"deployment/configuration/#s3-bucket","title":"S3 Bucket","text":"Parameter Environment variable Default value Description minio:endpoint MINIO__ENDPOINT localhost Hostname of the S3 Service minio:port MINIO__PORT 9000 Port of the S3 Service minio:use_ssl MINIO__USE_SSL <code>false</code> Is the S3 Service has TLS enabled minio:access_key MINIO__ACCESS_KEY ChangeMe The S3 Service access key minio:secret_key MINIO__SECRET_KEY ChangeMe The S3 Service secret key minio:bucket_name MINIO__BUCKET_NAME opencti-bucket The S3 bucket name (useful to change if you use AWS) minio:bucket_region MINIO__BUCKET_REGION us-east-1 The S3 bucket region if you use AWS minio:use_aws_role MINIO__USE_AWS_ROLE <code>false</code> To use AWS role auto credentials"},{"location":"deployment/configuration/#smtp-service","title":"SMTP Service","text":"Parameter Environment variable Default value Description smtp:hostname SMTP__HOSTNAME SMTP Server hostname smtp:port SMTP__PORT 9000 SMTP Port (25 or 465 for TLS) smtp:use_ssl SMTP__USE_SSL <code>false</code> SMTP over TLS smtp:reject_unauthorized SMTP__REJECT_UNAUTHORIZED <code>false</code> Enable TLS certificate check smtp:username SMTP__USERNAME SMTP Username if authentication is needed smtp:password SMTP__PASSWORD SMTP Password if authentication is needed smtp:from_email SMTP__FROM_EMAIL notifications@opencti.io Sender email address"},{"location":"deployment/configuration/#schedules-engines","title":"Schedules &amp; Engines","text":"Parameter Environment variable Default value Description rule_engine:enabled RULE_ENGINE__ENABLED <code>true</code> Enable/disable the rule engine rule_engine:lock_key RULE_ENGINE__LOCK_KEY rule_engine_lock Lock key of the engine in Redis - - - - history_manager:enabled HISTORY_MANAGER__ENABLED <code>true</code> Enable/disable the history manager history_manager:lock_key HISTORY_MANAGER__LOCK_KEY history_manager_lock Lock key for the manager in Redis - - - - task_scheduler:enabled TASK_SCHEDULER__ENABLED <code>true</code> Enable/disable the task scheduler task_scheduler:lock_key TASK_SCHEDULER__LOCK_KEY task_manager_lock Lock key for the scheduler in Redis task_scheduler:interval TASK_SCHEDULER__INTERVAL 10000 Interval to check new task to do (in ms) - - - - sync_manager:enabled SYNC_MANAGER__ENABLED <code>true</code> Enable/disable the sync manager sync_manager:lock_key SYNC_MANAGER__LOCK_KEY sync_manager_lock Lock key for the manager in Redis sync_manager:interval SYNC_MANAGER__INTERVAL 10000 Interval to check new sync feeds to consume (in ms) - - - - expiration_scheduler:enabled EXPIRATION_SCHEDULER__ENABLED <code>true</code> Enable/disable the scheduler expiration_scheduler:lock_key EXPIRATION_SCHEDULER__LOCK_KEY expired_manager_lock Lock key for the scheduler in Redis expiration_scheduler:interval EXPIRATION_SCHEDULER__INTERVAL 300000 Interval to check expired indicators - - - - retention_manager:enabled RETENTION_MANAGER__ENABLED <code>true</code> Enable/disable the manager retention_manager:lock_key RETENTION_MANAGER__LOCK_KEY retention_manager_lock Lock key for the manager in Redis retention_manager:interval RETENTION_MANAGER__INTERVAL 60000 Interval to check items to be deleted - - - - notification_manager:enabled NOTIFICATION_MANAGER__ENABLED <code>true</code> Enable/disable the notification manager notification_manager:lock_key NOTIFICATION_MANAGER__LOCK_KEY notification_manager_lock Lock key for the manager in Redis notification_manager:interval NOTIFICATION_MANAGER__INTERVAL 10000 Sender email address - - - - publisher_manager:enabled PUBLISHER_MANAGER__ENABLED <code>true</code> Enable/disable the publisher manager publisher_manager:lock_key PUBLISHER_MANAGER__LOCK_KEY publisher_manager_lock Sender email address publisher_manager:interval PUBLISHER_MANAGER__INTERVAL 10000 Sender email address <p>Default file</p> <p>It is possible to check all default parameters implemented in the platform in the <code>default.json</code> file.</p>"},{"location":"deployment/configuration/#worker-and-connector","title":"Worker and connector","text":"<p>Can be configured manually using the configuration file <code>config.yml</code> or through environment variables.</p> Parameter Environment variable Default value Description opencti:url OPENCTI_URL The URL of the OpenCTI platform opencti:token OPENCTI_TOKEN A token of an administrator account with bypass capability - - - - mq:use_ssl / / Depending of the API configuration (fetch from API) mq:use_ssl_ca MQ_USE_SSL_CA Path or cacert content mq:use_ssl_cert MQ_USE_SSL_CERT Path or cert content mq:use_ssl_key MQ_USE_SSL_KEY Path or key content mq:use_ssl_passphrase MQ_USE_SSL_PASSPHRASE Passphrase for the key certificate mq:use_ssl_reject_unauthorized MQ_USE_SSL_REJECT_UNAUTHORIZED <code>false</code> Reject rabbit self signed certificate"},{"location":"deployment/configuration/#worker-specific-configuration","title":"Worker specific configuration","text":"Parameter Environment variable Default value Description worker:log_level WORKER_LOG_LEVEL info The log level (error, warning, info or debug)"},{"location":"deployment/configuration/#connector-specific-configuration","title":"Connector specific configuration","text":"<p>For specific connector configuration, you need to check each connector behavior.</p>"},{"location":"deployment/configuration/#elasticsearch_1","title":"ElasticSearch","text":"<p>If you want to adapt the memory consumption of ElasticSearch, you can use theses options:</p> <pre><code># Add the following environment variable:\n\"ES_JAVA_OPTS=-Xms8g -Xmx8g\"\n</code></pre> <p>This can be done in configuration file in the <code>jvm.conf</code> file.</p>"},{"location":"deployment/connectors/","title":"Connectors","text":""},{"location":"deployment/connectors/#introduction","title":"Introduction","text":"<p>Connectors list</p> <p>You are looking for the available connectors? The list is in the OpenCTI Ecosystem.</p> <p>Connectors are the cornerstone of the OpenCTI platform and allow organizations to easily ingest, enrich or export data in the platform. According to their functionality and use case, they are categorized in following classes.</p> <p></p>"},{"location":"deployment/connectors/#import","title":"Import","text":"<p>These connectors automatically retrieve information from an external organization, application or service, convert it to STIX 2.1 bundles and import it into OpenCTI using the workers.</p>"},{"location":"deployment/connectors/#enrichment","title":"Enrichment","text":"<p>When a new object is created in the platform or on the user request, it is possible to trigger the internal enrichment connector to lookup and/or search the object in external organizations, applications or services. If the object is found, the connectors will generate a STIX 2.1 bundle which will increase the level of knowledge about the concerned object.</p>"},{"location":"deployment/connectors/#stream","title":"Stream","text":"<p>These connectors connect to a platform data stream and continously do something with the received events. In most cases, they are used to consume OpenCTI data and insert them in third-party platforms such as SIEMs, XDRs, EDRS, etc. In some cases, stream connectors can also query the external system on a regular basis and act as import connector for instance to gather alerts and sightings related to CTI data and push them to OpenCTI (bi-directional).</p>"},{"location":"deployment/connectors/#import-files","title":"Import files","text":"<p>Information from an uploaded file can be extracted and ingested into OpenCTI. Examples are files attached to a report or a STIX 2.1 file.</p>"},{"location":"deployment/connectors/#export-files","title":"Export files","text":"<p>Information stored in OpenCTI can be extracted into different file formats like .csv or .json (STIX 2).</p>"},{"location":"deployment/connectors/#connector-configuration","title":"Connector configuration","text":"<p>All connectors have to be able to access to the OpenCTI API. To allow this connection, they have 2 mandatory configuration parameters, the <code>OPENCTI_URL</code> and the <code>OPENCTI_TOKEN</code>. In addition of these 2 parameters, connectors have other mandatory parameters that need to be set in order to get them work.</p> <p>Connectors tokens</p> <p>Be careful, we strongly recommend to use a dedicated token for each connector running in the platform. So you have to create a specific user for each of them.</p> <p>Also, if all connectors users can run in with a user belonging to the <code>Connectors</code> group (with the <code>Connector</code> role), the <code>Internal Export Files</code> should be run with a user who is Administrator (with bypass capability) because they imperstonate the user requesting the export to avoid data leak.</p> Type Required role Used permissions EXTERNAL_IMPORT Connector Import data with the connector user. INTERNAL_ENRICHMENT Connector Enrich data with the connector user. INTERNAL_IMPORT_FILE Connector Import data with the connector user. INTERNAL_EXPORT_FILE Administrator Export data with the user who requested the export. STREAM Connector Consume the streams the connector user. <p>Here is an example of a connector <code>docker-compose.yml</code> file: <pre><code>- CONNECTOR_ID=ChangeMe\n- CONNECTOR_TYPE=EXTERNAL_IMPORT\n- CONNECTOR_NAME=MITRE ATT&amp;CK\n- CONNECTOR_SCOPE=identity,attack-pattern,course-of-action,intrusion-set,malware,tool,report\n- CONNECTOR_CONFIDENCE_LEVEL=3\n- CONNECTOR_UPDATE_EXISTING_DATA=true\n- CONNECTOR_LOG_LEVEL=info\n</code></pre></p> <p>Here is an example in a connector <code>config.yml</code> file:</p> <pre><code>-connector:\nid: 'ChangeMe'\ntype: 'EXTERNAL_IMPORT'\nname: 'MITRE ATT&amp;CK'\nscope: 'identity,attack-pattern,course-of-action,intrusion-set,malware,tool,report'\nconfidence_level: 3\nupdate_existing_data: true\nlog_level: 'info'\n</code></pre>"},{"location":"deployment/connectors/#networking","title":"Networking","text":"<p>Be aware that all connectors are reaching RabbitMQ based the RabbitMQ configuration provided by the OpenCTI platform. The connector must be able to reach RabbitMQ on the specified hostname and port. If you have a specific Docker network configuration, please be sure to adapt your <code>docker-compose.yml</code> file in such way that the connector container gets attached to the OpenCTI Network, e.g.:</p> <pre><code>networks:\ndefault:\nexternal: true\nname: opencti-docker_default\n</code></pre>"},{"location":"deployment/connectors/#connector-token","title":"Connector token","text":""},{"location":"deployment/connectors/#create-the-user","title":"Create the user","text":"<p>As mentionned previously, it is strongly recommended to run each connector with its own user. The <code>Internal Export File</code> connectors should be launched with a user that belongs to a group which has an \u201cAdministrator\u201d role (with bypass all capabilities enabled).</p> <p>By default in platform, a group named \"Connectors\" already exists. So just create a new user with the name <code>[C] Name of the connector</code> in Settings &gt; Security &gt; Users.</p> <p></p>"},{"location":"deployment/connectors/#put-the-user-in-the-group","title":"Put the user in the group","text":"<p>Just go to the user you have just created and add it to the <code>Connectors</code> group.</p> <p></p> <p>Then just get the token of the user displayed in the interface.</p> <p></p>"},{"location":"deployment/connectors/#docker-activation","title":"Docker activation","text":"<p>You can either directly run the Docker image of connectors or add them to your current <code>docker-compose.yml</code> file.</p>"},{"location":"deployment/connectors/#add-a-connector-to-your-deployment","title":"Add a connector to your deployment","text":"<p>For instance, to enable the MISP connector, you can add a new service to your <code>docker-compose.yml</code> file:</p> <pre><code>  connector-misp:\n    image: opencti/connector-misp:latest\n    environment:\n      - OPENCTI_URL=http://localhost\n      - OPENCTI_TOKEN=ChangeMe\n      - CONNECTOR_ID=ChangeMe\n      - CONNECTOR_TYPE=EXTERNAL_IMPORT\n      - CONNECTOR_NAME=MISP\n      - CONNECTOR_SCOPE=misp\n      - CONNECTOR_CONFIDENCE_LEVEL=3\n- CONNECTOR_UPDATE_EXISTING_DATA=false\n      - CONNECTOR_LOG_LEVEL=info\n      - MISP_URL=http://localhost # Required\n      - MISP_KEY=ChangeMe # Required\n      - MISP_SSL_VERIFY=False # Required\n      - MISP_CREATE_REPORTS=True # Required, create report for MISP event\n      - MISP_REPORT_CLASS=MISP event # Optional, report_class if creating report for event\n      - MISP_IMPORT_FROM_DATE=2000-01-01 # Optional, import all event from this date\n      - MISP_IMPORT_TAGS=opencti:import,type:osint # Optional, list of tags used for import events\n      - MISP_INTERVAL=1 # Required, in minutes\n    restart: always\n</code></pre>"},{"location":"deployment/connectors/#launch-a-standalone-connector","title":"Launch a standalone connector","text":"<p>To launch standalone connector, you can use the <code>docker-compose.yml</code> file of the connector itself. Just download the latest release and start the connector:</p> <pre><code>$ wget https://github.com/OpenCTI-Platform/connectors/archive/{RELEASE_VERSION}.zip\n$ unzip {RELEASE_VERSION}.zip\n$ cd connectors-{RELEASE_VERSION}/misp/\n</code></pre> <p>Change the configuration in the <code>docker-compose.yml</code> according to the parameters of the platform and of the targeted service. Then launch the connector:</p> <pre><code>$ docker-compose up\n</code></pre>"},{"location":"deployment/connectors/#manual-activation","title":"Manual activation","text":"<p>If you want to manually launch connector, you just have to install Python 3 and pip3 for dependencies:</p> <pre><code>$ apt install python3 python3-pip\n</code></pre> <p>Download the release of the connectors:</p> <pre><code>$ wget &lt;https://github.com/OpenCTI-Platform/connectors/archive/{RELEASE_VERSION}.zip&gt;\n$ unzip {RELEASE_VERSION}.zip\n$ cd connectors-{RELEASE_VERSION}/misp/src/\n</code></pre> <p>Install dependencies and initialize the configuration:</p> <pre><code>$ pip3 install -r requirements.txt\n$ cp config.yml.sample config.yml\n</code></pre> <p>Change the <code>config.yml</code> content according to the parameters of the platform and of the targeted service and launch the connector:</p> <pre><code>$ python3 misp.py\n</code></pre>"},{"location":"deployment/connectors/#connectors-status","title":"Connectors status","text":"<p>The connector status can be displayed in the dedicated section of the platform available in Data &gt; Connectors. You will be able to see the statistics of the RabbitMQ queue of the connector:</p> <p></p> <p>Problem</p> <p>If you encounter problems deploying OpenCTI or connectors, you can consult the troubleshooting page page.</p>"},{"location":"deployment/installation/","title":"Installation","text":"<p>All components of OpenCTI are shipped both as Docker images and manual installation packages.</p> <p>Production deployment</p> <p>For production deployment, we recommend to deploy all components in containers, including dependencies, using native cloud services or orchestration systems such as Kubernetes.</p> <p>To have more details about deploying OpenCTI and its dependencies in cluster mode, please read the dedicated section.</p> <ul> <li> <p> Use Docker</p> <p>Deploy OpenCTI using Docker and the default <code>docker-compose.yml</code> provided in the docker.</p> <p> Setup</p> </li> <li> <p> Manual installation</p> <p>Deploy dependencies and launch the platform manually using the packages released in the GitHub releases.</p> <p> Explore</p> </li> </ul>"},{"location":"deployment/installation/#using-docker","title":"Using Docker","text":""},{"location":"deployment/installation/#introduction","title":"Introduction","text":"<p>OpenCTI can be deployed using the docker-compose command.</p>"},{"location":"deployment/installation/#pre-requisites","title":"Pre-requisites","text":"<p> Linux</p> <pre><code>$ sudo apt install docker-compose\n</code></pre> <p> Windows and MacOS</p> <p>Just download the appropriate Docker for Desktop version for your operating system.</p>"},{"location":"deployment/installation/#clone-the-repository","title":"Clone the repository","text":"<p>Docker helpers are available in the Docker GitHub repository.</p> <pre><code>$ mkdir -p /path/to/your/app &amp;&amp; cd /path/to/your/app\n$ git clone https://github.com/OpenCTI-Platform/docker.git\n$ cd docker\n</code></pre>"},{"location":"deployment/installation/#configure-the-environment","title":"Configure the environment","text":"<p>Before running the <code>docker-compose</code> command, the <code>docker-compose.yml</code> file should be configured. By default, the <code>docker-compose.yml</code> file is using environment variables available in the file <code>.env.sample</code>.</p> <p>You can either rename the file <code>.env.sample</code> in <code>.env</code> and put the expected values or just fill directly the <code>docker-compose.yml</code> with the values corresponding to your environment.</p> <p>Configuration static parameters</p> <p>The complete list of available static parameters is available in the configuration section.</p> <p>Here is an example to quickly generate the <code>.env</code> file under Linux, especially all the default UUIDv4:</p> <pre><code>$ sudo apt install -y jq\n$ cd ~/docker\n$ (cat &lt;&lt; EOF\nOPENCTI_ADMIN_EMAIL=admin@opencti.io\nOPENCTI_ADMIN_PASSWORD=ChangeMePlease\nOPENCTI_ADMIN_TOKEN=$(cat /proc/sys/kernel/random/uuid)\nMINIO_ROOT_USER=$(cat /proc/sys/kernel/random/uuid)\nMINIO_ROOT_PASSWORD=$(cat /proc/sys/kernel/random/uuid)\nRABBITMQ_DEFAULT_USER=guest\nRABBITMQ_DEFAULT_PASS=guest\nELASTIC_MEMORY_SIZE=4G\nCONNECTOR_HISTORY_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_EXPORT_FILE_STIX_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_EXPORT_FILE_CSV_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_IMPORT_FILE_STIX_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_IMPORT_REPORT_ID=$(cat /proc/sys/kernel/random/uuid)\nEOF\n) &gt; .env\n</code></pre> <p>If your <code>docker-compose</code> deployment does not support <code>.env</code> files, just export all environment variables before launching the platform:</p> <pre><code>$ export $(cat .env | grep -v \"#\" | xargs)\n</code></pre>"},{"location":"deployment/installation/#memory-management-settings","title":"Memory management settings","text":"<p>As OpenCTI has a dependency on ElasticSearch, you have to set the <code>vm.max_map_count</code> before running the containers, as mentioned in the ElasticSearch documentation.</p> <pre><code>$ sudo sysctl -w vm.max_map_count=1048575\n</code></pre> <p>To make this parameter persistent, add the following to the end of your <code>/etc/sysctl.conf</code>:</p> <pre><code>$ vm.max_map_count=1048575\n</code></pre>"},{"location":"deployment/installation/#persist-data","title":"Persist data","text":"<p>The default for OpenCTI data is to be persistent.</p> <p>In the <code>docker-compose.yml</code>, you will find at the end the list of necessary persitent volumes for the dependencies:</p> <pre><code>volumes:\nesdata:     # ElasticSearch data\ns3data:     # S3 bucket data\nredisdata:  # Redis data\namqpdata:   # RabbitMQ data\n</code></pre>"},{"location":"deployment/installation/#run-opencti","title":"Run OpenCTI","text":""},{"location":"deployment/installation/#using-single-node-docker","title":"Using single node Docker","text":"<p>After changing your <code>.env</code> file run <code>docker-compose</code> in detached (-d) mode:</p> <pre><code>$ sudo systemctl start docker.service\n# Run docker-compose in detached \n$ docker-compose up -d\n</code></pre>"},{"location":"deployment/installation/#using-docker-swarm","title":"Using Docker swarm","text":"<p>In order to have the best experience with Docker, we recommend using the Docker stack feature. In this mode you will have the capacity to easily scale your deployment. </p> <pre><code># If your virtual machine is not a part of a Swarm cluster, please use:\n$ docker swarm init\n</code></pre> <p>Put your environment variables in <code>/etc/environment</code>:</p> <pre><code># If you already exported your variables to .env from above:\n$ sudo cat .env &gt;&gt; /etc/environment\n$ sudo bash -c 'cat .env &gt;&gt; /etc/environment\u2019\n$ sudo docker stack deploy --compose-file docker-compose.yml opencti\n</code></pre> <p>Installation done</p> <p>You can now go to http://localhost:8080 and log in with the credentials configured in your environment variables.</p>"},{"location":"deployment/installation/#manual-installation","title":"Manual installation","text":""},{"location":"deployment/installation/#prerequisites","title":"Prerequisites","text":""},{"location":"deployment/installation/#prepare-the-installation","title":"Prepare the installation","text":""},{"location":"deployment/installation/#installation-of-dependencies","title":"Installation of dependencies","text":"<p>You have to install all the needed dependencies for the main application and the workers. The example below is for Debian-based systems:</p> <pre><code>$ sudo apt-get install build-essential nodejs npm python3 python3-pip python3-dev\n</code></pre>"},{"location":"deployment/installation/#download-the-application-files","title":"Download the application files","text":"<p>First, you have to download and extract the latest release file. Then select the version to install depending of your operating system: </p> <p>For Linux:</p> <ul> <li>If your OS supports libc (Ubuntu, Debian, ...) you have to install the <code>opencti-release_{RELEASE_VERSION}.tar.gz</code> version.</li> <li>If your OS uses musl (Alpine, ...) you have to install the <code>opencti-release-{RELEASE_VERSION}_musl.tar.gz</code> version.</li> </ul> <p>For Windows:</p> <p>We don't provide any Windows release for now. However it is still possible to check the code out, manually install the dependencies and build the software.</p> <pre><code>$ mkdir /path/to/your/app &amp;&amp; cd /path/to/your/app\n$ wget &lt;https://github.com/OpenCTI-Platform/opencti/releases/download/{RELEASE_VERSION}/opencti-release-{RELEASE_VERSION}.tar.gz&gt;\n$ tar xvfz opencti-release-{RELEASE_VERSION}.tar.gz\n</code></pre>"},{"location":"deployment/installation/#install-the-main-platform","title":"Install the main platform","text":""},{"location":"deployment/installation/#configure-the-application","title":"Configure the application","text":"<p>The main application has just one JSON configuration file to change and a few Python modules to install</p> <pre><code>$ cd opencti\n$ cp config/default.json config/production.json\n</code></pre> <p>Change the config/production.json file according to your configuration of ElasticSearch, Redis, RabbitMQ and S3 bucket as well as default credentials (the <code>ADMIN_TOKEN</code> must be a valid UUID).</p>"},{"location":"deployment/installation/#install-the-python-modules","title":"Install the Python modules","text":"<pre><code>$ cd src/python\n$ pip3 install -r requirements.txt\n$ cd ../..\n</code></pre>"},{"location":"deployment/installation/#start-the-application","title":"Start the application","text":"<p>The application is just a NodeJS process, the creation of the database schema and the migration will be done at starting.</p> <pre><code>$ yarn install\n$ yarn build\n$ yarn serv\n</code></pre> <p>The default username and password are those you have put in the <code>config/production.json</code> file.</p>"},{"location":"deployment/installation/#install-the-worker","title":"Install the worker","text":"<p>The OpenCTI worker is used to write the data coming from the RabbitMQ messages broker.</p>"},{"location":"deployment/installation/#configure-the-worker","title":"Configure the worker","text":"<pre><code>$ cd worker\n$ pip3 install -r requirements.txt\n$ cp config.yml.sample config.yml\n</code></pre> <p>Change the config.yml file according to your OpenCTI token.</p>"},{"location":"deployment/installation/#start-as-many-workers-as-you-need","title":"Start as many workers as you need","text":"<pre><code>$ python3 worker.py &amp;\n$ python3 worker.py &amp;\n</code></pre> <p>Installation done</p> <p>You can now go to http://localhost:4000 and log in with the credentials configured in your <code>production.json</code> file.</p>"},{"location":"deployment/installation/#appendix","title":"Appendix","text":""},{"location":"deployment/installation/#community-contributions","title":"Community contributions","text":""},{"location":"deployment/installation/#terraform","title":"Terraform","text":"<ul> <li> <p> Multi-clouds Terraform scripts</p> <p>This repository is here to provide you with a quick and easy way to deploy an OpenCTI instance in the cloud (AWS, Azure, or GCP).</p> <p> GitHub Respository</p> </li> <li> <p> AWS Advanced Terraform scripts</p> <p>A Terraform deployment of OpenCTI designed to make use of native AWS Resources (where feasible). This includes AWS ECS Fargate, AWS OpenSearch, etc.</p> <p> GitHub Repository</p> </li> </ul>"},{"location":"deployment/installation/#helm-charts","title":"Helm Charts","text":"<ul> <li> <p> Kubernetes Helm Charts</p> <p>OpenCTI Helm Charts (may be out of date) for Kubernetes with a global configuration file.</p> <p> GitHub Repository</p> </li> </ul>"},{"location":"deployment/installation/#deploy-behind-a-reverse-proxy","title":"Deploy behind a reverse proxy","text":"<p>If you want to use OpenCTI behind a reverse proxy with a context path, like <code>https://domain.com/opencti</code>, please change the <code>base_path</code> static parameter.</p> <ul> <li><code>APP__BASE_PATH=/opencti</code></li> </ul> <p>By default OpenCTI use websockets so don't forget to configure your proxy for this usage, an example with <code>Nginx</code>:</p> <pre><code>location / {\nproxy_cache                 off;\nproxy_buffering             off;\nproxy_http_version          1.1;\nproxy_set_header Upgrade    $http_upgrade;\nproxy_set_header Connection \"upgrade\";\nproxy_set_header Host       $host;\nchunked_transfer_encoding   off;\nproxy_pass                  http://YOUR_UPSTREAM_BACKEND;\n}\n</code></pre>"},{"location":"deployment/installation/#additional-memory-information","title":"Additional memory information","text":""},{"location":"deployment/installation/#platform","title":"Platform","text":"<p>OpenCTI platform is based on a NodeJS runtime, with a memory limit of 8GB by default. If you encounter <code>OutOfMemory</code> exceptions, this limit could be changed:</p> <pre><code>- NODE_OPTIONS=--max-old-space-size=8096\n</code></pre>"},{"location":"deployment/installation/#workers-and-connectors","title":"Workers and connectors","text":"<p>OpenCTI workers and connectors are Python processes. If you want to limit the memory of the process, we recommend to directly use Docker to do that. You can find more information in the official Docker documentation.</p>"},{"location":"deployment/installation/#elasticsearch","title":"ElasticSearch","text":"<p>ElasticSearch is also a JAVA process. In order to setup the JAVA memory allocation, you can use the environment variable <code>ES_JAVA_OPTS</code>. You can find more information in the official ElasticSearch documentation.</p>"},{"location":"deployment/installation/#redis","title":"Redis","text":"<p>Redis has a very small footprint on keys but will consume memory for the stream. By default the size of the stream is limited to 2 millions which represents a memory footprint around <code>8 GB</code>. You can find more information in the Redis docker hub.</p>"},{"location":"deployment/installation/#minio-s3-bucket","title":"MinIO / S3 Bucket","text":"<p>MinIO is a small process and does not require a high amount of memory. More information are available for Linux here on the Kernel tuning guide.</p>"},{"location":"deployment/installation/#rabbitmq","title":"RabbitMQ","text":"<p>The RabbitMQ memory configuration can be find in the RabbitMQ official documentation. RabbitMQ will consumed memory until a specific threshold, therefore it should be configure along with the Docker memory limitation.</p>"},{"location":"deployment/integrations/","title":"Integrations","text":""},{"location":"deployment/integrations/#introduction","title":"Introduction","text":"<p>OpenCTI supports multiple ways to integrate with other systems which do not have native connectors or plugins to the platform. Here are the technical features available to ease the connection and the integration of the platform with other applications.</p> <p>Connectors list</p> <p>If you are looking to the list of OpenCTI connectors or native integration, please check the OpenCTI Ecosystem.</p>"},{"location":"deployment/integrations/#native-feeds-and-streams","title":"Native feeds and streams","text":"<p>To ease integrations with other products, OpenCTI has built-in capabilities to deliver the data to third-parties.</p>"},{"location":"deployment/integrations/#csv-feeds","title":"CSV Feeds","text":"<p>It is possible to create as many CSV feeds as needed, based on filters and accessible in HTTP. CSV feeds are available in Data &gt; Data sharing &gt; Feeds (CSV).</p> <p>When creating a CSV feed, you need to select one or multiple types of entity to make available. For all columns available in the CSV, you've to select which field will be used for each type of entity:</p> <p></p> <p>Details</p> <p>For more information about CSV feeds, filters and configuration, please check the Export in structured format section.</p>"},{"location":"deployment/integrations/#taxii-collections","title":"TAXII collections","text":"<p>Most of the moden cybersecurity systems such as SIEMs, EDRs, XDRs and even firewalls supports the TAXII protocol which is basically a paginated HTTP STIX feed. OpenCTI implements a TAXII 2.1 server with the ability to create as many TAXII collections as needed in Data &gt; Data sharing &gt; TAXII Collections?</p> <p>TAXII collections are a sub-selection of the knowledge available in the platform and relie on filters. For instance, it is possible to create TAXII collections for pieces of malware with a given label, for indicators with a score greater than n, etc.</p> <p></p>"},{"location":"deployment/integrations/#http-streams","title":"HTTP Streams","text":"<p>After implementing CSV feeds and TAXII collections, we figured out that those 2 stateless APIs are definitely not enough when it comes to tackle advanced information sharing challenges such as:</p> <ul> <li>Real time transmission of the information (ie. avoid hundreds of systems to pull data every 5 minutes).</li> <li>Dependencies resolution (ie. an intrusion created by an organization but the organization is not in the TAXII collection).</li> <li>Partial update for huge entities such as report (ie. just having the update event).</li> <li>Delete events when necessary (ie. to handle indicators expiration in third party systems for instance).</li> </ul> <p>Live streams are available in Data &gt; Data sharing &gt; Live streams. As TAXII collections, it is possible to create as many streams as needed using filters.</p> <p></p> <p>Streams implement the HTTP SSE (Server-sent events) protocol and give applications to consume a real time pure STIX 2.1 stream. Stream connectors in the OpenCTI Ecosystem are using live streams to consume data and do something such as create / update / delete information in SIEMs, XDRs, etc.</p>"},{"location":"deployment/integrations/#authentication","title":"Authentication","text":"<p>For all previously explained capabilities, as they are over the HTTP protocol, 3 authentication mechanisms are available to consume them.</p> <ol> <li> <p>Using a bearer header with your OpenCTI API key</p> <pre><code>Authorization: Bearer a17bc103-8420-4208-bd53-e1f80845d15f\n</code></pre> <p>API Key</p> <p>Your API key can be found in your profile available clicking on the top right icon.</p> </li> <li> <p>Using basic authentication</p> <pre><code>Username: Your platform username\nPassword: Your plafrom password\nAuthorization: Basic c2FtdWVsLmhhc3NpbmVBZmlsaWdyYW4uaW86TG91aXNlMTMwNCM=\n</code></pre> </li> <li> <p>Using client certificate authentication</p> <p>To know how to configure the client certificate authentication, please consult the authentication configuration section.</p> </li> </ol>"},{"location":"deployment/integrations/#api-and-libraries","title":"API and libraries","text":""},{"location":"deployment/integrations/#graphql-api","title":"GraphQL API","text":"<p>To allow analysts and developers to implement more custom or complex use cases, a full GraphQL API is available in the application on the <code>/graphql</code> endpoint.</p> <p>The API can be queried using various GraphQL client such as Postman but you can leverage any HTTP client to forge GraphQL queries using <code>POST</code> methods.</p>"},{"location":"deployment/integrations/#authentication_1","title":"Authentication","text":"<p>The API authentication can be performed using the token of a user and a classic Authorization header:</p> <pre><code>Content-Type: application/json\nAuthorization: Bearer 6b6554c4-bb2c-4c80-9cd3-30288c8bf424\n</code></pre>"},{"location":"deployment/integrations/#playground","title":"Playground","text":"<p>The playground is available on the <code>/graphql</code> endpoint. A link button is also available in the profile of your user.</p> <p></p> <p>All the schema documentation is directly available in the playground.</p> <p></p> <p>If you already logged to OpenCTI with the same browser you should be able to directly do some requests. If you are not authenticated or want to authenticate only through the playground you can use a header configuration using your profile token</p> <p>Example of configuration (bottom left of the playground):</p> <p></p>"},{"location":"deployment/integrations/#python-library","title":"Python library","text":"<p>Since not everyone is familiar with GraphQL APIs, we've developed a Python library to ease the interaction with it. The library is pretty easy to use. To initiate the client:</p> <pre><code># coding: utf-8\nfrom pycti import OpenCTIApiClient\n# Variables\napi_url = \"http://opencti:4000\"\napi_token = \"bfa014e0-e02e-4aa6-a42b-603b19dcf159\"\n# OpenCTI initialization\nopencti_api_client = OpenCTIApiClient(api_url, api_token)\n</code></pre> <p>Then just use the available helpers: <pre><code># Search for malware with the keyword \"windows\"\nmalwares = opencti_api_client.malware.list(search=\"windows\")\n# Print\nprint(malwares)\n</code></pre></p> <p>Details</p> <p>For more detailed information about the Python library, please read the dedicated section.</p>"},{"location":"deployment/overview/","title":"Overview","text":"<p>Before starting the installation, let's discover how OpenCTI is working, which dependencies are needed and what are the minimal requirements to deploy it in production.</p>"},{"location":"deployment/overview/#architecture","title":"Architecture","text":"<p>The OpenCTI platform relies on several external databases and services in order to work.</p> <p></p>"},{"location":"deployment/overview/#platform","title":"Platform","text":"<p>The platform is the central part of the OpenCTI technological stack. It allows users to access to the user interface but also provides the GraphQL API used by connectors and workers to insert data. In the context of a production deployment, you may need to scale horizontally and launch multiple platforms behind a load balancer connected to the same databases (ElasticSearch, Redis, S3, RabbitMQ).</p>"},{"location":"deployment/overview/#workers","title":"Workers","text":"<p>The workers are standalone Python processes consuming messages from the RabbitMQ broker in order to do asynchronous write queries. You can launch as many workers as you need to increase the write performances. At some point, the write performances will be limited by the throughput of the ElasticSearch database cluster.</p> <p>Number of workers</p> <p>If you need to increase performances, it is better to launch more platforms to handle worker queries. The recommended setup is to have at least one platform for 3 workers (ie. 9 workers distributed over 3 platforms).</p>"},{"location":"deployment/overview/#connectors","title":"Connectors","text":"<p>The connectors are third-party pieces of software (Python processes) that can play five different  roles on the platform:</p> Type Description Examples EXTERNAL_IMPORT Pull data from remote sources, convert it to STIX2 and insert it on the OpenCTI platform. MITRE Datasets, MISP, CVE, AlienVault, Mandiant, etc. INTERNAL_ENRICHMENT Listen for new OpenCTI entities or users requests, pull data from remote sources to enrich. Shodan, DomainTools, IpInfo, etc. INTERNAL_IMPORT_FILE Extract data from files uploaded on OpenCTI trough the UI or the API. STIX 2.1, PDF, Text, HTML, etc. INTERNAL_EXPORT_FILE Generate export from OpenCTI data, based on a single object or a list. STIX 2.1, CSV, PDF, etc. STREAM Consume a platform data stream an do something with events. Splunk, Elastic Security, Q-Radar, etc. <p>List of connectors</p> <p>You can find all currently available connector in the OpenCTI Ecosystem.</p>"},{"location":"deployment/overview/#infrastructure-requirements","title":"Infrastructure requirements","text":""},{"location":"deployment/overview/#dependencies","title":"Dependencies","text":"Component CPU RAM Disk type Disk space ElasticSearch 2 cores \u2265 8GB SSD \u2265 16GB Redis 1 core \u2265 1GB SSD \u2265 16GB RabbitMQ 1 core \u2265 512MB Standard \u2265 2GB S3 / MinIO 1 core \u2265 128MB SSD \u2265 16GB"},{"location":"deployment/overview/#platform_1","title":"Platform","text":"Component CPU RAM Disk type Disk space OpenCTI Core 2 cores \u2265 8GB None (stateless) - Worker(s) 1 core \u2265 128MB None (stateless) - Connector(s) 1 core \u2265 128MB None (stateless) - <p>Clustering</p> <p>To have more details about deploying OpenCTI and its dependencies in cluster mode, please read the dedicated section.</p>"},{"location":"deployment/resources/","title":"Other resources","text":""},{"location":"deployment/resources/#introduction","title":"Introduction","text":"<p>OpenCTI is an open and modular platform. A lot of connectors, plugins and clients  are created by Filigran and community. You can find here other resources available to complete your OpenCTI journey.</p>"},{"location":"deployment/resources/#videos-training","title":"Videos &amp; training","text":"<ul> <li> <p> YouTube channel</p> <p>Watch demonstration videos, use case explanations, customers and community testimonies and past webinars.</p> <p> Watch</p> </li> <li> <p> Training courses</p> <p>Empower your journey with OpenCTI training courses for both analyst and  administrators and get your certifcate.</p> <p> Learn</p> </li> </ul>"},{"location":"deployment/resources/#articles-news","title":"Articles &amp; news","text":"<ul> <li> <p> Blog articles</p> <p>Read posts written by both Filigran teams and community members about OpenCTI features and use cases.</p> <p> Read</p> </li> <li> <p> Newsletters</p> <p>Subscribe to Filigran newsletters to get informed about the latest evolutions of our product ecosystems.</p> <p> Subscribe</p> </li> </ul>"},{"location":"deployment/resources/#analysis","title":"Analysis","text":"<ul> <li> <p> Verticalized threat landcapes</p> <p>Access to monthly sectorial analysis from our experts team based on knowledge and data collected by our partners.</p> <p> Consult</p> </li> <li> <p> Case studies</p> <p>Explore the Filigran case studies about stories and usages of the platform  among our communities and customers.</p> <p> Download</p> </li> </ul>"},{"location":"deployment/rollover/","title":"Indices and rollover policies","text":"<p>Default rollover policies</p> <p>Since OpenCTI 5.9.0, rollover policies are automatically created when the platform is initialized for the first time. If your platform has been initialized using an older version of OpenCTI or if you would like to understand (and customize) rollover policies please read the following documentation.</p>"},{"location":"deployment/rollover/#introduction","title":"Introduction","text":"<p>ElasticSearch and OpenSearch both support rollover on indices. OpenCTI has been designed to be able to use aliases for indices and so support very well index lifeycle policies. Thus, by default OpenCTI initialized indices with a suffix <code>-00001</code> and use wildcard to query indices. When rollover policies are implemented (default starting OCTI 5.9.X if you initialized your platform at this version), indices are splitted to keep a reasonable volume of data in shards.</p> <p></p>"},{"location":"deployment/rollover/#elasticsearch-configuration","title":"ElasticSearch configuration","text":""},{"location":"deployment/rollover/#indices","title":"Indices","text":"<p>By default, a rollover policy is applied on all indices used by OpenCTI.</p> <ul> <li><code>opencti_history</code></li> <li><code>opencti_inferred_entities</code></li> <li><code>opencti_inferred_relationships</code></li> <li><code>opencti_internal_objects</code></li> <li><code>opencti_internal_relationships</code></li> <li><code>opencti_stix_core_relationships</code></li> <li><code>opencti_stix_cyber_observable_relationships</code></li> <li><code>opencti_stix_cyber_observables</code></li> <li><code>opencti_stix_domain_objects</code></li> <li><code>opencti_stix_meta_objects</code></li> <li><code>opencti_stix_meta_relationships</code></li> </ul> <p>For your information, the indices which can grow rapidly are:</p> <ul> <li>Index <code>opencti_stix_meta_relationships</code>: it contains all the nested relationships between objects and labels / marking definitions / external references / authors, etc.</li> <li>Index <code>opencti_history</code>: it contains the history log of all objects in the platform.</li> <li>Index <code>opencti_stix_cyber_observables</code>: it contains all observables stored in the platform.</li> <li>Index <code>opencti_stix_core_relationships</code>: it contains all main STIX relationships stored in the platform.</li> </ul>"},{"location":"deployment/rollover/#default-implemented-licecycle-policy","title":"Default implemented licecycle policy","text":"<p>Here is the recommended policy (initialized starting 5.9.X):</p> <ul> <li>Maximum primary shard size: <code>50 GB</code></li> <li>Maximum age: <code>365 days</code></li> <li>Maximum documents: <code>75,000,000</code></li> </ul>"},{"location":"deployment/rollover/#applying-rollover-policies-on-existing-indices","title":"Applying rollover policies on existing indices","text":"<p>Procedure information</p> <p>Please read the following only if your platform has been initialized before 5.9.0, otherwise lifecycle policies has been created (but you can still cutomize them).</p> <p>Unfortunately, to be able to implement rollover policies on ElasticSearch / OpenSearch indices, it will be needed to re-index all the data in new indices using ElasticSearch capabilities.</p>"},{"location":"deployment/rollover/#step-by-step-guide","title":"Step by step guide","text":""},{"location":"deployment/rollover/#shutdown","title":"Shutdown","text":"<p>First step is to shutdown your OpenCTI platform.</p>"},{"location":"deployment/rollover/#change-configuration","title":"Change configuration","text":"<p>Then, in the OpenCTI configuration, change the ElasticSearch / OpenSearch default prefix to <code>octi</code> (default is <code>opencti</code>).</p>"},{"location":"deployment/rollover/#create-the-rollover-policy","title":"Create the rollover policy","text":"<p>Create a rollover policy named <code>octi-ilm-policy</code> (in Kibana, <code>Management &gt; Index Lifecycle Policies</code>):</p> <ul> <li>Maximum primary shard size: <code>50 GB</code></li> <li>Maximum age: <code>365 days</code></li> <li>Maximum documents: <code>75,000,000</code></li> </ul> <p></p>"},{"location":"deployment/rollover/#create-index-templates","title":"Create index templates","text":"<p>In Kibana, clone the <code>opencti-index-template</code> to have one index template by OpenCTI index with the appropriate rollover policy, index pattern and rollover alias (in Kibana, <code>Management &gt; Index Management &gt; Index Templates</code>).</p> <p></p> <p>Create the following index templates:</p> <ul> <li><code>octi_history</code></li> <li><code>octi_inferred_entities</code></li> <li><code>octi_inferred_relationships</code></li> <li><code>octi_internal_objects</code></li> <li><code>octi_internal_relationships</code></li> <li><code>octi_stix_core_relationships</code></li> <li><code>octi_stix_cyber_observable_relationships</code></li> <li><code>octi_stix_cyber_observables</code></li> <li><code>octi_stix_domain_objects</code></li> <li><code>octi_stix_meta_objects</code></li> <li><code>octi_stix_meta_relationships</code></li> </ul> <p>Here is the overview of all templates (you should have something with <code>octi_</code> instead of <code>opencti_</code>).</p> <p></p>"},{"location":"deployment/rollover/#apply-rollover-policy-on-all-index-templates","title":"Apply rollover policy on all index templates","text":"<p>Then, going back in the index lifecycle policies screen, you can click on the \"+\" button of the <code>octi-ilm-policy</code> to <code>Add the policy to index template</code>, then add the policy to add previously created template with the proper \"Alias for rollover index\".</p> <p></p>"},{"location":"deployment/rollover/#re-index-all-indices","title":"Re-index all indices","text":"<p>Using the <code>reindex</code> API, re-index all indices one by one:</p> <pre><code>curl -X POST \"localhost:9200/_reindex?pretty\" -H 'Content-Type: application/json' -d'\n{\n  \"source\": {\n    \"index\": \"opencti_history-000001\"\n  },\n  \"dest\": {\n    \"index\": \"octi_history-000001\"\n  }\n}\n'\n</code></pre> <p>You will see the rollover policy to be applied and the new indices are automatically rolled-over during reindexation.</p>"},{"location":"deployment/rollover/#delete-all-old-indices","title":"Delete all old indices","text":"<p>Then just delete all indices with the prefix <code>opencti_</code>.</p>"},{"location":"deployment/rollover/#start-your-platform","title":"Start your platform","text":"<p>Start your platform, using the new indices.</p> <p>Rollover documentation</p> <p>To have more details about automatic rollover and lifecycle policies, please read the official ElasticSearch documentation.</p>"},{"location":"deployment/troubleshooting/","title":"Troubleshooting","text":"<p>This page aims to explains the typical errors you can have with your OpenCTI platform.</p>"},{"location":"deployment/troubleshooting/#finding-the-relevant-logs","title":"Finding the relevant logs","text":"<p>It is highly recommended to monitor the error logs of the platforms, workers and connectors. All the components have log outputs in an understandable JSON format. It necessary, it is always possible to increase the log level. In production, it is recommended to have the log level set to <code>error</code>.</p>"},{"location":"deployment/troubleshooting/#platform","title":"Platform","text":"<p>Here are some useful parameters for platform logging:</p> <pre><code>- APP__APP_LOGS__LOGS_LEVEL=[error|warning|info|debug]\n- APP__APP_LOGS__LOGS_CONSOLE=true # Output in the container console\n</code></pre>"},{"location":"deployment/troubleshooting/#connectors","title":"Connectors","text":"<p>All connectors support the same set of parameters to manage the log level and outputs:</p> <pre><code>- OPENCTI_JSON_LOGGING=true # Enable / disable JSON logging\n- CONNECTOR_LOG_LEVEL=info=[error|warning|info|debug]\n</code></pre>"},{"location":"deployment/troubleshooting/#workers","title":"Workers","text":"<p>The workers can have more or less verbose outputs:</p> <pre><code>- OPENCTI_JSON_LOGGING=true # Enable / disable JSON logging\n- WORKER_LOG_LEVEL=[error|warning|info|debug]\n</code></pre>"},{"location":"deployment/troubleshooting/#common-errors","title":"Common errors","text":""},{"location":"deployment/troubleshooting/#ingestion-technical-errors","title":"Ingestion technical errors","text":"<p>Missing reference to handle creation</p> <p>After 5 retries, if an element required to create another element is missing, the platform raises an exception. It usually comes from a connector that generates inconsistent STIX 2.1 bundles.</p> <p>Cant upsert entity. Too many entities resolved</p> <p>OpenCTI received an entity which is matching too many other entities in the platform. In this condition we cannot take a decision. We need to dig into the data bundle to identify why he match too much entities and fix the data in the bundle / or the platform according to what you expect.</p> <p>Execution timeout, too many concurrent call on the same entities</p> <p>The platform supports multi workers and multiple parallel creation but different parameters can lead to some locking timeout in the execution. </p> <ul> <li>Throughput capacity of your ElasticSearch</li> <li>Number of workers started at the same time</li> <li>Dependencies between data</li> <li>Merging capacity of OpenCTI</li> </ul> <p>If you have this kind of error, limit the number of workers deployed. Try to find the right balance of the number of workers, connectors and elasticsearch sizing.</p>"},{"location":"deployment/troubleshooting/#ingestion-functional-errors","title":"Ingestion functional errors","text":"<p>Indicator of type yara is not correctly formatted</p> <p>OpenCTI check the validity of the indicator rule.</p> <p>Observable of type IPv4-Addr is not correctly formatted</p> <p>OpenCTI check the validity of the oversable value.</p>"},{"location":"deployment/troubleshooting/#dependencies-errors","title":"Dependencies errors","text":"<p>TOO_MANY_REQUESTS/12/disk usage exceeded flood-stage watermark...</p> <p>Disk full, no space left on the device for ElasticSearch.</p>"},{"location":"deployment/upgrade/","title":"Upgrade","text":"<p>Depending on your installation mode, upgrade path may change.</p> <p>Migrations</p> <p>The platform is taking care of all necessary underlying migrations in the databases if any, you can upgrade OpenCTI from any version to the latest one, including skipping multiple major releases.</p>"},{"location":"deployment/upgrade/#using-docker","title":"Using Docker","text":"<p>Before applying this procedure, please update your <code>docker-compose.yml</code> file with the new version number of container images.</p>"},{"location":"deployment/upgrade/#for-single-node-docker","title":"For single node Docker","text":"<pre><code>$ sudo docker-compose stop\n$ sudo docker-compose pull\n$ sudo docker-compose up -d\n</code></pre>"},{"location":"deployment/upgrade/#for-docker-swarm","title":"For Docker swarm","text":"<p>For each of services, you have to run the following command:</p> <pre><code>$ sudo docker service update --force service_name\n</code></pre>"},{"location":"deployment/upgrade/#manual-installation","title":"Manual installation","text":"<p>When upgrading the platform, you have to replace all files and restart the platform, the database migrations will be done automatically:</p> <pre><code>$ yarn serv\n</code></pre>"},{"location":"development/api-usage/","title":"GraphQL API and playground","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"development/connectors/","title":"Connector development","text":""},{"location":"development/connectors/#introduction","title":"Introduction","text":"<p>A connector in OpenCTI is a service that runs next to the platform and can be implemented in almost any programming language that has STIX2 support. Connectors are used to extend the functionality of OpenCTI and allow operators to shift some of the processing workload to external services. To use the conveniently provided OpenCTI connector SDK you need to use Python3 at the moment.</p> <p>We choose to have a very decentralized approach on connectors, in order to bring a maximum freedom to developers and vendors. So a connector on OpenCTI can be defined by a standalone Python 3 process that pushes an understandable format of data to an ingestion queue of messages.</p> <p>Each connector must implement a long-running process that can be launched just by executing the main Python file. The only mandatory dependency is the <code>OpenCTIConnectorHelper</code> class that enables the connector to send data to OpenCTI.</p>"},{"location":"development/connectors/#getting-started","title":"Getting started","text":"<p>In the beginning first think about your use-case to choose and appropriate connector type - what do want to achieve with your connector? The following table gives you an overview of the current connector types and some typical use-cases:</p> <p>Connector types</p> Type Typical use cases Example connector EXTERNAL_IMPORT Integrate external TI provider, Integrate external TI platform AlienVault INTERNAL_ENRICHMENT Enhance existing data with additional knowledge AbuseIP INTERNAL_IMPORT_FILE (Bulk) import knowledge from files Import document INTERNAL_EXPORT_FILE (Bulk) export knowledge to files STIX 2.1, CSV. STREAM Integrate external TI provider, Integrate external TI platform Elastic Security <p>After you've selected your connector type make yourself familiar with STIX2 and the supported relationships in OpenCTI. Having some knowledge about the internal data models with help you a lot with the implementation of your idea.</p>"},{"location":"development/connectors/#preparation","title":"Preparation","text":""},{"location":"development/connectors/#environment-setup","title":"Environment Setup","text":"<p>To develop and test your connector, you need a running OpenCTI instance with the frontend and the messaging broker accessible. If you don't plan on developing anything for the OpenCTI platform or the frontend, the easiest setup for the connector development is using the docker setup, For more details see here.</p>"},{"location":"development/connectors/#coding-setup","title":"Coding Setup","text":"<p>To give you an easy starting point we prepared an example connector in the public repository you can use as template to bootstrap your development.</p> <p>Some prerequisites we recommend to follow this tutorial:</p> <ul> <li>Code editor with good Python3 support (e.g. Visual Studio Code with the Python extension pack)</li> <li>Python3 + setuptools is installed and configured</li> <li>Command shell (either Linux/Mac terminal or WSL on Windows)</li> </ul> <p>In the terminal check out the connectors repository and copy the template connector to <code>$myconnector</code> (replace it with your name throughout the following text examples).</p> <pre><code>$ pip3 install black flake8 pycti\n# Fork the current repository, then clone your fork\n$ git clone https://github.com/YOUR-USERNAME/connectors.git\n$ cd connectors\n$ git remote add upstream https://github.com/OpenCTI-Platform/connectors.git\n# Create a branch for your feature/fix\n$ git checkout -b [branch-name]\n$ cp -r template $connector_type/$myconnector\n$ cd $connector_type/$myconnector\n$ tree .\n.\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 entrypoint.sh\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 src\n    \u251c\u2500\u2500 config.yml.sample\n    \u251c\u2500\u2500 main.py\n    \u2514\u2500\u2500 requirements.txt\n\n1 directory, 7 files\n</code></pre>"},{"location":"development/connectors/#changing-the-template","title":"Changing the template","text":"<p>There are a few files in the template we need to change for our connector to be unique. You can check for all places you need to change you connector name with the following command (the output will look similar):</p> <pre><code>$ grep -Ri template .\n\nREADME.md:# OpenCTI Template Connector\nREADME.md:| `connector_type`                     | `CONNECTOR_TYPE`                    | Yes          | Must be `Template_Type` (this is the connector type).                                                                                                      |\nREADME.md:| `connector_name`                     | `CONNECTOR_NAME`                    | Yes          | Option `Template`                                                                                                                                          |\nREADME.md:| `connector_scope`                    | `CONNECTOR_SCOPE`                   | Yes          | Supported scope: Template Scope (MIME Type or Stix Object)                                                                                                 |\nREADME.md:| `template_attribute`                 | `TEMPLATE_ATTRIBUTE`                | Yes          | Additional setting for the connector itself                                                                                                                |\ndocker-compose.yml:  connector-template:\ndocker-compose.yml:    image: opencti/connector-template:4.5.5\ndocker-compose.yml:      - CONNECTOR_TYPE=Template_Type\ndocker-compose.yml:      - CONNECTOR_NAME=Template\ndocker-compose.yml:      - CONNECTOR_SCOPE=Template_Scope # MIME type or Stix Object\nentrypoint.sh:cd /opt/opencti-connector-template\nDockerfile:COPY src /opt/opencti-template\nDockerfile:    cd /opt/opencti-connector-template &amp;&amp; \\\nsrc/main.py:class Template:\nsrc/main.py:            \"TEMPLATE_ATTRIBUTE\", [\"template\", \"attribute\"], config, True\nsrc/main.py:        connectorTemplate = Template()\nsrc/main.py:        connectorTemplate.run()\nsrc/config.yml.sample:  type: 'Template_Type'\nsrc/config.yml.sample:  name: 'Template'\nsrc/config.yml.sample:  scope: 'Template_Scope' # MIME type or SCO\n</code></pre> <p>Required changes:</p> <ul> <li> Change <code>Template</code> or <code>template</code>mentions to your connector name e.g. <code>ImportCsv</code> or <code>importcsv</code></li> <li> Change <code>TEMPLATE</code> mentions to your connector name e.g. <code>IMPORTCSV</code></li> <li> Change <code>Template_Scope</code> mentions to the required scope of your connector. For processing imported files, that can be the Mime type e.g. <code>application/pdf</code> or for enriching existing information in OpenCTI, define the STIX object's name e.g. <code>Report</code>. Multiple scopes can be separated by a simple <code>,</code></li> <li> Change <code>Template_Type</code> to the connector type you wish to develop. The OpenCTI types (OpenCTI flags) are defined in this table.</li> </ul>"},{"location":"development/connectors/#development","title":"Development","text":""},{"location":"development/connectors/#initialize-the-opencti-connector-helper","title":"Initialize the OpenCTI connector helper","text":"<p>After getting the configuration parameters of your connector, you have to initialize the OpenCTI connector helper by using the <code>pycti</code> Python library. This is shown in the following example:</p> <pre><code>class TemplateConnector:\ndef __init__(self):\n# Instantiate the connector helper from config\nconfig_file_path = os.path.dirname(os.path.abspath(__file__)) + \"/config.yml\"\nconfig = (\nyaml.load(open(config_file_path), Loader=yaml.SafeLoader)\nif os.path.isfile(config_file_path)\nelse {}\n)\nself.helper = OpenCTIConnectorHelper(config)\nself.custom_attribute = get_config_variable(\n\"TEMPLATE_ATTRIBUTE\", [\"template\", \"attribute\"], config\n)\n</code></pre> <p>Since there are some basic differences in the tasks of the different connector classes, the structure is also a bit class dependent. While the external-import and the stream connector run independently in a regular interval or constantly, the other 3 connector classes only run when being requested by the OpenCTI platform.</p> <p>The self-triggered connectors run independently, but the OpenCTI need to define a callback function, which can be executed for the connector to start its work. This is done via         <code>self.helper.listen(self._process_message)</code> . In the appended examples, the difference of the setup can be seen.</p> <p>Self-triggered Connectors</p> <ul> <li>external-import</li> <li>stream</li> </ul> <p>OpenCTI triggered</p> <ul> <li>internal-enrichment</li> <li>internal-import</li> <li>internal-export</li> </ul> <pre><code>from pycti import OpenCTIConnectorHelper, get_config_variable\nclass TemplateConnector:\ndef __init__(self) -&gt; None:\n# Initialization procedures\n[...]\nself.template_interval = get_config_variable(\n\"TEMPLATE_INTERVAL\", [\"template\", \"interval\"], config, True\n)\ndef get_interval(self) -&gt; int:\nreturn int(self.template_interval) * 60 * 60 * 24\ndef run(self) -&gt; None:\n# Main procedure\nif __name__ == \"__main__\":\ntry:\ntemplate_connector = TemplateConnector()\ntemplate_connector.run()\nexcept Exception as e:\nprint(e)\ntime.sleep(10)\nexit(0)\n</code></pre> <pre><code>from pycti import OpenCTIConnectorHelper, get_config_variable\nclass TemplateConnector:\ndef __init__(self) -&gt; None:\n# Initialization procedures\n[...]\ndef _process_message(self, data: dict) -&gt; str:\n# Main procedure                \n# Start the main loop\ndef start(self) -&gt; None:\nself.helper.listen(self._process_message)\nif __name__ == \"__main__\":\ntry:\ntemplate_connector = TemplateConnector()\ntemplate_connector.start()\nexcept Exception as e:\nprint(e)\ntime.sleep(10)\nexit(0)\n</code></pre>"},{"location":"development/connectors/#write-and-read-operations","title":"Write and Read Operations","text":"<p>When using the <code>OpenCTIConnectorHelper</code> class, there are two way for reading from or writing data to the OpenCTI platform.</p> <ol> <li>via the OpenCTI API interface via <code>self.helper.api</code></li> <li>via the OpenCTI worker via <code>self.send_stix2_bundle</code></li> </ol>"},{"location":"development/connectors/#sending-data-to-the-opencti-platform","title":"Sending data to the OpenCTI platform","text":"<p>The recommended way for creating or updating data in the OpenCTI platform is via the OpenCTI worker. This enables the connector to just send and forget about thousands of entities at once to without having to think about the ingestion order, performance or error handling.</p>  \u26a0\ufe0f **Please DO NOT use the api interface to create new objects in connectors.**   <p>The OpenCTI connector helper method <code>send_stix2_bundle</code> must be used to send data to OpenCTI. The <code>send_stix2_bundle</code> function takes 2 arguments.</p> <ol> <li>A serialized STIX2 bundle as a <code>string</code> (mandatory)</li> <li>A <code>list</code> of entities types that should be ingested (optional)</li> </ol> <p>Here is an example using the STIX2 Python library:</p> <pre><code>from stix2 import Bundle, AttackPattern\n[...]\nattack_pattern = AttackPattern(name='Evil Pattern')\nbundle_objects = []\nbundle_objects.append(attack_pattern)\nbundle = Bundle(objects=bundle_objects).serialize()\nbundles_sent = self.opencti_connector_helper.send_stix2_bundle(bundle)\n</code></pre>"},{"location":"development/connectors/#reading-from-the-opencti-platform","title":"Reading from the OpenCTI platform","text":"<p>Read queries to the OpenCTI platform can be achieved using the API and the STIX IDs can be attached to reports to create the relationship between those two entities.</p> <pre><code>entity = self.helper.api.vulnerability.read(\nfilters={\"key\": \"name\", \"values\": [\"T1234\"]}\n)\n</code></pre> <p>If you want to add the found entity via <code>objects_refs</code> to another SDO, simple add a list of <code>stix_ids</code> to the SDO. Here's an example using the entity from the code snippet above:</p> <pre><code>from stix2 import Report\n[...]\nreport = Report(\nid=report[\"standard_id\"],\nobject_refs=[entity[\"standard_id\"]],\n)\n</code></pre>"},{"location":"development/connectors/#logging","title":"Logging","text":"<p>When something crashes at a user's, you as a developer want to know as much as possible about this incident to easily improve your code and remove this issue. To do so, it is very helpful if your connector documents what it does. Use <code>info</code> messages for big changes like the beginning or the finishing of an operation, but to facilitate your bug removal attempts, implement <code>debug</code> messages for minor operation changes to document different steps in your code.</p> <p>When encountering a crash, the connector's user can easily restart the troubling connector with the debug logging activated.</p> <ul> <li><code>CONNECTOR_LOG_LEVEL=debug</code></li> </ul> <p>Using those additional log messages, the bug report is more enriched with information about the possible cause of the problem. Here's an example of how the logging should be implemented:</p> <pre><code>        def run(self) -&gt; None:\nself.helper.log_info('Template connector starts')\nresults = self._ask_for_news()\n[...]\ndef _ask_for_news() -&gt; None:\noverall = []\nfor i in range(0, 10):\nself.log_debug(f\"Asking about news with count '{i}'\")\n# Do something\nself.log_debug(f\"Resut: '{result}'\")\noverall.append(result)\nreturn overall\n</code></pre> <p>Please make sure that the debug messages rich of useful information, but that they are not redundant and that the user is not drowned by unnecessary information.</p>"},{"location":"development/connectors/#additional-implementations","title":"Additional implementations","text":"<p>If you are still unsure about how to implement certain things in your connector, we advise you to have a look at the code of other connectors of the same type. Maybe they are already using approach which is suitable for addressing to your problem.</p>"},{"location":"development/connectors/#opencti-triggered-connector-special-cases","title":"OpenCTI triggered Connector - Special cases","text":""},{"location":"development/connectors/#data-layout-of-dictionary-from-callback-function","title":"Data Layout of Dictionary from Callback function","text":"<p>OpenCTI sends the connector a few instructions via the <code>data</code> dictionary in the callback function. Depending on the connector type, the data dictionary content is a bit different. Here are a few examples for each connector type.</p> <p>Internal Import Connector</p> <p>Internal Enrichment Connector</p> <pre><code>{ \"file_id\": \"&lt;fileId&gt;\",\n\"file_mime\": \"application/pdf\", \"file_fetch\": \"storage/get/&lt;file_id&gt;\", // Path to get the file\n\"entity_id\": \"report--82843863-6301-59da-b783-fe98249b464e\", // Context of the upload\n}\n</code></pre> <pre><code>{ \"entity_id\": \"&lt;stixCoreObjectId&gt;\" // StixID of the object wanting to be enriched\n}\n</code></pre> <p>Internal Export Connector</p> <pre><code>{ \"export_scope\": \"single\", // 'single' or 'list'\n\"export_type\": \"simple\", // 'simple' or 'full'\n\"file_name\": \"&lt;fileName&gt;\", // Export expected file name\n\"max_marking\": \"&lt;maxMarkingId&gt;\", // Max marking id\n\"entity_type\": \"AttackPattern\", // Exported entity type\n// ONLY for single entity export\n\"entity_id\": \"&lt;entity.id&gt;\", // Exported element\n// ONLY for list entity export\n\"list_params\": \"[&lt;parameters&gt;]\" // Parameters for finding entities\n}\n</code></pre>"},{"location":"development/connectors/#self-triggered-connector-special-cases","title":"Self triggered Connector - Special cases","text":""},{"location":"development/connectors/#initiating-a-work-before-pushing-data","title":"Initiating a 'Work' before pushing data","text":"<p>For self-triggered connectors, OpenCTI has to be told about new jobs to process and to import. This is done by registering a so called <code>work</code> before sending the stix bundle and signalling the end of a work. Here an example:</p> <p>By implementing the work registration, they will show up as shown in this screenshot for the MITRE ATT&amp;CK connector:</p> <pre><code>def run() -&gt; None:\n# Anounce upcoming work\ntimestamp = int(time.time())\nnow = datetime.utcfromtimestamp(timestamp)\nfriendly_name = \"Template run @ \" + now.strftime(\"%Y-%m-%d %H:%M:%S\")\nwork_id = self.helper.api.work.initiate_work(\nself.helper.connect_id, friendly_name\n)\n[...]\n# Send Stix bundle\nself.helper.send_stix2_bundle(\nbundle,\nentities_types=self.helper.connect_scope,\nupdate=True,\nwork_id=work_id,\n)\n# Finish the work\nself.helper.log_info(\nf\"Connector successfully run, storing last_run as {str(timestamp)}\"\n)              \nmessage = \"Last_run stored, next run in: {str(round(self.get_interval() / 60 / 60 / 24, 2))} days\"\nself.helper.api.work.to_processed(work_id, message)\n</code></pre>"},{"location":"development/connectors/#interval-handling","title":"Interval handling","text":"<p>The connector is also responsible for making sure that it runs in certain intervals. In most cases, the intervals are definable in the connector config and then only need to be set and updated during the runtime.</p> <pre><code>class TemplateConnector:\ndef __init__(self) -&gt; None:\n# Initialization procedures\n[...]\nself.template_interval = get_config_variable(\n\"TEMPLATE_INTERVAL\", [\"template\", \"interval\"], config, True\n)\ndef get_interval(self) -&gt; int:\nreturn int(self.template_interval) * 60 * 60 * 24\ndef run(self) -&gt; None:\nself.helper.log_info(\"Fetching knowledge...\")\nwhile True:\ntry:\n# Get the current timestamp and check\ntimestamp = int(time.time())\ncurrent_state = self.helper.get_state()\nif current_state is not None and \"last_run\" in current_state:\nlast_run = current_state[\"last_run\"]\nself.helper.log_info(\n\"Connector last run: \"\n+ datetime.utcfromtimestamp(last_run).strftime(\n\"%Y-%m-%d %H:%M:%S\"\n)\n)\nelse:\nlast_run = None\nself.helper.log_info(\"Connector has never run\")\n# If the last_run is more than interval-1 day\nif last_run is None or (\n(timestamp - last_run)\n&gt; ((int(self.template_interval) - 1) * 60 * 60 * 24)\n):\ntimestamp = int(time.time())\nnow = datetime.utcfromtimestamp(timestamp)\nfriendly_name = \"Connector run @ \" + now.strftime(\"%Y-%m-%d %H:%M:%S\")\n###\n# RUN CODE HERE     \n###\n# Store the current timestamp as a last run\nself.helper.log_info(\n\"Connector successfully run, storing last_run as \"\n+ str(timestamp)\n)\nself.helper.set_state({\"last_run\": timestamp})\nmessage = (\n\"Last_run stored, next run in: \"\n+ str(round(self.get_interval() / 60 / 60 / 24, 2))\n+ \" days\"\n)\nself.helper.api.work.to_processed(work_id, message)\nself.helper.log_info(message)\ntime.sleep(60)\nelse:\nnew_interval = self.get_interval() - (timestamp - last_run)\nself.helper.log_info(\n\"Connector will not run, next run in: \"\n+ str(round(new_interval / 60 / 60 / 24, 2))\n+ \" days\"\n)\ntime.sleep(60)\n</code></pre>"},{"location":"development/connectors/#running-the-connector","title":"Running the connector","text":"<p>For development purposes, it is easier to simply run the python script locally until everything works as it sould.</p> <pre><code>$ virtualenv env\n$ source ./env/bin/activate\n$ pip3 install -r requirements\n$ cp config.yml.sample config.yml\n# Define the opencti url and token, as well as the connector's id\n$ vim config.yml\n$ python3 main.py\nINFO:root:Listing Threat-Actors with filters null.\nINFO:root:Connector registered with ID: a2de809c-fbb9-491d-90c0-96c7d1766000\nINFO:root:Starting ping alive thread\n...\n</code></pre>"},{"location":"development/connectors/#final-testing","title":"Final Testing","text":"<p>Before submitting a Pull Request, please test your code for different use cases and scenarios. We don't have an automatic testing suite for the connectors yet, thus we highly depend on developers thinking about creative scenarios their code could encounter.</p>"},{"location":"development/connectors/#prepare-for-release","title":"Prepare for release","text":"<p>If you plan to provide your connector to be used by the community (\u2764\ufe0f) your code should pass the following (minimum) criteria.</p> <pre><code># Linting with flake8 contains no errors or warnings\n$ flake8 --ignore=E,W\n# Verify formatting with black\n$ black .\nAll done! \u2728 \ud83c\udf70 \u2728\n1 file left unchanged.\n# Push you feature/fix on Github\n$ git add [file(s)]\n$ git commit -m \"[connector_name] descriptive message\"\n$ git push origin [branch-name]\n# Open a pull request with the title \"[connector_name] message\"\n</code></pre> <p>If you have any trouble with this just reach out to the OpenCTI core team. We are happy to assist with this.</p>"},{"location":"development/environment_ubuntu/","title":"Prerequisites Ubuntu","text":"<p>Development stack require some base software that need to be installed.</p>"},{"location":"development/environment_ubuntu/#docker-or-podman","title":"Docker or podman","text":"<p>Platform dependencies in development are deployed through container management, so you need to install a container stack.</p> <p>We currently support docker and postman.</p> <pre><code>$ sudo apt-get install docker docker-compose curl\n</code></pre> <p>As OpenCTI has a dependency to ElasticSearch, you have to set the vm.max_map_count before running the containers, as mentioned in the ElasticSearch documentation.</p> <pre><code>$ sudo sysctl -w vm.max_map_count=262144\n</code></pre>"},{"location":"development/environment_ubuntu/#nodejs-and-yarn","title":"NodeJS and yarn","text":"<p>The platform is developed on nodejs technology, so you need to install node and the yarn package manager.</p> <pre><code>$ sudo apt-get install nodejs\n$ sudo curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -\n$ sudo echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n$ sudo apt-get update &amp;&amp; sudo apt-get install yarn\n</code></pre>"},{"location":"development/environment_ubuntu/#python-runtime","title":"Python runtime","text":"<p>For worker and connectors, a python runtime is needed.</p> <pre><code>$ sudo apt-get install python3 python3-pip\n</code></pre>"},{"location":"development/environment_ubuntu/#git-and-dev-tool","title":"Git and dev tool","text":"<ul> <li>Install Git from apt</li> </ul> <pre><code>$ sudo apt-get install git-all\n</code></pre> <ul> <li>Install your preferred IDE<ul> <li>Intellij community edition - https://www.jetbrains.com/idea/download/</li> <li>VSCode - https://code.visualstudio.com/</li> </ul> </li> </ul>"},{"location":"development/environment_windows/","title":"Prerequisites Windows","text":"<p>Development stack require some base software that need to be installed.</p>"},{"location":"development/environment_windows/#docker-or-podman","title":"Docker or podman","text":"<p>Platform dependencies in development are deployed through container management, so you need to install a container stack.</p> <p>We currently support docker and postman.</p> <p>Docker Desktop from - https://docs.docker.com/desktop/install/windows-install/</p> <ul> <li>Install new version of - https://docs.microsoft.com/windows/wsl/wsl2-kernel. This will require a reboot.</li> <li>Shell out to CMD as Administrator and run the following powershell command: </li> </ul> <p><code>wsl --set-default-version 2</code></p> <ul> <li>Reboot computer and continue to next step       </li> <li>Load Docker Application</li> <li>NOTE DOCKER LICENSE - You are agreeing to the licence for Non-commercial Open Source Project use. OpenCTI is Open Source and the version you would be possibly contributing to enhancing is the unpaid non-commercial/non-enterprise version. If you intention is different - please consult with your organization's legal/licensing department.</li> <li>Leave Docker Desktop running</li> </ul>"},{"location":"development/environment_windows/#nodejs-and-yarn","title":"NodeJS and yarn","text":"<p>The platform is developed on nodejs technology, so you need to install node and the yarn package manager.</p> <ul> <li>Install NodeJS from - https://nodejs.org/download/release/v16.20.0/node-v16.20.0-x64.msi</li> <li>Select the option for installing Chocolatey on the Tools for Native Modules screen<ul> <li>Will do this install for you automatically - https://chocolatey.org/packages/visualstudio2019-workload-vctools</li> <li>Includes Python 3.11.4</li> </ul> </li> <li> <p>Shell out to CMD prompt as Administrator and install/run:</p> <ul> <li><code>pip3 install pywin32</code></li> </ul> </li> <li> <p>Configure Yarn (https://yarnpkg.com/getting-started/install)</p> </li> <li>Open CMD as Administrator and run the following command:<ul> <li><code>corepack enable</code></li> </ul> </li> </ul>"},{"location":"development/environment_windows/#python-runtime","title":"Python runtime","text":"<p>For worker and connectors, a python runtime is needed. Even if you already have a python runtime installed through node installation,  on windows some nodejs package will be recompiled with python and C++ runtime. </p> <p>For this reason Visual Studio Build Tools is required.</p> <ul> <li>Install Visual Studio Build Tools from - https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=BuildTools</li> <li>Check off Desktop Development with C++</li> <li>Run install</li> </ul>"},{"location":"development/environment_windows/#git-and-dev-tool","title":"Git and dev tool","text":"<ul> <li>Download GIT for Windows (64-bit Setup)- https://git-scm.com/download/win</li> <li> <p>Just use defaults on each screen</p> </li> <li> <p>Install your preferred IDE</p> </li> <li>Intellij community edition - https://www.jetbrains.com/idea/download/</li> <li>VSCode - https://code.visualstudio.com/docs/?dv=win64</li> </ul>"},{"location":"development/platform/","title":"Platform development","text":""},{"location":"development/platform/#introduction","title":"Introduction","text":"<p>This summary should give you a detailed setup description for initiating the OpenCTI setup environment  necessary for developing on the OpenCTI platform, a client library or the connectors.  This page document how to set up an \"All-in-One\" development environment for OpenCTI.  The devenv will contain data of 3 different repositories:</p> <ul> <li>Platform: https://github.com/OpenCTI-Platform/opencti</li> <li>Connectors: https://github.com/OpenCTI-Platform/connectors</li> <li>Client python: https://github.com/OpenCTI-Platform/client-python</li> </ul>"},{"location":"development/platform/#platform","title":"Platform","text":"<p>Contains the platform OpenCTI project code base:</p> <ul> <li>docker-compose (docker or podman) <code>~/opencti/opencti-platform/opencti-dev</code></li> <li>Web frontend (nodejs / react) <code>~/opencti/opencti-platform/opencti-graphql</code></li> <li>Backend (nodejs) <code>~/opencti/opencti-platform/opencti-frontend</code></li> <li>Worker (nodejs / python) <code>~/opencti/opencti-worker</code></li> </ul>"},{"location":"development/platform/#connectors","title":"Connectors","text":"<p>Contains a lot of developed connectors, as a source of inspiration for your new connector.</p>"},{"location":"development/platform/#client-python","title":"Client python","text":"<p>Contains the source code of the python library used in worker or connectors.</p>"},{"location":"development/platform/#prerequisites","title":"Prerequisites","text":"<p>Some tools are needed before starting to develop. Please check Ubuntu prerequisites or Windows prerequisites</p>"},{"location":"development/platform/#clone-the-projects","title":"Clone the projects","text":"<p>Fork and clone the git repositories</p> <ul> <li>https://github.com/OpenCTI-Platform/opencti/ - frontend / backend</li> <li>https://github.com/OpenCTI-Platform/connectors - connectors</li> <li>https://github.com/OpenCTI-Platform/docker - docker stack</li> <li>https://github.com/OpenCTI-Platform/client-python/ - python client</li> </ul>"},{"location":"development/platform/#dependencies-containers","title":"Dependencies containers","text":"<p>In development dependencies are deployed trough containers. A development compose file is available in <code>~/opencti/opencti-platform/opencti-dev</code></p> <pre><code>cd ~/docker\n#Start the stack in background\ndocker-compose -f ./docker-compose-dev.yml up -d\n</code></pre> <p>You have now all the dependencies of OpenCTI running and waiting for product to run.</p>"},{"location":"development/platform/#backend-api","title":"Backend / API","text":""},{"location":"development/platform/#python-virtual-env","title":"Python virtual env","text":"<p>The GraphQL API is developed in JS and with some python code.  As it's an \"all-in-one\" installation, the python environment will be installed in a virtual environment.</p> <pre><code>cd ~/opencti/opencti-platform/opencti-graphql\npython3 -m venv .venv --prompt \"graphql\"\nsource .venv/bin/activate\npip install --upgrade pip wheel setuptools\nyarn install\nyarn install:python deactivate\n</code></pre>"},{"location":"development/platform/#development-configuration","title":"Development configuration","text":"<p>The API can be specifically configured with files depending on the starting profile. By default, the default.json file is used and will be correctly configured for local usage except for admin password</p> <p>So you need to create a development profile file. You can duplicate the default file and adapt if for you need. <pre><code>cd ~/opencti/opencti-platform/opencti-graphql/config\ncp default.json development.json\n</code></pre></p> <p>At minimum adapt the admin part for the password and token. <pre><code>    \"admin\": {\n\"email\": \"admin@opencti.io\",\n\"password\": \"MyNewPassord\",\n\"token\": \"UUID generated with https://www.uuidgenerator.net\"\n}\n</code></pre></p>"},{"location":"development/platform/#install-start","title":"Install / start","text":"<p>Before starting the backend you need to install the nodejs modules</p> <pre><code>cd ~/opencti/opencti-platform/opencti-graphql\nyarn install\n</code></pre> <p>Then you can simply start the backend API with the yarn start command</p> <pre><code>cd ~/opencti/opencti-platform/opencti-graphql\nyarn start\n</code></pre> <p>The platform will start logging some interesting information</p> <pre><code>{\"category\":\"APP\",\"level\":\"info\",\"message\":\"[OPENCTI] Starting platform\",\"timestamp\":\"2023-07-02T16:37:10.984Z\",\"version\":\"5.8.7\"}\n{\"category\":\"APP\",\"level\":\"info\",\"message\":\"[OPENCTI] Checking dependencies statuses\",\"timestamp\":\"2023-07-02T16:37:10.987Z\",\"version\":\"5.8.7\"}\n{\"category\":\"APP\",\"level\":\"info\",\"message\":\"[SEARCH] Elasticsearch (8.5.2) client selected / runtime sorting enabled\",\"timestamp\":\"2023-07-02T16:37:11.014Z\",\"version\":\"5.8.7\"}\n{\"category\":\"APP\",\"level\":\"info\",\"message\":\"[CHECK] Search engine is alive\",\"timestamp\":\"2023-07-02T16:37:11.015Z\",\"version\":\"5.8.7\"}\n...\n{\"category\":\"APP\",\"level\":\"info\",\"message\":\"[INIT] Platform initialization done\",\"timestamp\":\"2023-07-02T16:37:11.622Z\",\"version\":\"5.8.7\"}\n{\"category\":\"APP\",\"level\":\"info\",\"message\":\"[OPENCTI] API ready on port 4000\",\"timestamp\":\"2023-07-02T16:37:12.382Z\",\"version\":\"5.8.7\"}\n</code></pre> <p>If you want to start on another profile you can use the -e parameter. For example here to use the profile.json configuration file.</p> <pre><code>yarn start -e profile\n</code></pre>"},{"location":"development/platform/#code-check","title":"Code check","text":"<p>Before pushing your code you need to validate the syntax and ensure the testing will be validated.</p>"},{"location":"development/platform/#for-validation","title":"For validation","text":"<p><code>yarn lint</code></p> <p><code>yarn check-ts</code></p>"},{"location":"development/platform/#for-testing","title":"For testing","text":"<p>For starting the test you will need to create a test.json file. You can use the same dependencies by only adapting all prefix for all dependencies.</p> <p><code>yarn test:dev</code></p>"},{"location":"development/platform/#frontend","title":"Frontend","text":""},{"location":"development/platform/#install-start_1","title":"Install / start","text":"<p>Before starting the backend you need to install the nodejs modules</p> <pre><code>cd ~/opencti/opencti-platform/opencti-front\nyarn install\n</code></pre> <p>Then you can simply start the frontend with the yarn start command</p> <pre><code>cd ~/opencti/opencti-platform/opencti-front\nyarn start\n</code></pre> <p>The frontend will start with some interesting information</p> <pre><code>[INFO] [default] compiling...\n[INFO] [default] compiled documents: 1592 reader, 1072 normalization, 1596 operation text\n[INFO] Compilation completed.\n[INFO] Done.\n[HPM] Proxy created: /stream  -&gt; http://localhost:4000\n[HPM] Proxy created: /storage  -&gt; http://localhost:4000\n[HPM] Proxy created: /taxii2  -&gt; http://localhost:4000\n[HPM] Proxy created: /feeds  -&gt; http://localhost:4000\n[HPM] Proxy created: /graphql  -&gt; http://localhost:4000\n[HPM] Proxy created: /auth/**  -&gt; http://localhost:4000\n[HPM] Proxy created: /static/flags/**  -&gt; http://localhost:4000\n</code></pre> <p>The web UI should be accessible on http://127.0.0.1:3000</p>"},{"location":"development/platform/#code-check_1","title":"Code check","text":"<p>Before pushing your code you need to validate the syntax and ensure the testing will be validated.</p>"},{"location":"development/platform/#for-validation_1","title":"For validation","text":"<p><code>yarn lint</code></p> <p><code>yarn check-ts</code></p>"},{"location":"development/platform/#for-testing_1","title":"For testing","text":"<p><code>yarn test</code></p>"},{"location":"development/platform/#worker","title":"Worker","text":"<p>Running a worker is required when you want to develop on the ingestion or import/export connectors.</p>"},{"location":"development/platform/#python-virtual-env_1","title":"Python virtual env","text":"<pre><code>cd ~/opencti/opencti-worker/src\npython3 -m venv .venv --prompt \"worker\"\nsource .venv/bin/activate\npip3 install --upgrade pip wheel setuptools\npip3 install -r requirements.txt\ndeactivate\n</code></pre>"},{"location":"development/platform/#install-start_2","title":"Install / start","text":"<pre><code>cd ~/opencti/opencti-worker/src\nsource .venv/bin/activate\npython worker.py\n</code></pre>"},{"location":"development/platform/#connectors_1","title":"Connectors","text":"<p>For connectors development, please take a look to Connectors development dedicated page.</p>"},{"location":"development/platform/#production-build","title":"Production build","text":"<p>Based on development source you can build the package for production. This package will be minified and optimized with esbuild.</p> <pre><code>$ cd opencti-frontend\n$ yarn build\n$ cd ../opencti-graphql\n$ yarn build\n</code></pre> <p>After the build you can start the production build with yarn serv. This build will use the production.json configuration file</p> <pre><code>$ cd ../opencti-graphql\n$ yarn serv\n</code></pre>"},{"location":"development/python/","title":"Python library","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"reference/api/","title":"Knowledge graph","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"reference/csv-feeds/","title":"CSV feeds","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"reference/data-intelligence/","title":"Data intelligence","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"reference/data-model/","title":"Data model","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"reference/graph/","title":"Knowledge graph","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"reference/security/","title":"Security","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"reference/streaming/","title":"Data Streaming","text":""},{"location":"reference/streaming/#presentation","title":"Presentation","text":"<p>In order to provide a real time way to consume STIX CTI information, OpenCTI provides data events in a stream that can be consume to react on creation, update, deletion and merge. This way of getting information out of OpenCTI is highly efficient and already use by some connectors.</p>"},{"location":"reference/streaming/#technology","title":"Technology","text":""},{"location":"reference/streaming/#redis-stream","title":"Redis stream","text":"<p>OpenCTI is currently using REDIS Stream (See https://redis.io/topics/streams-intro) as the technical layer. Each time something is modified in the OpenCTI database, a specific event is added in the stream.</p>"},{"location":"reference/streaming/#sse-protocol","title":"SSE protocol","text":"<p>In order to provides a really easy consuming protocol we decide to provide a SSE (https://fr.wikipedia.org/wiki/Server-sent_events) http URL linked to the standard login system of OpenCTI. Any user with the correct access rights can open and access http://opencti_instance/stream and open an SSE connection to start receiving live events. You can of course consume directly the stream in Redis but you will have to manage access and rights directly.</p>"},{"location":"reference/streaming/#events-format","title":"Events format","text":"<pre><code>id: {Event stream id} -&gt; Like 1620249512318-0\nevent: {Event type} -&gt; create / update / delete\ndata: { -&gt; The complete event data\n    version -&gt; The version number of the event\n    type -&gt; The inner type of the event\n    scope -&gt; The scope of the event [internal or external]\n    data: {STIX data} -&gt; The STIX representation of the data.\n    message -&gt; A simple string to easy understand the event\n    origin: {Data Origin} -&gt; Complex object with different information about the origin of the event\n    context: {Event context} -&gt; Complex object with meta information depending of the event type\n}\n</code></pre> <p>Id can be used to consume the stream from this specific point.</p>"},{"location":"reference/streaming/#stix-data","title":"STIX data","text":"<p>The current stix data representation is based on the STIX 2.1 format using extension mechanism. Please take a look to https://docs.oasis-open.org/cti/stix/v2.1/stix-v2.1.html for more information.</p>"},{"location":"reference/streaming/#create","title":"Create","text":"<p>Its simply the data created in STIX format.</p>"},{"location":"reference/streaming/#delete","title":"Delete","text":"<p>Its simply the data in STIX format just before his deletion. You will also find the automated deletions in context due to automatic dependency management.</p> <pre><code>{\n\"context\": {\n\"deletions\": [{STIX data}]\n}\n}\n</code></pre>"},{"location":"reference/streaming/#update","title":"Update","text":"<p>This event type publish the complete STIX data information along with patches information. Thanks to the patches, its possible to rebuild the previous version and easily understand that happens in the update. patch and reverse_patch follow the official jsonpatch specification. You can find more information at https://jsonpatch.com/</p> <pre><code>{\n\"context\": {\n\"patch\": [/* patch operation object */],\n\"reverse_patch\": [/* patch operation object */]\n}\n}\n</code></pre>"},{"location":"reference/streaming/#merge","title":"Merge","text":"<p>Merge is a mix of an update of the merge targets and deletions of the sources. In this event you will find the same patch and reverse_patch as an update and the list of elements merged into the target in the \"sources\" attribute.</p> <pre><code>{\n\"context\": {\n\"patch\": [/* patch operation object */],\n\"reverse_patch\": [/* patch operation object */],\n\"sources\": [{STIX data}]\n}\n}\n</code></pre>"},{"location":"reference/streaming/#stream-types","title":"Stream types","text":"<p>In OpenCTI we propose 2 types of streams.</p>"},{"location":"reference/streaming/#base-stream","title":"Base stream","text":"<p>The stream hosted in /stream url contains all the raw events of the platform, always filtered by the user rights (marking based). It's a technical stream a bit complex to used but very useful for internal processing or some specific connectors like backup/restore. This stream is live by default but if you want to catchup you can simply add the from parameter to your query. This parameter accept a timestamp in millisecond and also an event id. Like http://localhost/stream?from=1620249512599</p> <p>Stream size?</p> <p>The raw stream is really important in the platform and needs te be sized according to the period of retention you want to ensure. More retention you will have, more security about reprocessing the past information you will get. We usually recommand 1 month of retention, that usually match 2 000 000 of events. This limit can be configured with redis:trimming option, please check deployment configuration page.</p>"},{"location":"reference/streaming/#live-stream","title":"Live stream","text":"<p>This stream aims to simplify your usage of the stream through the connectors, providing a way to create stream with specific filters through the UI. After creating this stream, is simply accessible from /stream/{STREAM_ID}.</p> <p>It's very useful for various cases of data externalization, synchronization, like SPLUNK, TANIUM...</p> <p>This stream provides different interesting mechanics:</p> <ul> <li>Stream the initial list of instances matching your filters when connecting based on main database if you use the recover parameter</li> <li>Auto dependencies resolution to guarantee the consistency of the information distributed</li> <li>Automatic events translation depending on the element segregation</li> </ul> <p>If you want to dig in about the internal behavior you can check this complete diagram:</p>"},{"location":"reference/streaming/#general-options","title":"General options","text":"<ul> <li>no-dependencies (query parameter or header, default false). Can be used to prevent the auto dependencies resolution. To be used with caution.</li> <li>listen-delete (query parameter or header, default true). Can be used prevent receive deletion events. To be used with caution.</li> <li>with-inferences (query parameter or header, default false). Can be used to add inferences events (from rule engine) in the stream.</li> </ul>"},{"location":"reference/streaming/#from-and-recover","title":"From and Recover","text":"<p>From and recover are 2 different options that need to be explains.</p> <ul> <li> <p>from (query parameter) is always the parameter that describe the initial date/event_id you want to start from. Can also be setup with request header from or last-event-id </p> </li> <li> <p>recover (query parameter) is an option that let you consume the initial event from the database and not from the stream.  Can also be setup with request header recover or recover-date </p> </li> </ul> <p>This difference will be transparent for the consumer but very important to get old information as an initial snapshot. This also let you consume information that is no longer in the stream retention period.</p> <p>The next diagram will help you to understand the concept:</p>"},{"location":"reference/taxii-feeds/","title":"Taxii feeds","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"reference/taxonomy/","title":"Taxonomy","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/case-management/","title":"Case management","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/containers/","title":"Containers","text":""},{"location":"usage/containers/#stix-standard","title":"STIX standard","text":""},{"location":"usage/containers/#definition","title":"Definition","text":"<p>In the STIX 2.1 standard, some STIX Domain Objects (SDO) can be considered as \"container of knowledge\", using the <code>object_refs</code> attribute to refer multiple other objects as nested references. In <code>object_refs</code>, it is possible to refer to entities and relationships. </p>"},{"location":"usage/containers/#example","title":"Example","text":"<pre><code>{\n\"type\": \"report\",\n\"spec_version\": \"2.1\",\n\"id\": \"report--84e4d88f-44ea-4bcd-bbf3-b2c1c320bcb3\",\n\"created_by_ref\": \"identity--a463ffb3-1bd9-4d94-b02d-74e4f1658283\",\n\"created\": \"2015-12-21T19:59:11.000Z\",\n\"modified\": \"2015-12-21T19:59:11.000Z\",\n\"name\": \"The Black Vine Cyberespionage Group\",\n\"description\": \"A simple report with an indicator and campaign\",\n\"published\": \"2016-01-20T17:00:00.000Z\",\n\"report_types\": [\"campaign\"],\n\"object_refs\": [\n\"indicator--26ffb872-1dd9-446e-b6f5-d58527e5b5d2\",\n\"campaign--83422c77-904c-4dc1-aff5-5c38f3a2c55c\",\n\"relationship--f82356ae-fe6c-437c-9c24-6b64314ae68a\"\n]\n}\n</code></pre> <p>In the previous example, we have a nested reference to 3 other objects:</p> <pre><code>\"object_refs\": [\n\"indicator--26ffb872-1dd9-446e-b6f5-d58527e5b5d2\",\n\"campaign--83422c77-904c-4dc1-aff5-5c38f3a2c55c\",\n\"relationship--f82356ae-fe6c-437c-9c24-6b64314ae68a\"\n]\n</code></pre>"},{"location":"usage/containers/#implementation","title":"Implementation","text":""},{"location":"usage/containers/#types-of-container","title":"Types of container","text":"<p>In OpenCTI, containers are displayed differently than other entities, because they contain pieces of knowledge. Here is the list of containers in the platform:</p> Type of entity STIX standard Description Report Native Reports are collections of threat intelligence focused on one or more topics, such as a description of a threat actor, malware, or attack technique, including context and related details. Grouping Native A Grouping object explicitly asserts that the referenced STIX Objects have a shared context, unlike a STIX Bundle (which explicitly conveys no context). Observed Data Native Observed Data conveys information about cyber security related entities such as files, systems, and networks using the STIX Cyber-observable Objects (SCOs). Note Native A Note is intended to convey informative text to provide further context and/or to provide additional analysis not contained in the STIX Objects. Opinion Native An Opinion is an assessment of the correctness of the information in a STIX Object produced by a different entity. Case Extension A case whether an Incident Response, a Request for Information or a Request for Takedown is use to convey an epic with a set of tasks. Task Extension A task, generally used in the context of case, is intended to convery information about something that must be done in a limited timeframe."},{"location":"usage/containers/#containers-behaviour","title":"Containers behaviour","text":"<p>In the platform, it is always possible to visualize the list of entities and/or observables referenced in a container (<code>Container &gt; Entities or Observables</code>) but also to add / remove entities from the container.</p> <p></p> <p>As containers can also contain relationships, which are generally linked to the other entities in the container, it is also possible to visualize the container as a graph (<code>Container &gt; Knowledge</code>)</p> <p></p>"},{"location":"usage/containers/#containers-of-an-entity-or-a-relationship","title":"Containers of an entity or a relationship","text":"<p>On the entity or the relationship side, you can always find all containers where the objecti is contained using the top menu <code>Analysis</code>:</p> <p></p> <p>In all containers list, you can also filter containers based on one or multiple contained object(s):</p> <p></p>"},{"location":"usage/dashboards/","title":"Custom dashboards","text":""},{"location":"usage/dashboards/#sharing-and-access-restriction","title":"Sharing and access restriction","text":"<p><code>Organizations</code>, <code>groups</code>, or <code>users</code> who have access to a dashboard can have 3 levels of access:  - <code>admin</code> read, write, access management - <code>edit</code> read and write - <code>view</code> read-only</p> <p>When a user creates a custom dashboard, it is only visible to themselves. They then have <code>admin</code> access. They can then define who can access it and with what level of rights via the <code>Manage access</code> button at the top right of the dashboard page.</p> <p> Manage access button</p> <p>They can give access to organizations, groups, users, but also to all users on the platform (<code>everyone</code>).</p> <p> Manage access window</p> <p>It is important to note that a dashboard must have at least one user with <code>admin</code> access level.</p>"},{"location":"usage/data-model/","title":"Data model","text":""},{"location":"usage/data-model/#introduction","title":"Introduction","text":"<p>The OpenCTI core design relies on the concept of a knowledge graph, where you have two different kinds of object:</p> <ol> <li>Nodes are used to describe <code>entities</code>, which have some <code>properties</code> or <code>attributes</code>.</li> <li>Edges are used to describe <code>relationships</code>, which are created between two <code>entity</code> nodes and have some <code>properties</code> or <code>attributes</code>.</li> </ol> <p>Example</p> <p>An example would be that the entity <code>APT28</code> has a relationship <code>uses</code> to the malware entity <code>Drovorub</code>.</p>"},{"location":"usage/data-model/#standard","title":"Standard","text":""},{"location":"usage/data-model/#the-stix-model","title":"The STIX model","text":"<p>To enable a unified approach in the description of threat intelligence knowledge as well as importing and exporting data, the OpenCTI data model is based on the STIX 2.1 standard. Thus we highly recommend to take a look to the STIX Introductory Walkthrough and to the different kinds of STIX relationships to get a better understanding of how OpenCTI works.</p> <p>Some more important STIX naming shortcuts are:</p> <ul> <li>STIX Domain Objects (SDO): Attack Patterns, Malware, Threat Actors, etc.</li> <li>STIX Cyber Observable (SCO): IP Addresses, domain names, hashes, etc.</li> <li>STIX Relationship Object (SRO): Relationships, Sightings</li> </ul> <p></p>"},{"location":"usage/data-model/#extensions","title":"Extensions","text":"<p>In some cases, the model has been extended to be able to:</p> <ul> <li>Support more types of SCOs to modelize information systems such as cryptocurrency wallets, user agents, etc.</li> <li>Support more types of SDOs to modelize disinformation and cybercrime such as channels, events, narrative, etc.</li> <li>Support more types of SROs to extend the new SDOs such as<code>amplifies</code>, <code>publishes</code>, etc.</li> </ul>"},{"location":"usage/data-model/#implementation-in-the-platform","title":"Implementation in the platform","text":""},{"location":"usage/data-model/#diagram-of-types","title":"Diagram of types","text":"<p>You can find below the digram of all types of entities and relationships available in OpenCTI.</p>"},{"location":"usage/data-model/#attributes-and-properties","title":"Attributes and properties","text":"<p>To get a comprehensive list of available properties for a given type of entity or relationship, you can use the GraphQL playground schema available in your \"Profile &gt; Playground\". Then you can click on schema. You can for instance search for the keyword <code>IntrusionSet</code>:</p> <p></p>"},{"location":"usage/deduplication/","title":"Deduplication","text":"<p>One of the core concept of the OpenCTI knowledge graph is all underlying mechanisms implemented to accurately de-duplicate and consolidate (aka. <code>upserting</code>) information about entities and relationships.</p>"},{"location":"usage/deduplication/#creation-behavior","title":"Creation behavior","text":"<p>When an object is created in the platform, whether manually by a user or automatically by the connectors / workers chain, the platform checks if something already exist based on some properties of the object. If the object already exists, it will return the existing object and, in some cases, update it as well.</p> <p>Technically, OpenCTI generates deterministic IDs based on the listed properties below to prevent duplicate (aka \"ID Contributing Properties\"). Also, it is important to note that there is a special link between <code>name</code> and <code>aliases</code> leading to not have entities with overlaping aliases or an alias already used in the name of another entity.</p>"},{"location":"usage/deduplication/#entities","title":"Entities","text":"Type Attributes Area (<code>name</code> OR <code>x_opencti_alias</code>) AND <code>x_opencti_location_type</code> Attack Pattern (<code>name</code> OR <code>alias</code>) AND optional <code>x_mitre_id</code> Campaign <code>name</code> OR <code>alias</code> Channel <code>name</code> OR <code>alias</code> City (<code>name</code> OR <code>x_opencti_alias</code>) AND <code>x_opencti_location_type</code> Country (<code>name</code> OR <code>x_opencti_alias</code>) AND <code>x_opencti_location_type</code> Course Of Action (<code>name</code> OR <code>alias</code>) AND optional <code>x_mitre_id</code> Data Component <code>name</code> OR <code>alias</code> Data Source <code>name</code> OR <code>alias</code> Event <code>name</code> OR <code>alias</code> Feedback Case <code>name</code> AND <code>created</code> (date) Grouping <code>name</code> AND <code>context</code> Incident <code>name</code> OR <code>alias</code> Incident Response Case <code>name</code> OR <code>alias</code> Indicator <code>name</code> OR <code>alias</code> Individual (<code>name</code> OR <code>x_opencti_alias</code>) and <code>identity_class</code> Infrastructure <code>name</code> OR <code>alias</code> Intrusion Set <code>name</code> OR <code>alias</code> Language <code>name</code> OR <code>alias</code> Malware <code>name</code> OR <code>alias</code> Malware Analysis <code>name</code> OR <code>alias</code> Narrative <code>name</code> OR <code>alias</code> Note None Observed Data <code>name</code> OR <code>alias</code> Opinion None Organization (<code>name</code> OR <code>x_opencti_alias</code>) and <code>identity_class</code> Position (<code>name</code> OR <code>x_opencti_alias</code>) AND <code>x_opencti_location_type</code> Region <code>name</code> OR <code>alias</code> Report <code>name</code> AND <code>publised</code> (date) RFI Case <code>name</code> AND <code>created</code> (date) RFT Case <code>name</code> AND <code>created</code> (date) Sector (<code>name</code> OR <code>alias</code>) and <code>identity_class</code> Task None Threat Actor <code>name</code> OR <code>alias</code> Tool <code>name</code> OR <code>alias</code> Vulnerability <code>name</code> OR <code>alias</code>"},{"location":"usage/deduplication/#relationships","title":"Relationships","text":"<p>The deduplication process of relationships is based on the following criterias:</p> <ul> <li>Type</li> <li>Source</li> <li>Target</li> <li>Start time between -30 days / + 30 days</li> <li>Stop time between -30 days / + 30 days</li> </ul>"},{"location":"usage/deduplication/#observables","title":"Observables","text":"<p>For STIX Cyber Observables, OpenCTI also generate deterministic IDs based on the STIX specification using the \"ID Contributing Properties\" defined for each type of observable.</p>"},{"location":"usage/deduplication/#update-behavior","title":"Update behavior","text":"<p>If an entity already exists in the platform, the <code>attributes</code> may be updated by the incoming creation with the following rule:</p> <p>If <code>confidence_level</code> of the created entity is &gt;= (greater or equal) then the <code>confidence_level</code> of the existing entity, attributes will be updated. Obviously, the <code>confidence_level</code> will also be increased with the new one.</p> <p>This logic has been implemented so the platform can converge to the highest confidence and quality levels for the entities and the relationships.</p>"},{"location":"usage/enrichment/","title":"Enrichment connectors","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/exploring-analysis/","title":"Exploring \"Analysis\"","text":"<p>When you click on \"Analysis\" in the left-side bar, you access all the \"Analysis\" tabs, visible on the top bar on the left. By default, the user directly access the \"Reports\" tab, but can navigate to the other tabs as well.</p> <p>From the <code>Analysis</code> section, users can access the following tabs:</p> <ul> <li><code>Reports</code>: See Reports as a sort of containers to detail and structure what is contained on a specific report, either from a source or write by yourself. Think of it as an Intelligence Production in OpenCTI.</li> <li><code>Groupings</code>: Groupings are containers, like Reports, but do not represent an Intelligence Production. They regroup Objects sharing an explicit context. For example, a Grouping might represent a set of data that, in time, given sufficient analysis, would mature to convey an incident or threat report as Report container.</li> <li><code>Malware Analysis</code>: As define by STIX 2.1 standard, Malware Analysis captures the metadata and results of a particular static or dynamic analysis performed on a malware instance or family.</li> <li><code>Notes</code>: Through this tab, you can find all the Notes that have been written in the platform, for example to add some analyst's unstructured knowledge about an Object.</li> <li><code>External references</code>: Intelligence is never created from nothing. External references give user a way to link sources or reference documents to any Object in the platform.</li> </ul> <p></p>"},{"location":"usage/exploring-analysis/#reports","title":"Reports","text":""},{"location":"usage/exploring-analysis/#general-presentation","title":"General presentation","text":"<p>Reports are one of the central component of the platform. It is from a <code>Report</code> that knowledge is extracted and integrated in the platform for further navigation, analysis and exports. Always tying the information back to a report allows for the user to be able to identify the source of any piece of information in the platform at all time.</p> <p>In the MITRE STIX 2.1 documentation, a <code>Report</code> is defined as such :</p> <p>Reports are collections of threat intelligence focused on one or more topics, such as a description of a threat actor, malware, or attack technique, including context and related details. They are used to group related threat intelligence together so that it can be published as a comprehensive cyber threat story.</p> <p>As a result, a <code>Report</code> object in OpenCTI is a set of attributes and metadata defining and describing a document outside the platform, which can be a threat intelligence report from a security reseearch team, a blog post, a press article a video, a conference extract, a MISP event, or any type of document and source.</p> <p>When clicking on the Reports tab at the top left, you access the list of all Reports you have access too, in respect with your allowed marking definitions. You can then search and filter on some common and specific attributes of reports.</p>"},{"location":"usage/exploring-analysis/#visualizing-knowledge-within-a-report","title":"Visualizing Knowledge within a Report","text":"<p>When clicking on a Report, you land on the Overview tab. For a Report, the following tabs are accessible:</p> <ul> <li>Overview: as described here.</li> <li>Knowledge: a complex tab that regroups all the structured Knowledge contained in the report, accessible through different views (See below for a dive-in).</li> <li>Content: a tab to upload or creates outcomes document displaying the content of the Report (for example in PDF, text, HTML or markdown files). The Content of the document is displayed to ease the access of Knowledge through a readable format.</li> <li>Entities: A table containing all SDO (Stix Domain Objects) contained in the Report, with search and filters available. It also display if the SDO has been added directly or through inferences with the reasonging engine</li> <li>Observables: A table containing all SCO (Stix Cyber Observable) contained in the Report, with search and filters available. It also display if the SDO has been added directly or through inferences with the reasonging engine</li> <li>Data: as described here.</li> </ul> <p>Exploring and modifying the structured Knowledge contained in a Report can be done through different lenses.</p>"},{"location":"usage/exploring-analysis/#graph-view","title":"Graph View","text":"<p>In Graph view, STIX SDO are displayed as graph nodes and relationships as graph links. Nodes are colored depending of their type. Direct relationship are displayed as plain link and inferred relationships in dotted link. At the top right, you will find a serie of icons. From there you can change the current type of view. Here you can also perform global action on the Knowledge of the Report. Let's highlight 2 of them: - Suggestions: This tool suggests you some logical relationships to add between your contained Object to give more consistency to your Knowledge. - Share with an Organization: if you have designated a main Organization in the platform settings, you can here share your Report and its content with users of an other Organization. At the bottom, you have many option to manipulate the graph: - Multiple option for shaping the graph and applying forces to the nodes and links - Multiple selection options - Multiple filters, including a time range selector allowing you to see the evolution of the Knowledge within the Report. - Multiple creation and edition tools to modify the Knowledge contained in the Report.</p>"},{"location":"usage/exploring-analysis/#content-mapping-view","title":"Content mapping view","text":"<p>Through this view, you can map exsisting or new Objects directly from a readable content, allowing you to quickly append structured Knowledge in your Report before refining it with relationships and details.  This view is a great place to see the continuum between unstructured and structured Knowledge of a specific Intelligence Production.</p>"},{"location":"usage/exploring-analysis/#timeline-view","title":"Timeline view","text":"<p>This view allows you to see the structured Knowledge chronologically. This view is really useful when the report describes an attack or a campaign that lasted some time, and the analyst payed attention to the dates. The view can be filtered and displayed relationships too.</p>"},{"location":"usage/exploring-analysis/#correlation-view","title":"Correlation view","text":"<p>The correlation view is a great way to visualize and find other Reports related to your current subject of interest. This graph displays all Report related to the important nodes contained in your current Report, for example Objects like Malware or Intrusion sets.</p>"},{"location":"usage/exploring-analysis/#matrix-view","title":"Matrix view","text":"<p>If your Report describes let's say an attack, a campaign, or an understanding of an Intrusion set, it should contains multiple attack patterns Objects to structure the Knowledge about the TTPs of the Threat Actor. Those attack patterns can be displayed as highlighted matrices, by default the MITRE ATT&amp;CK Enterprise matrix. As some matrices can be huge, it can be also filtered to only display attack patterns describes in the Report.</p>"},{"location":"usage/exploring-analysis/#groupings","title":"Groupings","text":"<p>Groupings are an alternative to Report for grouping Objects sharing a context without describing an Intelligence Production.</p> <p>In the MITRE STIX 2.1 documentation, a <code>Grouping</code> is defined as such :</p> <p>A Grouping object explicitly asserts that the referenced STIX Objects have a shared context, unlike a STIX Bundle (which explicitly conveys no context). A Grouping object should not be confused with an intelligence product, which should be conveyed via a STIX Report. A STIX Grouping object might represent a set of data that, in time, given sufficient analysis, would mature to convey an incident or threat report as a STIX Report object. For example, a Grouping could be used to characterize an ongoing investigation into a security event or incident. A Grouping object could also be used to assert that the referenced STIX Objects are related to an ongoing analysis process, such as when a threat analyst is collaborating with others in their trust community to examine a series of Campaigns and Indicators.</p> <p>When clicking on the Groupings tab at the top of the interface, you access the list of all Groupings you have access too, in respect with your allowed marking definitions. You can then search and filter on some common and specific attributes of the groupings.</p> <p>Clicking on a Grouping, you land on its Overview tab. For a Groupings, the following tabs are accessible: - Overview: as described here. - Knowledge: a complex tab that regroups all the structured Knowledge contained in the groupings, as for a Report, except for the Timeline view. - Entities: A table containing all SDO (Stix Domain Objects) contained in the Grouping, with search and filters available. It also display if the SDO has been added directly or through inferences with the reasonging engine - Observables: A table containing all SCO (Stix Cyber Observable) contained in the Grouping, with search and filters available. It also display if the SDO has been added directly or through inferences with the reasonging engine - Data: as described here.</p>"},{"location":"usage/exploring-analysis/#malware-analysis","title":"Malware Analysis","text":"<p>Malware analyses are an important part of the Cyber Threat Intelligence, allowing an precise understanding of what and how a malware really do on the host but also how and from where it receives its command and communicates its results.</p> <p>In OpenCTI, Malware Analyses can be created from enrichment connectors that will take an Observable as input and perform a scan on a online service platform to bring back results. As such, Malware Analysis can be done on File, Domain and URL.</p> <p>In the MITRE STIX 2.1 documentation, a <code>Malware Analysis</code> is defined as such :</p> <p>Malware Analysis captures the metadata and results of a particular static or dynamic analysis performed on a malware instance or family.</p> <p>When clicking on the Malware Analysis tab at the top of the interface, you access the list of all Malware Analysis you have access too, in respect with your allowed marking definitions. You can then search and filter on some common and specific attributes of the Malware Analysis.</p> <p>Clicking on a Malware Analysis, you land on its Overview tab. The following tabs are accessible: - Overview: This view contains some additions from the common Overview here. You will find here details about how the analysis have been performed, what is the global result regarding the malicioussness of the analysed artifact and all the Observables that have been found during the analysis.  - Knowledge: If you Malware analysis is linked to other Objects that are not part of the analysis result, they will be displayed here. - Data: as described here. - History: as described here.</p> <p></p>"},{"location":"usage/exploring-analysis/#notes","title":"Notes","text":"<p>Not every Knowledge can be structured. For allowing any users to share their insights about a specific Knowledge, they can create a Note for every Object and relationship in OpenCTI they can access to. All the Notes are listed within the Analysis menu for allowing global review of this unstructured addition to the global Knowledge.</p> <p>In the MITRE STIX 2.1 documentation, a <code>Note</code> is defined as such :</p> <p>A Note is intended to convey informative text to provide further context and/or to provide additional analysis not contained in the STIX Objects, Marking Definition objects, or Language Content objects which the Note relates to. Notes can be created by anyone (not just the original object creator).</p> <p>Clicking on a Note, you land on its Overview tab. The following tabs are accessible: - Overview: as described here. - Data: as described here. - History: as described here.</p>"},{"location":"usage/exploring-analysis/#external-references","title":"External references","text":"<p>Intelligence is never created from nothing. External references give user a way to link sources or reference documents to any Object in the platform. All external references are listed within the Analysis menu for accessing directly sources of the structured Knowledge.</p> <p>In the MITRE STIX 2.1 documentation, a <code>External references</code> is defined as such :</p> <p>External references are used to describe pointers to information represented outside of STIX. For example, a Malware object could use an external reference to indicate an ID for that malware in an external database or a report could use references to represent source material.</p> <p>Clicking on an External reference, you land on its Overview tab. The following tabs are accessible: - Overview: as described here.</p>"},{"location":"usage/exploring-arsenal/","title":"Manual creations","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/exploring-cases/","title":"Exploring \"Cases\"","text":"<p>When you click on \"Cases\" in the left-side bar, you access all the \"Cases\" tabs, visible on the top bar on the left. By default, the user directly access the \"Incident Responses\" tab, but can navigate to the other tabs as well.</p> <p>As Analyses, <code>Cases</code> can contains other objects. This way, by adding context and results of your investigations in the case, you will be able to get an up to date overview of the ongoing situation, and later produce more easily an incident report. </p> <p>From the <code>Cases</code> section, users can access the following tabs:</p> <ul> <li><code>Incident Responses</code>: This type of Cases is dedicated to the management of incidents. An Incident Reponse case does not represent an incident, but all the context and actions that will encompass the response to a specific incident.</li> <li><code>Request for Information</code>: CTI teams are often asked to provide extensive information and analysis on a specific subject, be it related to an ongoing incident or a particular trending threat. Request for Information cases allow you to store context and actions relative to this type of request and its response.</li> <li><code>Request for Takedown</code>: When an orgnization is targeted by an attack campaign, a typical response action can be to request the Takedown of elements of the attack infrastructure, for example a domain name impersonating the organization to phish its employees, or an email address used to deliver phishing content. As Takedown needs in most case to reach out to external providers and be effective quickly, it often needs specific workflows. Request for Takedown cases give you a dedicated space to manage these specific actions.</li> <li><code>Tasks</code>: In every case, you need tasks to be performed in order to solve it. The Tasks tab allows you to review all created tasks to quickly see past due date, or quickly see every task assigned to a specific user.</li> <li><code>Feedbacks</code>: If you use your platform to interact with other teams and provide them CTI Knowledge, some users may want to give you feedback about it. Those feedbacks can easily be considered as an other type of case to solve, as it will often reffer to Knowledge inconsistency or gaps.</li> </ul> <p></p>"},{"location":"usage/exploring-cases/#incident-response-request-for-information-request-for-takedown","title":"Incident Response, Request for Information &amp; Request for Takedown","text":""},{"location":"usage/exploring-cases/#general-presentation","title":"General presentation","text":"<p>Incident responses, Request for Information &amp; Request for Takedown cases are an important part of the case management system in OpenCTI. Here, you can organize the work of your team to respond to cybersecurity situations. You can also give context to the team and other users on the platform about the situation and actions (to be) taken.</p> <p>To manage the situation, you can issue <code>Tasks</code> and assign them to users in the platform, by directly creating a Task or by applying a Case template that will append a list of predifined tasks.</p> <p>To bring context, you can use your Case as a container (like Reports or Groupings), allowing you to add any Knowledge from your platform in it. You can also use this possibility to trace your investigation, your Case playing the role of an Incident report. You will find more information about case management here.</p> <p>Incident Response, Request for Information &amp; Request for Takedown are not STIX 2.1 Objects.</p> <p>When clicking on the Incident Response, Request for Information &amp; Request for Takedown tabs at the top, you access the list of all Cases you have access too, in respect with your allowed marking definitions. You can then search and filter on some common and specific attributes.</p>"},{"location":"usage/exploring-cases/#visualizing-knowledge-within-an-incident-response-request-for-information-request-for-takedown","title":"Visualizing Knowledge within an Incident Response, Request for Information &amp; Request for Takedown","text":"<p>When clicking on an Incident Response, Request for Information or Request for Takedown, you land on the Overview tab. The following tabs are accessible:</p> <ul> <li>Overview: Overview of Cases are slightly different than the usual (described here). Cases' Overview displays also the list of the tasks associated with the case. It also let you hightlight Incident, Report or Sighting at the origin of the case. If other cases contains some Observables with your Case, they will be displayed as Related Cases in the Overview.</li> <li>Knowledge: a complex tab that regroups all the structured Knowledge contained in the Case, accessible through different views (See below for a dive-in).</li> <li>Content: a tab to upload or creates outcomes document displaying the content of the Case (for example in PDF, text, HTML or markdown files). The Content of the document is displayed to ease the access of Knowledge through a readable format.</li> <li>Entities: A table containing all SDO (Stix Domain Objects) contained in the Case, with search and filters available. It also display if the SDO has been added directly or through inferences with the reasonging engine</li> <li>Observables: A table containing all SCO (Stix Cyber Observable) contained in the Case, with search and filters available. It also display if the SDO has been added directly or through inferences with the reasonging engine</li> <li>Data: as described here.</li> </ul> <p>Exploring and modifying the structured Knowledge contained in a Case can be done through different lenses.</p>"},{"location":"usage/exploring-cases/#graph-view","title":"Graph View","text":"<p>In Graph view, STIX SDO are displayed as graph nodes and relationships as graph links. Nodes are colored depending of their type. Direct relationship are displayed as plain link and inferred relationships in dotted link. At the top right, you will find a serie of icons. From there you can change the current type of view. Here you can also perform global action on the Knowledge of the Case. Let's highlight 2 of them: - Suggestions: This tool suggests you some logical relationships to add between your contained Object to give more consistency to your Knowledge. - Share with an Organization: if you have designated a main Organization in the platform settings, you can here share your Case and its content with users of an other Organization. At the bottom, you have many option to manipulate the graph: - Multiple option for shaping the graph and applying forces to the nodes and links - Multiple selection options - Multiple filters, including a time range selector allowing you to see the evolution of the Knowledge within the Case. - Multiple creation and edition tools to modify the Knowledge contained in the Case.</p>"},{"location":"usage/exploring-cases/#content-mapping-view","title":"Content mapping view","text":"<p>Through this view, you can map exsisting or new Objects directly from a readable content, allowing you to quickly append structured Knowledge in your Case before refining it with relationships and details.  This view is a great place to see the continuum between unstructured and structured Knowledge.</p>"},{"location":"usage/exploring-cases/#timeline-view","title":"Timeline view","text":"<p>This view allows you to see the structured Knowledge chronologically. This view is particularily useful in the context of a Case, allowing you to see the chain of events, either from the attack perspectives, the defense perspectives or both. The view can be filtered and displayed relationships too.</p>"},{"location":"usage/exploring-cases/#matrix-view","title":"Matrix view","text":"<p>If your Case contains attack patterns, you will be able to visualize them in a Matrix view.</p>"},{"location":"usage/exploring-cases/#tasks","title":"Tasks","text":"<p>Tasks are actions to be performed in the context of a Case (Incident Response, Request for Information, Request for Takedown). Usually, a task is assigned to a user, but important tasks may involved more participants.</p> <p>When clicking on the Tasks tab at the top of the interface, you access the list of all Tasks you have access too, in respect with your allowed marking definitions. You can then search and filter on some common and specific attributes of the tasks.</p> <p>Clicking on a Task, you land on its Overview tab. For a Tasks, the following tabs are accessible: - Overview: as described here. - Data: as described here. - History: as described here.</p>"},{"location":"usage/exploring-cases/#feedbacks","title":"Feedbacks","text":"<p>When a user fill a feedback form from its Profile/Feedback menu, it will then be accessible here.</p> <p>This feature gives the opportunity to engage with other users of your platform and to respond directly to their concern about it or the Knowledge, without the need of third party software.</p> <p></p> <p>Clicking on a Feedback, you land on its Overview tab. For a Feedback, the following tabs are accessible: - Overview: as described here. - Content: as described here.  - Data: as described here. - History: as described here.</p>"},{"location":"usage/exploring-entities/","title":"Manual creations","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/exploring-events/","title":"Manual creations","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/exploring-locations/","title":"Manual creations","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/exploring-observations/","title":"Manual creations","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/exploring-techniques/","title":"Manual creations","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/exploring-threats/","title":"Threats","text":"<p>When you click on \"Threats\" in the left-side bar, you access all the \"Threats\" tabs, visible on the top bar on the left. By default, the user directly access the \"Threat Actor (Group)\" tab, but can navigate to the other tabs as well.</p> <p>From the <code>Threats</code> section, users can access the following tabs:</p> <ul> <li><code>Threat actors (Group)</code>: Threat actor (Group) represents a physical group of attackers operating an Intrusion set, using malware and attack infrastructure, etc.</li> <li><code>Threat actors (Indvidual)</code>: Threat actor (Individual) represents a real attacker that can be described by physical and personal attributes and motivations. Threat actor (Individual) operates Intrusion set, uses malware and infrastructure, etc.</li> <li><code>Intrusion sets</code>: Intrusion set is an important concept in Cyber Threat Intelligence field. It is a consistent set of technical and non technical elements corresponding of what, how and why a Threat actor acts. it is particularly usefull for associating multiple attacks and malicious actions to a defined Threat, even without sufficiant informations regarding who did them. Often, with you understanding of the threat growing, you will link an Intrusion set to a Threat actor (either a Group or an Individual).</li> <li><code>Campaigns</code>: Campaign represents a serie of attacks taking place in a certain period of time and/or targeting a consistent subset of Organization/Individual.</li> </ul>"},{"location":"usage/exploring-threats/#threat-actors-group-and-individual","title":"Threat actors (Group and Individual)","text":""},{"location":"usage/exploring-threats/#general-presentation","title":"General presentation","text":"<p>Threat actors are the humans who are building, deploying and operating intrusion sets. A threat actor can be an single individual or a group of attackers (who may be composed of individuals). A group of attackers may be a state-nation, a state-sponsored group, a corporation, a group of hacktivists, etc. </p> <p>Beware, groups of attackers might be modelized as \"Intrusion sets\" in feeds, as there is sometimes a misunderstanding in the industry between group of people and the technical/operational intrusion set they operate.</p> <p></p> <p>When clicking on the Threat actor (Group or Individual) tabs at the top left, you access the list of all the groups of Threat actors or INdivudual Threat actors you have access too, in respect with your allowed marking definitions. These groups or individual are displayed as Cards where you can find a summary of the important Knowledge associated with each of them: description, aliases, malwares they used, countries and industries they target, labels. You can then search and filter on some common and specific attributes of Threat actors.</p> <p>At the top right of each Card, you can click the star icon to put it as favorite. It will pin the card on top of the list. You will also be able to display all your favorite easily in your Custom Dashboards.</p>"},{"location":"usage/exploring-threats/#visualizing-knowledge-associated-with-a-threat-actor","title":"Visualizing Knowledge associated with a Threat actor","text":"<p>When clicking on a Threat actor Card, you land on its Overview tab. For a Threat actor, the following tabs are accessible:</p> <ul> <li>Overview: as described here.</li> <li>Knowledge: a complex tab that regroups all the structured Knowledge linked to the Threat actor. Different thematic views are proposed to easily see the victimology, arsenal and techniques used by the Threat actor, etc. </li> <li>Analyses: as described here.</li> <li>Data: as described here.</li> <li>History: as described here.</li> </ul>"},{"location":"usage/exploring-threats/#intrusion-sets","title":"Intrusion Sets","text":"<p>An intrusion set is a consistent group of technical elements such as \"tactics, technics and procedures\" (TTP), tools, malware and infrastructure used by a threat actor against one or a number of victims who are usually sharing some characteristics (field of activity, country or region) to reach a similar goal whoever the victim is. The intrusion set may be deployed once or several times and may evolve with time. Several intrusion sets may be linked to one threat actor. All of the entities described below may be linked to one intrusion set. There are many debates in the Threat Intelligence community on how to define an intrusion set and how to distinguish several intrusion sets with regards to:</p> <ul> <li>their differences</li> <li>their evolutions</li> <li>the possible reuse</li> <li>\"false flag\" type of attacks</li> </ul> <p>As OpenCTI is very customizable, each organization or individual may use these categories as they wish. Instead, it is also possible to use the import feed for the choice of categories.</p> <p></p> <p>When clicking on the Intrusion set tab on the top left, you access the list of all the Intrusion sets you have access too, in respect with your allowed marking definitions. These intrusion sets are displayed as Cards where you can find a summary of the important Knowledge associated with each of them: description, aliases, malwares they used, countries and industries they target, labels. You can then search and filter on some common and specific attributes of Intrusion set.</p> <p>At the top right of each Card, you can click the star icon to put it as favorite. It will pin the card on top of the list. You will also be able to display all your favorite easily in your Custom Dashboards.</p>"},{"location":"usage/exploring-threats/#visualizing-knowledge-associated-with-an-intrusion-set","title":"Visualizing Knowledge associated with an Intrusion set","text":"<p>When clicking on an Intrusion set Card, you land on its Overview tab. The following tabs are accessible:</p> <ul> <li>Overview: as described here.</li> <li>Knowledge: a complex tab that regroups all the structured Knowledge linked to the Threat actor. Different thematic views are proposed to easily see the victimology, arsenal and techniques used by the Threat actor, etc. </li> <li>Analyses: as described here.</li> <li>Data: as described here.</li> <li>History: as described here.</li> </ul>"},{"location":"usage/exploring-threats/#campaigns","title":"Campaigns","text":"<p>A campaign can be defined as \"a series of malicious activities or attacks (sometimes called a \"wave of attacks\") taking place within a limited period of time, against a defined group of victims, associated to a similar intrusion set and characterized by the use of one or several identical malware towards the various victims and common TTPs\". However, a campaign is an investigation element and may not be widely recognized. Thus, a provider might define a series of attacks as a campaign and another as an intrusion set. Campaigns can be attributed to an Intrusion set.</p> <p></p> <p>When clicking on the Campaign tab on the top left, you access the list of all the Campaigns you have access too, in respect with your allowed marking definitions. These campaigns are displayed as Cards where you can find a summary of the important Knowledge associated with each of them: description, aliases, malwares used, countries and industries they target, labels. You can then search and filter on some common and specific attributes of Campaigns.</p> <p>At the top right of each Card, you can click the star icon to put it as favorite. It will pin the card on top of the list. You will also be able to display all your favorite easily in your Custom Dashboards.</p>"},{"location":"usage/exploring-threats/#visualizing-knowledge-associated-with-a-campaign","title":"Visualizing Knowledge associated with a Campaign","text":"<p>When clicking on an Campaign Card, you land on its Overview tab. The following tabs are accessible:</p> <ul> <li>Overview: as described here.</li> <li>Knowledge: a complex tab that regroups all the structured Knowledge linked to the Threat actor. Different thematic views are proposed to easily see the victimology, arsenal and techniques used by the Threat actor, etc. </li> <li>Analyses: as described here.</li> <li>Data: as described here.</li> <li>History: as described here.</li> </ul>"},{"location":"usage/export-documents/","title":"Export in documents","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/export-structured/","title":"Export in structured format","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/feeds/","title":"Native feeds","text":""},{"location":"usage/feeds/#live-streams","title":"Live streams","text":""},{"location":"usage/feeds/#introduction","title":"Introduction","text":"<p>The best way to consume OpenCTI data, whether it is through a stream connector or within another OpenCTI instance, is to use the live streams. Live streams are like TAXII collection (ie. serving STIX 2.1 bundles) but under steroids. This means that live streams are supporting:</p> <ul> <li>create, update and delete events depending on the filters ;</li> <li>caching already created entities in the last 5 minutes ;</li> <li>resolving relationships and dependencies even out of the filters ;</li> <li>they can be public (without authentication).</li> </ul> <p></p>"},{"location":"usage/feeds/#schenario","title":"Schenario","text":"<p>To better understand how live streams are working, let's take a few examples, from simple to complex.</p> <p>Given a live stream with filters Entity type: Indicator <code>AND</code> Label: detection. Let's see what happen with an indicator with:</p> <ul> <li>Marking definition: <code>TLP:GREEN</code></li> <li>Author <code>Crowdstrike</code></li> <li>Relation <code>indicates</code> to the malware <code>Emotet</code></li> </ul> Action Result in stream (<code>resolve-dependencies=false</code>) Result in stream (<code>resolve-dependencies=true</code>) 1. Create an indicator Nothing Nothing 2. Add the label <code>detection</code> Create <code>TLP:GREEN</code>, create <code>CrowdStrike</code>, create the indicator Create <code>TLP:GREEN</code>, create <code>CrowdStrike</code>, create the malware <code>Emotet</code>, create the indicator, create the relationship <code>indicates</code> 3. Remove the label <code>detection</code> Delete the indicator Delete the indicator 4. Add the label <code>detection</code> Create the indicator Create the indicator, create the relationship <code>indicates</code> 5. Delete the indicator Delete the indicator Delete the indicator"},{"location":"usage/feeds/#taxii-collections","title":"TAXII Collections","text":"<p>OpenCTI has an embedded TAXII API endpoint which provides valid STIX 2.1 bundles. If you wish to know more about the TAXII standard, please read the official introduction.</p> <p>In OpenCTI you can create as many TAXII 2.1 collections as needed. Each of them can have specific filters to publish only a subset of the platform overall knowledge (specific types of entities, labels, marking definitions, etc.).</p> <p></p> <p>After creating a new collection, every systems with a proper access token can consume the collection using different kinds of authentication (basic, bearer, etc.)</p> <p>As when using the GraphQL API, TAXII 2.1 collections have a classic pagination system that should be handled by the consumer. Also, it's important to understand that element dependencies (nested IDs) inside the collection are not always contained/resolved in the bundle, so consistency needs to be handled at the client level.</p>"},{"location":"usage/feeds/#csv-feeds","title":"CSV feeds","text":"<p>OpenCTI is able to publish data in CSV feeds on a rolling period.</p>"},{"location":"usage/getting-started/","title":"Getting started","text":"<p>This guide aims to give you a full overview of the OpenCTI features and workflows. The platform can be used in various contexts to handle threats management use cases from a technical to a more strategic level. OpenCTI has been designed as a knowledge graph, taking inputs (threat intelligence feeds, sightings &amp; alerts, vulnerabilities, assets, artifacts, etc.) and generating outputs based on built-in capabilities and / or connectors.</p> <p>Here are some examples of use cases:</p> <ul> <li>Cyber Threat Intelligence knowledge base</li> <li>Detection as code feeds for XDR, EDR, SIEMs, firewalls, proxies, etc.</li> <li>Incident response artifacts &amp; cases management</li> <li>Vulnerabilities management</li> <li>Reporting, alerting and dashboarding on a subset of data</li> </ul> <p></p>"},{"location":"usage/getting-started/#welcome-dashboard","title":"Welcome dashboard","text":"<p>The welcome gives any visitor on the OpenCTI platform an outlook on the live of the platform. It can be replaced by a custom dashboard, created by a user (or the default dashboard in a role, a group or an organization).</p> <p></p>"},{"location":"usage/getting-started/#indicators-in-the-dashboard","title":"Indicators in the dashboard","text":""},{"location":"usage/getting-started/#numbers","title":"Numbers","text":"Component Description Total entities Number of entities (<code>threat actor</code>, <code>intrusion set</code>, <code>indicator</code>, etc.). Total relationships Number of relationships (<code>targets</code>, <code>uses</code>, <code>indicates</code>, etc.). Total reports Number of reports. Total observables Number of observables (<code>IPv4-Addr</code>, <code>File</code>, etc.)."},{"location":"usage/getting-started/#charts-lists","title":"Charts &amp; lists","text":"Component Description Top labels Top labels given to entities during the last 3 months. Ingested entities Number of entities ingested by month. Top 10 active entities List of the entities with the greatest number of relations over the last 3 months. Targeted countries Intensity of the targeting tied to the number of relations <code>targets</code> for a given country. Observable distribution Distribution of the number of observables by type. Last ingested reports Last reports ingested in the platform."},{"location":"usage/import-automated/","title":"Automate import","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/import-files/","title":"Import from files","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/inferences/","title":"Inferences and reasoning","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/manual-creation/","title":"Manual creations","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/merging/","title":"Merge objects","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/nested/","title":"Nested references and objects","text":""},{"location":"usage/nested/#stix-standard","title":"STIX standard","text":""},{"location":"usage/nested/#definition","title":"Definition","text":"<p>In the STIX 2.1 standard, objects can:</p> <ol> <li>Refer to other objects in directly in their <code>attributes</code>, by referencing one or multiple IDs.</li> <li>Have other objects directly embedded in the entity.</li> </ol>"},{"location":"usage/nested/#example","title":"Example","text":"<pre><code>{\n\"type\": \"intrusion-set\",\n\"spec_version\": \"2.1\",\n\"id\": \"intrusion-set--4e78f46f-a023-4e5f-bc24-71b3ca22ec29\",\n\"created_by_ref\": \"identity--f431f809-377b-45e0-aa1c-6a4751cae5ff\", // nested reference to an identity\n\"object_marking_refs\": [\"marking-definition--34098fce-860f-48ae-8e50-ebd3cc5e41da\"], // nested reference to multiple marking defintions\n\"external_references\": [\n{\n\"source_name\": \"veris\",\n\"external_id\": \"0001AA7F-C601-424A-B2B8-BE6C9F5164E7\",\n\"url\": \"https://github.com/vz-risk/VCDB/blob/125307638178efddd3ecfe2c267ea434667a4eea/data/json/validated/0001AA7F-C601-424A-B2B8-BE6C9F5164E7.json\",    }\n],\n\"created\": \"2016-04-06T20:03:48.000Z\",\n\"modified\": \"2016-04-06T20:03:48.000Z\",\n\"name\": \"Bobcat Breakin\",\n\"description\": \"Incidents usually feature a shared TTP of a bobcat being released within the building containing network access...\",\n\"aliases\": [\"Zookeeper\"],\n\"goals\": [\"acquisition-theft\", \"harassment\", \"damage\"]\n}\n</code></pre> <p>In the previous example, we have 2 nested references to other objects in:</p> <pre><code>\"created_by_ref\": \"identity--f431f809-377b-45e0-aa1c-6a4751cae5ff\", // nested reference to an identity\n\"object_marking_refs\": [\"marking-definition--34098fce-860f-48ae-8e50-ebd3cc5e41da\"], // nested reference to multiple marking defintions\n</code></pre> <p>But we also have a nested object within the entity (an <code>External Reference</code>):</p> <pre><code>\"external_references\": [\n{\n\"source_name\": \"veris\",\n\"external_id\": \"0001AA7F-C601-424A-B2B8-BE6C9F5164E7\",\n\"url\": \"https://github.com/vz-risk/VCDB/blob/125307638178efddd3ecfe2c267ea434667a4eea/data/json/validated/0001AA7F-C601-424A-B2B8-BE6C9F5164E7.json\",    }\n]\n</code></pre>"},{"location":"usage/nested/#implementation","title":"Implementation","text":""},{"location":"usage/nested/#modelization","title":"Modelization","text":"<p>In OpenCTI, all nested references and objects are modelized as relationships, to be able to pivot more easily on labels, external references, kill chain phases, marking definitions, etc.</p> <p></p>"},{"location":"usage/nested/#import-export","title":"Import &amp; export","text":"<p>When importing and exporting data to/from OpenCTI, the translation between nested references and objects to full-fledged nodes and edges is automated and therefore transparent for the users. Here is an example with the object in the graph above:</p> <pre><code>{\n\"id\": \"file--b6be3f04-e50f-5220-af3a-86c2ca66b719\",\n\"spec_version\": \"2.1\",\n\"x_opencti_description\": \"...\",\n\"x_opencti_score\": 50,\n\"hashes\": {\n\"MD5\": \"b502233b34256285140676109dcadde7\"\n},\n\"labels\": [\n\"cookiecutter\",\n\"clouddata-networks-1\"\n],\n\"external_references\": [\n{\n\"source_name\": \"Sekoia.io\",\n\"url\": \"https://app.sekoia.io/intelligence/objects/indicator--3e6d61b4-d5f0-48e0-b934-fdbe0d87ab0c\"\n}\n],\n\"x_opencti_id\": \"8a3d108f-908c-4833-8ff4-4d6fc996ce39\",\n\"type\": \"file\",\n\"created_by_ref\": \"identity--b5b8f9fc-d8bf-5f85-974e-66a7d6f8d4cb\",\n\"object_marking_refs\": [\n\"marking-definition--613f2e26-407d-48c7-9eca-b8e91df99dc9\"\n]\n}\n</code></pre>"},{"location":"usage/notifications/","title":"Notifications and alerting","text":"<p>It is possible to receive <code>notifications</code> via email or directly on the platform interface triggered by events such as entity <code>creation</code>, <code>modification</code> or <code>deletion</code>.</p> <p> </p>"},{"location":"usage/notifications/#triggers","title":"Triggers","text":"<p>Each user can create their own triggers. Triggers listen all the events that respect their filters and their event types, and notify the user of those events via the chosen outcome(s) (user interface or email).</p> <p>A platform administrator can create and manage triggers for a user, who will remain the <code>trigger administrator</code>, as well as for a group or an organization. Users belonging to this group or organization will then have <code>read-only</code> access rights on this trigger. The user can use filters to ensure that the created triggers are as accurate as possible.</p>"},{"location":"usage/notifications/#instance-triggers","title":"Instance triggers","text":"<p>Instance triggers are specific live triggers that listen to one or several instance(s). To create an instance trigger, you can</p> <ul> <li>either use the general trigger creation form in the \u2018Triggers and digests\u2019 section,</li> <li>either click on the \u2018quick subscription\u2019 icon at the top right of an entity overview.</li> </ul> <p>An instance trigger on an entity X notifies the following events:</p> <ul> <li>update/deletion of X,</li> <li>creation/deletion of a relationship from/to X,</li> <li>creation/deletion of an entity that has X in its refs (examples: contains X, is shared with X, is created by X...),</li> <li>adding/removing X in the ref of an entity (examples: adding X in the author of an entity, adding X in a report\u2026).</li> </ul> <p>Note: The notification of an entity deletion can either provides from the real deletion of an entity, either from a modification of the entity that leads to the user loss of visibility for the entity.</p>"},{"location":"usage/notifications/#digest","title":"Digest","text":"<p>A digest allows triggering the sending of notifications based on <code>multiple triggers</code> over a given period.</p>"},{"location":"usage/overview/","title":"Overview","text":""},{"location":"usage/overview/#introduction","title":"Introduction","text":"<p>The following chapter aims at giving the reader a step-by-step description of what is available on the platform and the meaning of the different tabs and entries.</p> <p>When the user connects to the platform, the home page is the <code>Dashboard</code>. This <code>Dashboard</code> contains several visuals summarizing the types and quantity of data recently imported into the platform.</p> <p>Dashboard</p> <p>To get more information about the components of the default dashboard, you can consult the Getting started.</p> <p>The left side panel allows the user to navigate through different windows and access different views and categories of knowledge.</p> <p></p>"},{"location":"usage/overview/#structure","title":"Structure","text":""},{"location":"usage/overview/#the-hot-knowledge","title":"The \"hot knowledge\"","text":"<p>The first part of the platform in the left menu is dedicated to what we call the \"hot knowledge\", which means this is the entities and relationships which are added on a daily basis in the platform and which generally require work / analysis from the users.</p> <ul> <li><code>Analysis</code>: all containers which convey relevant knowledge such as reports, groupings and malware analysis.</li> <li><code>Cases</code>: all types of case like incident responses, requests for information, for takedown, etc.</li> <li><code>Events</code>: all incidents &amp; alerts coming from operational systems as well as sightings.</li> <li><code>Observations</code>: all technical data in the platform such as observables, artifacts and indicators.</li> </ul>"},{"location":"usage/overview/#the-cold-knowledge","title":"The \"cold knowledge\"","text":"<p>The second part of the platform in the left menu is dedicated to the \"cold knowledge\", which means this is the entities and relationships used in the hot knowledge. You can see this as the \"encyclopedia\" of all pieces of knowledge you need to get context: threats, countries, sectors, etc.</p> <ul> <li><code>Threats</code>: all threats entities from campaigns to threat actors, including intrusion sets.</li> <li><code>Arsenal</code>: all tools and pieces of malware used and/or targeted by threats, including vulnerabilities.</li> <li><code>Techniques</code>: all objects related to tactics and techniques used by threats (TTPs, etc.).</li> <li><code>Entities</code>: all non-geographical contextual information such as sectors, events, organizations, etc.</li> <li><code>Locations</code>: all geographical contextual information, from cities to regions, including precise positions.</li> </ul>"},{"location":"usage/overview/#hide-categories","title":"Hide categories","text":"<p>You can customize the experience in the platform by hiding some categories in the left menu, whether globally or for a specific role.</p>"},{"location":"usage/overview/#hide-categories-globally","title":"Hide categories globally","text":"<p>In the <code>Settings &gt; Parameters</code>, it is possible for the platform administrator to hide categories in the platform for all users.</p> <p></p>"},{"location":"usage/overview/#hide-categories-in-roles","title":"Hide categories in roles","text":"<p>In OpencTI, the different roles are highly customizable. It is possible to defined default dashboards, triggers, etc. but also be able to hide categories in the roles:</p> <p></p>"},{"location":"usage/overview/#presentation-of-a-typical-page-in-opencti","title":"Presentation of a typical page in OpenCTI","text":"<p>Although there are many different entities in OpenCTI and many different tabs, most of them are quite similar and only have minor differences from the other, mostly due to some of their characteristics, which requires specific fields or do not require some fields which are necessary for the other. </p> <p>In this part will only be detailed a general outline of a \"typical\" OpenCTI page. The specifies of the different entities will be detailed in the corresponding pages below (Activities and Knowledge).</p> <p></p>"},{"location":"usage/overview/#overview_1","title":"Overview","text":"<p>In the <code>Overview</code> tab on the entity, you will find all properties of the entity as well as the recent activities.</p> <p>First, you will find the <code>Details</code> section, where are displayed all properties specific to the type of entity you are looking at, an example below with a piece of malware:</p> <p></p> <p>Thus, in the <code>Basic information</code> section, are displayed all common properties to all objects in OpenCTI, such as the marking definition, the author, the labels (ie. tags), etc.</p> <p></p> <p>Below these two sections, you will find latest modifications in the Knowledge base related to the Entity:</p> <ul> <li><code>Latest created relationships</code>: display the latest relationships that have been created from or to this Entity. For example, latest Indicators of Compromise and associated Threat Actor of a Malware.</li> <li><code>latest containers about the object</code>: display all the Cases and Analysis that contains this Entity. For example, the latest Reports about a Malware.</li> <li><code>External references</code>: display all the the external sources associated with the Entity. You will often find here links to external reports or webpages from where Entity's information came from.</li> <li><code>History</code>: display the latest chronological modifications of the Entity and its relationships that occured in the platform, in order to traceback any alteration.</li> </ul> <p> </p> <p>Last, all Notes written by users of the platform about this Entity are displayed in order to access unstructured analysis comments.</p>"},{"location":"usage/overview/#knowledge","title":"Knowledge","text":"<p>In the <code>Knowledge</code> tab, which is the central part of the entity, you will find all the Knowledge related to the current entity. The <code>Knowledge</code> tab is different for Analysis (<code>Report</code>, <code>Groupings</code>) and Cases (<code>Incident response</code>, <code>Request for Information</code>, <code>Request for Takedown</code>) entities than for all the other entity types.</p> <ul> <li>The <code>Knowledge</code> tab of those entities (who represents Analyses or Cases that can contains a collection of Objects) is the place to integrate and link together entities. For more information on how to integrate information in OpenCTI using the knowledge tab of a report, please refer to the part Manual creation.</li> <li><code>Knowledge</code> tabs of any other entity (that does not aim to contain a collection of Objects) gather all the entities which have been at some point linked to the entity the user is looking at (for instance, as shown in the following capture, the <code>Knowledge</code> tab of Intrusion set APT29) gives access to the list of all entities APT29 is attributed to, all victims the intrusion set has targeted, all its campaigns, TTPs, malwares etc. For entities to appear in theses tabs under <code>Knowledge</code>, they need to have been linked to the entity directly or have been computed with the inference engine (to come).</li> </ul> <p></p>"},{"location":"usage/overview/#analysis","title":"Analysis","text":"<p>The <code>Analysis</code> tab contains the list of all Analysis (<code>Report</code>, <code>Groupings</code>) and Cases (<code>Incident response</code>, <code>Request for Information</code>, <code>Request for Takedown</code>) in which the entity has been identified.</p> <p></p> <p>By default, this tab display the list, but you can also display the content of all the listed Analyses on a graph, allowing you to explore all their Knowledge and have a glance of the context around the Entity.</p> <p></p>"},{"location":"usage/overview/#data","title":"Data","text":"<p>The Data tab contains documents that are associated to the object and were either :</p> <ul> <li>Uploaded to the platform : for instance the PDF document containing the text of the report</li> <li>Generated from the platform to be downloaded : a JSON or CSV file containing information on the object and generated by the user.</li> <li>associated to an external reference</li> </ul> <p>Analyst Workbench can also be created from here. They will contain the entity by default. </p>"},{"location":"usage/overview/#history","title":"History","text":"<p>The <code>History</code> tab display the history of change of the Entity, update of attributes, creation of relations, ...</p> <p>Because of the volumes of information the history is written in a specific index by the history connector (https://www.notion.so/luatix/History-17503579a70c467ba02ec11350c593bf) that consume the redis stream to rebuild the history for the UI. </p> <p>Less frequent tabs are the following:</p> <ul> <li>The <code>Indicators</code> tab (for all the threats and the entities in arsenal - except the courses of action -)</li> <li>The <code>Observables</code> tab (for reports, observed data)</li> <li>the <code>Entities</code> tab (for reports and observed data)</li> <li>the <code>Sightings</code> tab (for Indicators and observables)</li> </ul>"},{"location":"usage/pivoting/","title":"Pivot and investigate","text":"<p>In Opencti, all data can be represented as a large knowledge graph: everything is linked to something.  You can pivot on any entity and on any relationship you have in your platform, using investigations.</p> <p>Investigations are available on the top right of the top bar:</p> <p></p> <p>Investigations are organized by workspace. When you create a new empty workspace, it will only be visible by you and enables you to work on your investigation before sharing it.</p> <p>In your workspace, you can add entities that you want to investigate, visualize the data linked to these entities, add relationships, and export your investigation graph in pdf, image or as new stix report.</p> <p></p>"},{"location":"usage/pivoting/#add-and-expand-an-entity","title":"Add and expand an entity","text":"<p>You can add any existing entity of the platform to your investigation.</p> <p></p> <p>Once added, you can select the entity, and see its details in the right.  In this bottom right menu, right next to \"Add en entity\", you can expand the selected entity and select the number of linked entities you want to see in your investigation.</p> <p></p>"},{"location":"usage/pivoting/#add-a-relationship","title":"Add a relationship","text":"<p>You can add a relationship between entities directly in your investigation.</p> <p></p>"},{"location":"usage/pivoting/#export-your-investigation","title":"Export your investigation","text":"<p>You can export your investigation in PDF or image format.  You can also download all the content of your investigation graph in a Report stix bundle (investigation is automatically converted).</p> <p></p>"},{"location":"usage/search/","title":"Search for knowledge","text":"<p>In OpenCTI, you have access to different capabilities to be able to search for knowledge in the platform. In most cases, a search by keyword can be refined with additional filters for instance on the type of object, the author etc.</p>"},{"location":"usage/search/#global-search","title":"Global search","text":"<p>The global search is always available in the top bar of the platform.</p> <p></p> <p>This search covers all STIX Domain Objects (SDOs) and STIX Cyber Observables (SCOs) in the platform. The search results are sorted according to the following behaviour:</p> <ul> <li>Priority 1 for exact matching of the keyword in one attribute of the objects.</li> <li>Priority 2 for partial matching of the keyword in the <code>name</code>, the <code>aliases</code> and the <code>description</code> attributes (full text search).</li> <li>Priority 3 for partial matching of the keyword in all other attributes (full text search).</li> </ul> <p>If you get unexpected result, it is always possible to add some filters after the initial search:</p> <p></p> <p>Also, using the <code>Advanced search</code> button, it is possible to directly put filters in a global search:</p> <p></p>"},{"location":"usage/search/#bulk-search","title":"Bulk search","text":"<p>The bulk search capabilities in available in the top bar of the platform and allow you to copy paste a list of keyword or objects (ie. list of domains, list of IP addresses, list of vulnerabilities, etc.) to search in the platform:</p> <p></p> <p>When searching in bulk, OpenCTI is only looking for an exact match in some properties:</p> <ul> <li><code>name</code></li> <li><code>aliases</code></li> <li><code>x_opencti_aliases</code></li> <li><code>x_mitre_id</code></li> <li><code>value</code></li> <li><code>subject</code></li> <li><code>abstract</code></li> <li><code>hashes_MD5</code></li> <li><code>hashes_SHA1</code></li> <li><code>hashes_SHA256</code></li> <li><code>hashes_SHA512</code></li> <li><code>x_opencti_additional_names</code></li> </ul> <p>When something is not found, it appears in the list as <code>Unknown</code> and will be excluded if you choose to export your search result in a JSON STIX bundle or in a CSV file.</p> <p></p>"},{"location":"usage/search/#contextual-search","title":"Contextual search","text":"<p>In most of the screens of knowledge, you always have a contextual search bar allowing you to filter the list you are on:</p> <p></p> <p>The search keyword used here is taken into account if you decide to export the current view in a file such as a JSON STIX bundle or a CSV file.</p>"},{"location":"usage/search/#other-search-bars","title":"Other search bars","text":"<p>Some other screens can contain search bars for specific purposes. For instance, in the graph views to filter the nodes displayed on the graph:</p> <p></p>"},{"location":"usage/workbench/","title":"Analyst workbench","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"},{"location":"usage/workflows/","title":"Workflows and assignation","text":"<p>Under construction</p> <p>We are doing our best to complete this page.  If you want to participae, dont hesitate to join the Filigran Community on Slack  or submit your pull request on the Github doc repository.</p>"}]}