{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"OpenCTI Documentation Space","text":"<p>Welcome to the OpenCTI Documentation space. Here you will be able to find all documents, meeting notes and presentations about the platform.</p> <p>Need more help?</p> <p>We are doing our best to keep this documentation complete, accurate and up to date. If you still have questions or you find something which is not sufficiently explained, join the Filigran Community on Slack.</p>"},{"location":"#introduction","title":"Introduction","text":"<p>OpenCTI is an open source platform allowing organizations to manage their cyber threat intelligence knowledge and observables. It has been created in order to structure, store, organize and visualize technical and non-technical information about cyber threats.</p>"},{"location":"#getting-started","title":"Getting started","text":"<ul> <li> <p> Deployement &amp; Setup</p> <p>Learn how to deploy and configure the platform as well as launch connectors to get the first data in OpenCTI.</p> <p> Deploy now</p> </li> <li> <p> User Guide</p> <p>Understand how to use the platform, explore the knowledge, import and export information, create dashboard, etc.</p> <p> Explore</p> </li> <li> <p> Administration</p> <p>Know how to administrate OpenCTI, create users and groups using RBAC / segregation, put retention policies and custom taxonomies.</p> <p> Customize</p> </li> </ul>"},{"location":"#latest-blog-posts","title":"Latest blog posts","text":"<p>Articles</p> <p>All tutorials are published directly on the Medium blog, this section provides a comprehensive list of the most important ones.</p>"},{"location":"administration/parameters/","title":"Platform","text":""},{"location":"deployment/configuration/","title":"Configuration","text":"<p>In this section, we learn how to configure OpenCTI to have it tailored to our production and development needs. </p> <p>Here are the configuration keys, for both Docker (environment variables) and manual deployment.</p>  \ud83d\udca1 The equivalent of a config variable in environment variables is the usage of a double underscores (__) for a level of config. Example: `\"providers\": {     \"ldap\": {       \"strategy\": \"LdapStrategy\"    } }` will become `PROVIDERS__LDAP__STRATEGY=LdapStrategy`  If you need to put a list of element for the key, it must have a special formatting. Example for redirect uris for openid config:  `\"PROVIDERS__OPENID__CONFIG__REDIRECT_URIS=[\\\"https://demo.opencti.io/auth/oic/callback\\\"]\"`    \ud83d\udc49 To change the allowed memory of the platform process, you can use the environment variable `NODE_OPTIONS=--max-old-space-size=8096` (where 8096 is the amount of memory in MB).   <p>API / Front</p>  \ud83d\udca1 Example to enforce references:   <pre><code>\"enforce_references\": [\n\"Threat-Actor\",\n\"Intrusion-Set\",\n...\n]\n</code></pre> <p>Schedulers / engines</p> <p>Dependencies</p>"},{"location":"deployment/configuration/#worker","title":"Worker","text":"<p>The Python worker can be configured manually using the configuration file <code>config.yml</code> or through environment variables.</p> <p>Python worker</p>"},{"location":"deployment/configuration/#dependencies","title":"Dependencies","text":"<p>Dependencies have their own set of configuration that you can found in their specific documentation.</p>  \ud83d\udca1 Sometime the documentation doesn't have every options so we try to fill the gap here."},{"location":"deployment/configuration/#elasticsearch-memory","title":"ElasticSearch memory","text":"<p>If you want to adapt the memory consumption of ElasticSearch, you can use theses options:</p> <pre><code># Add the followiung environment variable:\n\"ES_JAVA_OPTS=-Xms8g -Xmx8g\"\n</code></pre>"},{"location":"deployment/configuration/#authentication","title":"Authentication","text":""},{"location":"deployment/configuration/#introduction","title":"Introduction","text":"<p>OpenCTI supports several authentication providers. If you configure multiple strategies, they will be tested in the order you declared them.</p>  \ud83d\udca1 You need to configure/activate only that you really want to propose to your users in term of authentication   <p>The product proposes two kind of authentication strategy:</p> <ul> <li>Form (asking user for a user/password)</li> <li>Buttons (click with authentication on an external system)</li> </ul>"},{"location":"deployment/configuration/#supported-strategies","title":"Supported Strategies","text":"<p>Under the hood we technically use the strategies provided by http://www.passportjs.org/</p> <p>We integrate a subset of the strategies available with passport we if you need more we can theatrically integrate all the passport strategies.</p>"},{"location":"deployment/configuration/#localstrategy-form","title":"LocalStrategy (form)","text":"<p>This strategy used the OpenCTI database as user management.</p> <p>OpenCTI use this strategy as the default but its not the one we recommend for security reason.</p> <pre><code>\"local\": {\n\"strategy\": \"LocalStrategy\",\n\"config\": {\n\"disabled\": false\n}\n}\n</code></pre>  \ud83d\udca1 Please use the LDAP/Auth0/OpenID strategy for production deployment"},{"location":"deployment/configuration/#ldapstrategy-form","title":"LdapStrategy (form)","text":"<p>This strategy can be used to authenticate your user with your company LDAP. Based on http://www.passportjs.org/packages/passport-ldapauth/</p> <pre><code>\"ldap\": {\n\"strategy\": \"LdapStrategy\",\n\"config\": {\n\"url\": \"ldaps://mydc.domain.com:686\",\n\"bind_dn\": \"cn=Administrator,cn=Users,dc=mydomain,dc=com\",\n\"bind_credentials\": \"MY_STRONG_PASSWORD\",\n\"search_base\": \"cn=Users,dc=mydomain,dc=com\",\n\"search_filter\": \"(cn={{username}})\",\n\"mail_attribute\": \"mail\",\n// \"account_attribute\": \"givenName\",\n// \"firstname_attribute\": \"cn\",\n// \"lastname_attribute\": \"cn\",\n\"account_attrgroup_search_filteribute\": \"givenName\",\n\"allow_self_signed\": true\n}\n}\n</code></pre> <p>If you would like to use LDAP groups to automatically associate a role and/or group to users depending of its group.</p> <pre><code>\"group_search_base\": \"cn=Groups,dc=mydomain,dc=com\",\n\"group_search_filter\": \"(member={{dn}})\",\n\"roles_management\": {\n\"group_attribute\": \"cn\",\n\"groups_mapping\": [\"GROUP_NAME:Administrator\", \"GROUP_NAME_2:ROLE_NAME\", ...]\n}\n\"groups_management\": {\n\"group_attribute\": \"cn\",\n\"groups_mapping\": [\"GROUP_NAME:AdminGroup\", \"GROUP_NAME_2:GROUP_NAME\", ...]\n}\n</code></pre>"},{"location":"deployment/configuration/#samlstrategy-button","title":"SamlStrategy (button)","text":"<p>This strategy can be used to authenticate your user with your company SAML. Based on http://www.passportjs.org/packages/passport-saml/</p> <pre><code>\"saml\": {\n\"identifier\": \"saml\",\n\"strategy\": \"SamlStrategy\",\n\"config\": {\n\"issuer\": \"mytestsaml\",\n// \"account_attribute\": \"nameID\",\n// \"firstname_attribute\": \"nameID\",\n// \"lastname_attribute\": \"nameID\",\n\"entry_point\": \"https://auth.citeum.org/auth/realms/citeum/protocol/saml\",\n\"saml_callback_url\": \"http://localhost:4000/auth/saml/callback\",\n// \"private_key\": \"MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwg...\",\n\"cert\": \"MIICmzCCAYMCBgF2Qt3X1zANBgkqhkiG9w0BAQsFADARMQ8w...\",\n\"roles_management\": { // Only if you need to\n\"role_attributes\": [\"Role\"],\n\"roles_mapping\": [\"asso_limeo_founder:Administrator\"]\n}\n}\n},\n</code></pre> <ul> <li>cert is mandatory (pem format), used to validate the SAML response</li> <li>private_key (pem format) is optional, only required if you want to sign the SAML client request</li> </ul>  \ud83d\udca1 **Be careful to put the cert/private key in PEM format. A lot of system give you the keys in X509 / PCKS12 format and so need to be converted.** **Example to extract from PCKS12**: openssl pkcs12 -in keystore.p12 -out newfile.pem -nodes   <p>Docker style:</p> <pre><code>- PROVIDERS__SAML__STRATEGY=SamlStrategy - \"PROVIDERS__SAML__CONFIG__LABEL=Login with SAML\"\n- PROVIDERS__SAML__CONFIG__ISSUER=mytestsaml\n- PROVIDERS__SAML__CONFIG__ENTRY_POINT=https://auth.citeum.org/auth/realms/citeum/protocol/saml\n- PROVIDERS__SAML__CONFIG__SAML_CALLBACK_URL=http://localhost:4000/auth/saml/callback\n- PROVIDERS__SAML__CONFIG__CERT=MIICmzCCAYMCBgF2Qt3X1zANBgkqhkiG9w0BAQsFADARMQ8w\n</code></pre>"},{"location":"deployment/configuration/#auth0strategy-button","title":"Auth0Strategy (button)","text":"<p>This strategy permits to use https://auth0.com/ service to handle the authentication.</p> <p>Based on http://www.passportjs.org/packages/passport-auth0/</p> <pre><code>\"authzero\": {\n\"identifier\": \"auth0\",\n\"strategy\": \"Auth0Strategy\",\n\"config\": {\n\"clientID\": \"XXXXXXXXXXXXXXXXXX\",\n\"baseURL\": \"https://demo.opencti.io\",\n\"clientSecret\": \"XXXXXXXXXXXXXXXXXX\",\n\"callback_url\": \"https://demo.opencti.io/auth/auth0/callback\",\n\"domain\": \"luatix.eu.auth0.com\",\n\"audience\": \"XXXXXXXXXXXXXXX\",\n\"scope\": \"openid email profile XXXXXXXXXXXXXXX\"\n}\n}\n</code></pre>"},{"location":"deployment/configuration/#openidconnectstrategy-button","title":"OpenIDConnectStrategy (button)","text":"<p>This strategy can use the https://openid.net/connect/ protocol to handle the authentication.</p> <p>Based on https://github.com/panva/node-openid-client that is more powerful than the passport one.</p> <pre><code>\"oic\": {\n\"identifier\": \"oic\",\n\"strategy\": \"OpenIDConnectStrategy\",\n\"config\": {\n\"label\": \"Login with OpenID\",\n\"issuer\": \"https://xxxxxxx/auth/realms/xxxx\",\n\"client_id\": \"XXXXXXXXXXXXXXXXXX\",\n\"client_secret\": \"XXXXXXXXXXXXXXXXXX\",\n\"redirect_uris\": [\"https://demo.opencti.io/auth/oic/callback\"]\n}\n}\n</code></pre> <p>Docker style:</p> <pre><code>- PROVIDERS__OPENID__STRATEGY=OpenIDConnectStrategy - \"PROVIDERS__OPENID__CONFIG__LABEL=Login with OpenID\"\n- PROVIDERS__OPENID__CONFIG__ISSUER=https://xxxxxxx/auth/realms/xxxx\n- PROVIDERS__OPENID__CONFIG__CLIENT_ID=XXXXXXXXXXXXXXXXXX\n- PROVIDERS__OPENID__CONFIG__CLIENT_SECRET=XXXXXXXXXXXXXXXXXX\n- \"PROVIDERS__OPENID__CONFIG__REDIRECT_URIS=[\\\"https://demo.opencti.io/auth/oic/callback\\\"]\"\n</code></pre> <p>Examples of roles mapping in OpenID strategies (for group mappings, just replace \u201croles\u201d with \u201cgroups\u201d).</p> <p>In the mapping, the syntax is <code>OpenID-Role:OpenCTI-Group-Name</code>.</p> <pre><code>\"roles_management\": {\n\"roles_scope\": \"roles\",\n\"roles_path\": [\"roles\", \"realm_access.roles\", \"resource_access.account.roles\"],\n\"roles_mapping\": [\"asso_luatix_admin:Administrator\", \"asso_luatix_supporter:Default\", \"asso_luatix_active:Default\", \"asso_luatix_sponsor:Default\", \"asso_luatix_founder:Default\"]\n}\n</code></pre> <p>In Docker style:</p> <pre><code>- \"PROVIDERS__OPENID__CONFIG__ROLES_MANAGEMENT__ROLES_SCOPE=roles\"\n- \"PROVIDERS__OPENID__CONFIG__ROLES_MANAGEMENT__ROLES_PATH=[\\\"roles\\\", \\\"realm_access.roles\\\", \\\"resource_access.account.roles\\\"]\"\n- \"PROVIDERS__OPENID__CONFIG__ROLES_MANAGEMENT__ROLES_MAPPING=[\\\"asso_luatix_admin:Administrator\\\", \\\"asso_luatix_supporter:Default\\\", \\\"asso_luatix_active:Default\\\", \\\"asso_luatix_sponsor:Default\\\", \\\"asso_luatix_founder:Default\\\"]\"\n</code></pre>"},{"location":"deployment/configuration/#facebookstrategy-button","title":"FacebookStrategy (button)","text":"<p>This strategy can authenticate your users with Facebook</p> <p>Based on http://www.passportjs.org/packages/passport-facebook/</p> <pre><code>\"facebook\": {\n\"identifier\": \"facebook\",\n\"strategy\": \"FacebookStrategy\",\n\"config\": {\n\"client_id\": \"XXXXXXXXXXXXXXXXXX\",\n\"client_secret\": \"XXXXXXXXXXXXXXXXXX\",\n\"callback_url\": \"https://demo.opencti.io/auth/facebook/callback\"\n}\n}\n</code></pre>"},{"location":"deployment/configuration/#googlestrategy-button","title":"GoogleStrategy (button)","text":"<p>This strategy can authenticate your users with Google</p> <p>Based on http://www.passportjs.org/packages/passport-google-oauth/</p> <pre><code>\"google\": {\n\"identifier\": \"google\",\n\"strategy\": \"GoogleStrategy\",\n\"config\": {\n\"client_id\": \"XXXXXXXXXXXXXXXXXX\",\n\"client_secret\": \"XXXXXXXXXXXXXXXXXX\",\n\"callback_url\": \"https://demo.opencti.io/auth/google/callback\"\n}\n}\n</code></pre>"},{"location":"deployment/configuration/#githubstrategy-button","title":"GithubStrategy (button)","text":"<p>This strategy can authenticate your users with Github</p> <p>Based on http://www.passportjs.org/packages/passport-github/</p> <pre><code>\"github\": {\n\"identifier\": \"github\",\n\"strategy\": \"GithubStrategy\",\n\"config\": {\n\"client_id\": \"XXXXXXXXXXXXXXXXXX\",\n\"client_secret\": \"XXXXXXXXXXXXXXXXXX\",\n\"callback_url\": \"https://demo.opencti.io/auth/github/callback\"\n}\n}\n</code></pre> <p>-</p>"},{"location":"deployment/configuration/#clientcertstrategy-button","title":"ClientCertStrategy (button)","text":"<p>This strategy can authenticate a user based on ssl client certificate. For this you need to configure your OCTI to start in https, for example</p> <pre><code>\"port\": 443,\n\"https_cert\": {\n\"key\": \"/cert/server_key.pem\",\n\"crt\": \"/cert/server_cert.pem\",\n\"reject_unauthorized\":true\n},\n</code></pre> <p>And the add the ClientCertStrategy</p> <pre><code>\"cert\": {\n\"strategy\":\"ClientCertStrategy\",\n\"config\": {\n\"label\":\"CLIENT CERT\"\n}\n}\n</code></pre> <p>Then when accessing for the first time OCTIm your browser will ask for the certificate you want to use.</p>"},{"location":"deployment/configuration/#examples","title":"Examples","text":""},{"location":"deployment/configuration/#ldap-then-fallback-to-local","title":"LDAP then fallback to local","text":"<p>In this example the users have a login form and need to enter username / password.</p> <p>Authentication is done on LDAP first, then locally if user not authenticated by the LDAP, then fail.</p> <p>If you use local deployment, here are an example for the <code>production.json</code> file:</p> <pre><code>\"providers\": {\n\"ldap\": {\n\"strategy\": \"LdapStrategy\",\n\"config\": {\n\"url\": \"ldap://mydc.mydomain.com:389\",\n\"bind_dn\": \"cn=Administrator,cn=Users,dc=mydomain,dc=com\",\n\"bind_credentials\": \"MY_STRONG_PASSWORD\",\n\"search_base\": \"cn=Users,dc=mydomain,dc=com\",\n\"search_filter\": \"(cn={{username}})\",\n\"mail_attribute\": \"mail\",\n\"account_attribute\": \"givenName\"\n}\n},\n\"local\": {\n\"strategy\": \"LocalStrategy\"\n\"config\": {\n\"disabled\": false\n}\n}\n}\n</code></pre> <p>If you use docker deployment, here an example for the <code>docker-compose.yml</code> file:</p> <pre><code>- PROVIDERS__LDAP__STRATEGY=LdapStrategy\n- PROVIDERS__LDAP__CONFIG__URL=ldaps://mydc.limeo.org:636\n- PROVIDERS__LDAP__CONFIG__BIND_DN=cn=Administrator,cn=Users,dc=limeo,dc=org\n- PROVIDERS__LDAP__CONFIG__BIND_CREDENTIALS=XXXXXXXXXX\n- PROVIDERS__LDAP__CONFIG__SEARCH_BASE=cn=Users,dc=limeo,dc=org\n- PROVIDERS__LDAP__CONFIG__SEARCH_FILTER=(cn={{username}})\n- PROVIDERS__LDAP__CONFIG__MAIL_ATTRIBUTE=mail\n- PROVIDERS__LDAP__CONFIG__ACCOUNT_ATTRIBUTE=givenName\n- PROVIDERS__LDAP__CONFIG__ALLOW_SELF_SIGNED=true\n- PROVIDERS__LOCAL__STRATEGY=LocalStrategy\n</code></pre>"},{"location":"deployment/connectors/","title":"Connectors","text":""},{"location":"deployment/connectors/#introduction","title":"Introduction","text":"\ud83d\udca1 You are looking for the available connectors? The list is in the [OpenCTI Ecosystem](https://www.notion.so/OpenCTI-Ecosystem-868329e9fb734fca89692b2ed6087e76).   <p>Connectors are the cornerstone of the OpenCTI platform and allow organizations to easily ingest, enrich or export new data on the platform. According to their functionality and use case, they are categorized in following classes:</p> <p>External Import Connector</p> <p>Automatically retrieve information from an external entity or service and import it into OpenCTI</p> <p>Stream Input Connector</p> <p>Connect to a data stream and continously ingest the retrieved information into OpenCTI. When used in combination with EDR systems like Tanium, the connector is also able to answer the originating system and turn this into a two way interaction between another system and OpenCTI.</p> <p>Internal Enrichment Connector</p> <p>SDOs and SCOs can be enriched using external lookup services to increase the knowledge of that object in OpenCTI. An example would be a whois lookup for an IP address.</p> <p>Internal Import File Connector</p> <p>Information from an uploaded file can be extracted and ingested into OpenCTI. Examples are files attached to a report or a json (STIX2) file.</p> <p>Internal Export Connector</p> <p>Information stored in OpenCTI can be extracted into different file formats like .csv or .json (STIX 2).</p> <p>Those connectors should be launched with a user that has an \u201cAdministrator\u201d role (with bypass all capabilities enabled).</p> <p></p> <p>API Interactions</p> <p>API interactions are not connectors per definition, nonetheless they allow a script or a program to interact with OpenCTI using a client library.</p>"},{"location":"deployment/connectors/#information-processing","title":"Information Processing","text":"<p>Every data the connector wants to sent to OpenCTI has to be converted into a STIX2 object, which will then be pushed via a messaging system to the OpenCTI worker. </p> <p>The worker is responsible for the error and performance handling and for interacting with the OpenCTI API interface for creating or updating the respective objects.</p>  \ud83d\udca1 For the moment, only a valid STIX2 bundle is supported, by we intend to support CSV and other formats in the future.   <p></p>"},{"location":"deployment/connectors/#connector-configuration","title":"Connector configuration","text":"<p>All connectors have to be able to access to the OpenCTI API. To allow this connection, they have 2 mandatory configuration parameters, the <code>OPENCTI_URL</code> and the <code>OPENCTI_TOKEN</code>. In addition of these 2 parameters, connectors have other mandatory parameters that need to be set in order to get them work.</p>  \u26a0\ufe0f Be careful, we advise you to use a dedicated token for each of your connector. So you have to create a specific user for each of your connector.   **All users for connectors should have the \u201cConnector\u201d role except \u201cWorkers\u201d and \u201cinternal-import-files/internal-export-files Connectors\u201d which should run with an Administrator user.**  You can see the user token by clicking on \"Edit\" on a user in the Settings / Accesses / Users panel. Please see the section *Create Connector User and Role* at the end of this page for detailed user and role creation.   <p>Example in a <code>docker-compose.yml</code> file:</p> <p>Example in a <code>config.yml</code> file:</p> <pre><code>- CONNECTOR_ID=ChangeMe\n- CONNECTOR_TYPE=EXTERNAL_IMPORT\n- CONNECTOR_NAME=MITRE ATT&amp;CK\n- CONNECTOR_SCOPE=identity,attack-pattern,course-of-action,intrusion-set,malware,tool,report\n- CONNECTOR_CONFIDENCE_LEVEL=3\n- CONNECTOR_UPDATE_EXISTING_DATA=true\n- CONNECTOR_LOG_LEVEL=info\n</code></pre> <pre><code>-connector:\nid: 'ChangeMe'\ntype: 'EXTERNAL_IMPORT'\nname: 'MITRE ATT&amp;CK'\nscope: 'identity,attack-pattern,course-of-action,intrusion-set,malware,tool,report'\nconfidence_level: 3\nupdate_existing_data: true\nlog_level: 'info'\n</code></pre>"},{"location":"deployment/connectors/#docker-activation","title":"Docker activation","text":"<p>You can either directly run the Docker image of connectors or add them to your current <code>docker-compose.yml</code> file.</p>"},{"location":"deployment/connectors/#add-a-connector-to-your-deployment","title":"Add a connector to your deployment","text":"<p>For instance, to enable the MISP connector, you can add a new service to your <code>docker-compose.yml</code> file:</p> <pre><code>  connector-misp:\n    image: opencti/connector-misp:latest\n    environment:\n      - OPENCTI_URL=http://localhost\n      - OPENCTI_TOKEN=ChangeMe\n      - CONNECTOR_ID=ChangeMe\n      - CONNECTOR_TYPE=EXTERNAL_IMPORT\n      - CONNECTOR_NAME=MISP\n      - CONNECTOR_SCOPE=misp\n      - CONNECTOR_CONFIDENCE_LEVEL=3\n- CONNECTOR_UPDATE_EXISTING_DATA=false\n      - CONNECTOR_LOG_LEVEL=info\n      - MISP_URL=http://localhost # Required\n      - MISP_KEY=ChangeMe # Required\n      - MISP_SSL_VERIFY=False # Required\n      - MISP_CREATE_REPORTS=True # Required, create report for MISP event\n      - MISP_REPORT_CLASS=MISP event # Optional, report_class if creating report for event\n      - MISP_IMPORT_FROM_DATE=2000-01-01 # Optional, import all event from this date\n      - MISP_IMPORT_TAGS=opencti:import,type:osint # Optional, list of tags used for import events\n      - MISP_INTERVAL=1 # Required, in minutes\n    restart: always\n</code></pre>"},{"location":"deployment/connectors/#launch-a-standalone-connector","title":"Launch a standalone connector","text":"<p>To launch standalone connector, you can use the <code>docker-compose.yml</code> file of the connector itself. Just download the latest release and start the connector:</p> <pre><code>$ wget https://github.com/OpenCTI-Platform/connectors/archive/{RELEASE_VERSION}.zip\n$ unzip {RELEASE_VERSION}.zip\n$ cd connectors-{RELEASE_VERSION}/misp/\n</code></pre> <p>Change the configuration in the <code>docker-compose.yml</code> according to the parameters of the platform and of the targeted service. Then launch the connector:</p> <pre><code>$ docker-compose up\n</code></pre>  \u26a0\ufe0f Be careful that some connectors will try to connect to the RabbitMQ based on the RabbitMQ configuration provided for the OpenCTI platform. The connector must be able to reach RabbitMQ on the specified hostname and port. If you have a specific Docker network configuration, please be sure to adapt your `docker-compose.yml` file in such way that the connector container gets attached to the OpenCTI Network, e.g.:  <pre><code>networks:\ndefault:\nexternal: true\nname: opencti-docker_default\n</code></pre>  More details on: [https://docs.docker.com/compose/networking/#use-a-pre-existing-network](https://docs.docker.com/compose/networking/#use-a-pre-existing-network)"},{"location":"deployment/connectors/#manual-activation","title":"Manual activation","text":"<p>If you want to manually launch connector, you just have to install Python 3 and pip3 for dependencies:</p> <pre><code>$ apt install python3 python3-pip\n</code></pre> <p>Download the release of the connectors:</p> <pre><code>$ wget &lt;https://github.com/OpenCTI-Platform/connectors/archive/{RELEASE_VERSION}.zip&gt;\n$ unzip {RELEASE_VERSION}.zip\n$ cd connectors-{RELEASE_VERSION}/misp/src/\n</code></pre> <p>Install dependencies and initialize the configuration:</p> <pre><code>$ pip3 install -r requirements.txt\n$ cp config.yml.sample config.yml\n</code></pre> <p>Change the <code>config.yml</code> content according to the parameters of the platform and of the targeted service and launch the connector:</p> <pre><code>$ python3 misp.py\n</code></pre>  \u26a0\ufe0f Be careful that some connectors will try to connect to the RabbitMQ based on the RabbitMQ configuration provided for the OpenCTI platform. The connector must be able to reach RabbitMQ on the specified hostname and port."},{"location":"deployment/connectors/#connectors-status","title":"Connectors status","text":"<p>The connector status can be displayed in the dedicated section. You will be able to see the statistics of the RabbitMQ queue of the connector:</p> <p></p>  \u27a1\ufe0f If you encounter problems deploying OpenCTI or connectors, you can consult the [Troubleshooting](https://www.notion.so/Troubleshooting-4927527403c64d8aac2ac2e127ff464b) page. If not, go to the next section, the [Introduction](https://www.notion.so/Introduction-31c3e69442da4d84b8d6c60aa2a86833) page."},{"location":"deployment/connectors/#create-connector-user-and-role","title":"Create Connector User and Role","text":"<p>To have all the great history, access control and changelog features of OpenCTI you need to create a dedicated user per connector.</p> <p>This guide assumes OpenCTI is running at http://localhost:8080 please change for your real URL.</p> <p>The \u201cInternal Export File\u201d connectors should be launched with a user that has an \u201cAdministrator\u201d role (with bypass all capabilities enabled).</p>"},{"location":"deployment/connectors/#create-a-connector-role","title":"Create a connector role","text":"<p>Go to http://localhost:8080/dashboard/settings/accesses/roles</p> <p>Click on the red + in the bottom right corner and fill out the role details and click \"CREATE\".</p> <p></p> <p>After the Role has been created you can click on the three dots on the right side of the role table entry and click on \"Update\".</p> <p>The following capabilities are necessary for all connectors to work correctly:</p> <p></p>"},{"location":"deployment/connectors/#create-a-connector-user-and-attach-role","title":"Create a connector user and attach role","text":"<p>Now you can create a user per connector.</p> <p>Go to http://localhost:8080/dashboard/settings/accesses/users and click the red + in the bottom right corner.</p> <p>The \u201cInternal Export File\u201d connectors should be launched with a user that has an \u201cAdministrator\u201d role (with bypass all capabilities enabled).</p> <p>This example is creating a user for the Hygiene Connector. Remember to use a long and complex password for every user:</p> <p></p> <p>Now attach the role to the freshly created user by clicking on the user. In the user detail view click on the three dots next to the user name and click \"Update\". In the \"Roles\" section click into the line and click on \"Connectors\" to enable the Role for the user immediately.</p>"},{"location":"deployment/installation/","title":"Installation","text":""},{"location":"deployment/installation/#using-docker","title":"Using Docker","text":""},{"location":"deployment/installation/#introduction","title":"Introduction","text":"<p>OpenCTI can be deployed using the docker-compose command.</p> <p>Memory management</p> <p>For production deployment, we advise you to deploy ElasticSearch and Redis manually in a dedicated environment and then to start the other components using Docker.</p>"},{"location":"deployment/installation/#1-pre-requisites","title":"1. Pre-requisites","text":"<p>*\ud83d\udc27\u00a0Linux:*</p> <pre><code>$ sudo apt-get install docker-compose\n</code></pre> <p>\u2318 MacOS</p> <p>Download:\u00a0https://www.docker.com/products/docker-desktop</p>"},{"location":"deployment/installation/#2-clone-the-repository","title":"2. Clone the repository","text":"<pre><code>$ mkdir -p /path/to/your/app &amp;&amp; cd /path/to/your/app\n$ git clone https://github.com/OpenCTI-Platform/docker.git\n$ cd docker\n</code></pre>"},{"location":"deployment/installation/#3-configure-the-environment","title":"3. Configure the environment","text":"<p>Before running the\u00a0<code>docker-compose</code>\u00a0command, the\u00a0<code>docker-compose.yml</code>\u00a0file must be configured.</p> <p>There are two ways to do that:</p> <ol> <li>Use environment variables as it is proposed and you have an exemple in the\u00a0<code>.env.sample</code>\u00a0file (ie.\u00a0<code>APP__ADMIN__EMAIL=${OPENCTI_ADMIN_EMAIL}</code>).</li> <li>Directly set the parameters in the\u00a0<code>docker-compose.yml</code>.</li> </ol> <p>If setting within the environment, you can reference the methodology in the\u00a0Environment setup on OpenCTI's Notion page\u00a0- located below for ease:</p>"},{"location":"deployment/installation/#linux","title":"\ud83d\udc27\u00a0Linux:","text":"<pre><code>sudo apt install -y jq\n\ncd ~/docker\n(cat &lt;&lt; EOF\nOPENCTI_ADMIN_EMAIL=admin@opencti.io\nOPENCTI_ADMIN_PASSWORD=CHANGEMEPLEASE\nOPENCTI_ADMIN_TOKEN=$(cat /proc/sys/kernel/random/uuid)\nMINIO_ROOT_USER=$(cat /proc/sys/kernel/random/uuid)\nMINIO_ROOT_PASSWORD=$(cat /proc/sys/kernel/random/uuid)\nRABBITMQ_DEFAULT_USER=guest\nRABBITMQ_DEFAULT_PASS=guest\nCONNECTOR_HISTORY_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_EXPORT_FILE_STIX_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_EXPORT_FILE_CSV_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_IMPORT_FILE_STIX_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_IMPORT_REPORT_ID=$(cat /proc/sys/kernel/random/uuid)\nEOF\n) &gt; .env\n</code></pre>"},{"location":"deployment/installation/#macos","title":"\u2318 MacOS","text":"<pre><code>brew install jq\ncd ~/docker\n (cat &lt;&lt;EOF\nOPENCTI_ADMIN_EMAIL=admin@opencti.io\nOPENCTI_ADMIN_PASSWORD=CHANGEMEPLEASE\nOPENCTI_ADMIN_TOKEN=$(uuidgen)\nMINIO_ROOT_USER=$(uuidgen)\nMINIO_ROOT_PASSWORD=$(uuidgen)\nRABBITMQ_DEFAULT_USER=guest\nRABBITMQ_DEFAULT_PASS=guest\nCONNECTOR_HISTORY_ID=$(uuidgen)\nCONNECTOR_EXPORT_FILE_STIX_ID=$(uuidgen)\nCONNECTOR_EXPORT_FILE_CSV_ID=$(uuidgen)\nCONNECTOR_IMPORT_FILE_STIX_ID=$(uuidgen)\nCONNECTOR_IMPORT_REPORT_ID=$(uuidgen)\nEOF\n) &gt; .env\n</code></pre> <pre><code>cd ~/docker # trick to export the .env \nexport $(cat .env | grep -v \"#\" | xargs)\n</code></pre>"},{"location":"deployment/installation/#4-memory-management-settings","title":"4. Memory Management Settings","text":"\ud83d\udca1 For additional memory management information see the Memory configuration notes section   <p>As OpenCTI has a dependency on ElasticSearch, you have to set the\u00a0<code>vm.max_map_count</code>\u00a0before running the containers, as mentioned in the\u00a0ElasticSearch documentation.</p> <pre><code>$ sudo sysctl -w vm.max_map_count=1048575\n</code></pre> <p>To make this parameter persistent, add the following to the end of your\u00a0<code>/etc/sysctl.conf</code>:</p> <pre><code>$ vm.max_map_count=1048575\n</code></pre>"},{"location":"deployment/installation/#5-run-opencti-full-stack-including-ui","title":"5. Run OpenCTI - Full-stack, including UI","text":""},{"location":"deployment/installation/#using-single-node-docker","title":"Using single node Docker","text":""},{"location":"deployment/installation/#using-docker-swarm","title":"Using Docker swarm","text":"<p>After changing your\u00a0<code>.env</code>\u00a0file run\u00a0<code>docker-compose</code>\u00a0in detached (<code>-d</code>) mode:</p> <p>In order to have the best experience with Docker, we recommend using the Docker stack feature. In this mode you will have the capacity to easily scale your deployment. </p>  \ud83d\udca1 **Top Tip:** If you are looking for a easy way to manage your docker installation and containers try [Portainer](https://documentation.portainer.io/quickstart/?hsCtaTracking=cb3a059b-7f57-4333-a92f-b06202ef8690%7C4427d7bc-1ae8-4a30-812c-d30ee496008f).   <pre><code># ****\ud83d\udc27**** Linux only\n$ sudo systemctl start docker.service\n# Run docker-compose in detached \n$ docker-compose up -d\n</code></pre> <pre><code># If your virtual machine is not a part of a Swarm cluster, please use:\n$ docker swarm init\n</code></pre> <p>Put your environment variables in\u00a0<code>/etc/environment</code>:</p> <pre><code># If you already exported your variables to .env from above:\n$ sudo cat .env &gt;&gt; /etc/environment\n$ sudo bash -c 'cat .env &gt;&gt; /etc/environment\u2019\n$ sudo docker stack deploy --compose-file docker-compose.yml opencti\n</code></pre> <p>You can now go to\u00a0http://localhost:8080\u00a0and log in with the credentials configured in your environment variables.</p>"},{"location":"deployment/installation/#6-run-opencti-infrastructure-with-uigraphql-in-development-mode","title":"6. Run OpenCTI infrastructure with UI/GraphQL in development mode","text":"<p>In order to develop OpenCTI UI/GraphQL in the most efficient manner we have provided a\u00a0<code>docker-compose.dev.yml</code>\u00a0which stands up the back-end/infrastructure of OpenCTI, with the expectation that you will run the OpenCTI front-end (React/GraphQL) separately.</p> <p>This docker-compose exposes all necessary ports for the UI/GraphQL to attach to in order to support local development.</p> <p>To run the services required for local development run:</p> <pre><code>$ sudo docker-compose -f docker-compose.dev.yml up -d\n</code></pre> <p>To configure/run the UI/GraphQL we would direct you to the\u00a0Notion documentation</p>"},{"location":"deployment/installation/#appendices","title":"Appendices","text":""},{"location":"deployment/installation/#a-how-to-update-your-docker-instances","title":"A. How to update your docker instances","text":""},{"location":"deployment/installation/#for-single-node-docker","title":"For single node Docker","text":"<pre><code>$ sudo docker-compose stop\n$ sudo docker-compose pull\n$ sudo docker-compose up -d\n</code></pre>"},{"location":"deployment/installation/#for-docker-swarm","title":"For Docker swarm","text":"<p>For each of services, you have to run the following command:</p> <pre><code>$ sudo docker service update --force service_name\n</code></pre>"},{"location":"deployment/installation/#b-how-to-deploy-behind-a-reverse-proxy","title":"B. How to deploy behind a reverse proxy","text":"<p>If you want to use OpenCTI behind a reverse proxy with a context path, like\u00a0<code>https://myproxy.com/opencti</code>, please change the base_path configuration.</p> <ul> <li><code>APP__BASE_PATH=/opencti</code></li> </ul> <p>By default OpenCTI use websockets so don't forget to configure your proxy for this usage, an example with\u00a0<code>Nginx</code>:</p> <pre><code>location / {\nproxy_cache               off;\nproxy_buffering           off;\nproxy_http_version 1.1;\nproxy_set_header Upgrade $http_upgrade;\nproxy_set_header Connection \"upgrade\";\nproxy_set_header Host $host;\nchunked_transfer_encoding off;\nproxy_pass http:/YOUR_UPSTREA_BACKEND;\n}\n</code></pre>"},{"location":"deployment/installation/#c-how-to-persist-data","title":"C. How to persist data","text":"<p>The default for OpenCTI data is to be persistent.</p> <p>If you do not wish the data to persist:</p> <pre><code>$ mv docker-compose.override.no-persist.yml docker-compose.override.yml\n</code></pre>"},{"location":"deployment/installation/#d-memory-configuration-additional-information","title":"D. Memory configuration: additional information","text":""},{"location":"deployment/installation/#opencti-platform","title":"OpenCTI - Platform","text":"<p>OpenCTI platform is based on a NodeJS runtime, with a memory limit of 8GB by default. If you encounter <code>OutOfMemory</code> exceptions, this limit could be changed:</p> <pre><code>- NODE_OPTIONS=--max-old-space-size=8096\n</code></pre>"},{"location":"deployment/installation/#opencti-workers-and-connectors","title":"OpenCTI - Workers and connectors","text":"<p>OpenCTI workers and connectors are Python processes. If you want to limit the memory of the process, we recommend to directly use Docker to do that. You can find more information in the official Docker documentation.</p>  \ud83d\udca1 If you do not use Docker stack, consider using the `--compatibility` option."},{"location":"deployment/installation/#elasticsearch","title":"ElasticSearch","text":"<p>ElasticSearch is also a JAVA process. In order to setup the JAVA memory allocation, you can use the environment variable <code>ES_JAVA_OPTS</code>.</p>  \ud83d\udca1 The minimal recommended option today is `-Xms8G -Xmx8G`   <p>You can find more information in the official ElasticSearch documentation.</p>"},{"location":"deployment/installation/#redis","title":"Redis","text":"<p>Redis has a very small footprint on keys but will consume memory for the stream. By default the size of the stream is limited to 2 millions</p>  \ud83d\udca1 With 2 million of events in the stream, the memory footprint will be around `8G`   <p>You can find more information in the Redis docker hub.</p>"},{"location":"deployment/installation/#minio","title":"MinIO","text":"<p>MinIO is a small process and does not require a high amount of memory. More information are available for Linux here on the Kernel tuning guide.</p>"},{"location":"deployment/installation/#rabbitmq","title":"RabbitMQ","text":"<p>The RabbitMQ memory configuration can be find in the RabbitMQ official documentation. RabbitMQ will consumed memory until a specific threshold, therefore it should be configure along with the Docker memory limitation.</p>"},{"location":"deployment/installation/#e-load-balancing","title":"E. Load-balancing","text":"<p>Ingesting lots of data from connectors can cause the OpenCTI platform to slow down and make it difficult for analysts to use the platform properly for their work. A simple way of solving this issue is to have 2 parallel OpenCTI platform containers running at the same time and to distribute the workload between them.</p> <ol> <li>OpenCTI container #1 is the responsible go-to address for all connectors for ingesting data</li> <li>OpenCTI container #2 is the analysts\u2019 UI interface for their research</li> </ol> <p>Since both OpenCTI containers are using the same backend infrastructure, both platforms are able to access the same data while balancing the workload between them.</p>"},{"location":"deployment/installation/#f-updating-opencti-containers","title":"F. Updating OpenCTI containers","text":"<p>Before applying this procedure, please update your <code>docker-compose.yml</code> file with the new version number of container images.</p>"},{"location":"deployment/installation/#using-single-node-docker_1","title":"Using single node Docker","text":""},{"location":"deployment/installation/#using-docker-swarm_1","title":"Using Docker swarm","text":"<pre><code>$ docker-compose up -d\n</code></pre> <p>For each of services, you have to run the following command:</p> <pre><code>$ docker service update --force service_name\n</code></pre>"},{"location":"deployment/installation/#g-deployment-behind-a-reverse-proxy","title":"G. Deployment behind a reverse proxy","text":"<p>If you want to use OpenCTI behind a reverse proxy with a context path, like <code>https://myproxy.com/opencti</code>, please change the <code>base_path</code> configuration.</p> <pre><code>- APP__BASE_PATH=/opencti\n</code></pre> <p>By default OpenCTI use websockets and SSE so don't forget to configure your proxy for this usage, an example with <code>Nginx</code>:</p> <pre><code>location / {\nproxy_cache               off;\nproxy_buffering           off;\nproxy_http_version 1.1;\nproxy_set_header Upgrade $http_upgrade;\nproxy_set_header Connection \"upgrade\";\nproxy_set_header Host $host;\nchunked_transfer_encoding off;\nproxy_pass http://YOUR_UPSTREAM_BACKEND;\n}\n</code></pre>"},{"location":"deployment/installation/#community-additions","title":"Community Additions","text":""},{"location":"deployment/installation/#setup-with-caddy-server-thanks-to-sukesh-ak","title":"Setup with Caddy Server (thanks to @sukesh-ak)","text":"<p>Setup and automate FREE valid SSL for OpenCTI, using an OpenSource project called\u00a0Caddy Server\u00a0with very minimal effort.</p>"},{"location":"deployment/installation/#about-caddy","title":"About Caddy","text":"<p>Caddy 2 is a powerful, enterprise-ready, open source web server with\u00a0automatic HTTPS\u00a0written in Go. Caddy works well as a direct install and also using Docker.</p>"},{"location":"deployment/installation/#using-docker_1","title":"Using Docker","text":"<p>OpenCTI runs all its components in individual containers. For accessing the WebUI, by default it exposes opencti service on port 8080 locally.</p> <p>It\u2019s easy to setup reverse proxy with FREE SSL using Caddy with very minimal effort. So lets check the steps for setting it up</p> <ul> <li>Configure DNS with A record pointing to your OpenCTI public IP address</li> <li>Create a base folder for config file <code>'Caddyfile'</code></li> <li>Create a <code>docker-compose</code> file for Caddy</li> <li>Create a container using <code>docker-compose run</code></li> </ul> <pre><code># Create a DNS A/AAAA record pointing your domain to the public IP address\n$ cti.domain.com  A  &lt;public-IP-address-for-OpenCTI-instance&gt;\n</code></pre> <p>Make sure to wait for the DNS record to complete propagation (depending on TTL). Otherwise automatic SSL creation would not work.</p> <p>Caddy uses 2 volumes for data (storing certificates etc) &amp; config.Create a file called <code>'Caddyfile'</code> in the local folder for configuration, which will be mapped to <code>/etc/caddy/Caddyfile</code> through docker-compose file as below.</p> <pre><code># /etc/caddy/Caddyfile\ncti.domain.com {\nreverse_proxy http://opencti:8080\n}\n</code></pre>  \ud83d\udca1 Port 80 mapping is not necessary but it helps in automatic redirection if clients try the HTTP url.   <pre><code># **docker-compose-caddy.yml** \nversion: \"3.7\"\nservices:\n      caddy:\n        image: caddy\n        restart: unless-stopped\n        ports:\n          - \"80:80\"\n- \"443:443\"\nvolumes:\n          - ./Caddyfile:/etc/caddy/Caddyfile\n          - caddy_data:/data\n          - caddy_config:/config\n\nnetworks:\n  default:\n    external: true\nname: &lt;your OpenCTI network name&gt;\n\nvolumes:\n  caddy_data:\n  caddy_config:\n</code></pre> <p>Since you are running Caddy in docker, you need to make it part of OpenCTI network. Reverse proxy takes care of everything else. This also means you don't need to expose OpenCTI <code>8080</code> port outside the container. So you can remove <code>-port</code> setting in OpenCTI <code>docker-compose</code> file.</p> <p>Now just get it running and Caddy will request and get SSL certificate automagically for your domain.</p> <pre><code>docker-compose -f docker-compose-caddy.yml up -d\n</code></pre>"},{"location":"deployment/installation/#resources","title":"Resources","text":"<p>How Caddy automatic SSL works https://caddyserver.com/docs/automatic-https</p> <p>Using Caddy with Load Balancer https://caddy.community/t/load-balancing-caddy/10467</p>"},{"location":"deployment/integrations/","title":"Integrations","text":""},{"location":"deployment/overview/","title":"Overview","text":"<p>Let's get started and discover the OpenCTI platform! What is OpenCTI, which technical architecture is used to run the platform and what are the hardware requirements to deploy it in production.</p>"},{"location":"deployment/overview/#architecture","title":"Architecture","text":"<p>The OpenCTI platform relies on several external databases and services in order to work.</p> <p> </p>"},{"location":"deployment/overview/#the-graphql-api","title":"The GraphQL API","text":"<p>The API is the central part of the OpenCTI platform, allowing the clients (including the frontend) to interact with the database and the broker (messaging system). Built in NodeJS, it implements the GraphQL query language. As the API is not fully documented yet, you can explore the available methods and parameters through a GraphQL playground. An example is available on the OpenCTI demonstration instance.</p>"},{"location":"deployment/overview/#the-write-workers","title":"The write workers","text":"<p>The workers are standalone Python processes consuming messages from the RabbitMQ broker in order to do asynchronous write queries. You can launch as many workers as you need to increase the write performances. At some point, the write performances will be limited by the throughput of the database (ElasticSearch), if you have not the expected performances with 3 or 4 workers, then is will be useless to launch more and you have to think about enhancing the hardware of the database nodes (or extend your setup to a cluster).</p>"},{"location":"deployment/overview/#the-connectors","title":"The connectors","text":"<p>The connectors are third-party pieces of software (Python processes) that can play four different roles on the platform:</p> <p>You can find all currently available connector in the OpenCTI Ecosystem.</p>"},{"location":"deployment/overview/#infrastructure-requirements","title":"Infrastructure requirements","text":""},{"location":"deployment/overview/#dependencies","title":"Dependencies","text":"<p>Since OpenCTI has some dependencies, you can find below the minimum configuration and amount of resources needed to launch the OpenCTI platform. </p> <p>The minimal hardware requirements for all components of the platform, including the databases, are:</p> CPU RAM Disk type Disk space 6 cores 16GB SSD (recommanded) / Normal Depending of your content (&gt; 32GB)"},{"location":"deployment/overview/#elasticsearch","title":"ElasticSearch","text":"<p>ElasticSearch is also a JAVA process that needs a minimal amount of memory and CPUs.</p> CPU RAM Disk type Disk space 2 cores 8GB SSD (recommanded) / Normal Depending of your content (&gt; 16GB) <p>Memory management</p> <p>In order to setup the JAVA memory allocation, you can use the environment variable ES_JAVA_OPTS. You can find more information in the official ElasticSearch documentation.</p>"},{"location":"deployment/overview/#minio","title":"MinIO","text":"<p>MinIO has a very small footprint but depending on what you intend to store on OpenCTI, it could require disk space:</p> CPU RAM Disk type Disk space 1 core 128MB Normal Depending of your content (&gt; 1GB)"},{"location":"deployment/overview/#redis","title":"Redis","text":"<p>Redis has a very small footprint and only needs a tiny configuration:</p> CPU RAM Disk type Disk space 1 core 1GB Normal Depending of your content (&gt; 16GB) <p>Memory management</p> <p>You can use the option --maxmemory to limit the use. You can find more information in the Redis docker hub.</p>"},{"location":"deployment/overview/#rabbitmq","title":"RabbitMQ","text":"<p>RabbitMQ has a very small footprint and can store messages directly on the disk if it does not have enough memory.</p> CPU RAM Disk type Disk space 1 core 512MB Normal Depending of your content (&gt; 1GB) <p>Memory management</p> <p>The RabbitMQ memory configuration can be found in the RabbitMQ official documentation.</p>"},{"location":"deployment/overview/#platform","title":"Platform","text":""},{"location":"deployment/overview/#application","title":"Application","text":"<p>OpenCTI platform is based on a NodeJS runtime, with a memory limit of 512MB by default.</p> CPU RAM Disk type Disk space 2 cores 8GB Normal 256MB"},{"location":"deployment/overview/#workers-and-connectors","title":"Workers and connectors","text":"<p>OpenCTI workers and connectors are Python processes with a very small footprint. For each connector, requirements are:</p> CPU RAM Disk type Disk space 1 core 128MB Normal 128MB"},{"location":"deployment/third-party/","title":"Third-party systems","text":""},{"location":"deployment/upgrade/","title":"Upgrade","text":""},{"location":"development/environment/","title":"Environment setup","text":"<p>This summary should give you a detailed setup description for initiating the OpenCTI setup environment necessary for developing on the OpenCTI platform, a client library or the connectors.</p> <p>This page document how to setting up an \"All-in-One\" development ****environment for OpenCTI. Everything was done on a virtual machine (Virtualbox VM - 16 vCPU / 20Gb RAM) which contains:</p> <ul> <li>the OpenCTI project code base:<ul> <li>web frontend (nodejs / react)<ul> <li><code>~/opencti/opencti-platform</code></li> </ul> </li> <li>backend (nodejs / python)<ul> <li><code>~/opencti/opencti-worker</code></li> </ul> </li> <li>connectors (python)<ul> <li><code>~/connectors</code></li> </ul> </li> <li>python client<ul> <li><code>~/client-python</code></li> </ul> </li> </ul> </li> <li>docker-compose for the databases / broker<ul> <li>elasticsearch (and kibana)</li> <li>redis</li> <li>minio</li> <li>rabbitmq</li> </ul> </li> </ul>"},{"location":"development/environment/#prerequisites","title":"Prerequisites","text":""},{"location":"development/environment/#installation-of-dependencies-ubuntu-2004","title":"Installation of dependencies (Ubuntu 20.04)","text":"<p>If you are on a version of Debian/Ubuntu prior to 20, please refer to this GIthub issue.</p> <pre><code>$ sudo apt-get install docker docker-compose curl nodejs python3 python3-pip\n$ sudo curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -\n$ sudo echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n$ sudo apt-get update &amp;&amp; sudo apt-get install yarn\n</code></pre>"},{"location":"development/environment/#docker-stack","title":"Docker stack","text":"<p>As OpenCTI has a dependency to ElasticSearch, you have to set the vm.max_map_count before running the containers, as mentioned in the ElasticSearch documentation.</p> <pre><code>$ sudo sysctl -w vm.max_map_count=262144\n</code></pre> <p>Clone the latest version of the dev docker compose and start</p> <pre><code>$ git clone https://github.com/OpenCTI-Platform/docker.git\n$ cd docker\n$ docker-compose -f ./docker-compose-dev.yml up -d\n</code></pre>"},{"location":"development/environment/#clone-the-project","title":"Clone the project","text":"<p>Depending on the part of OpenCTI to which you want to contribute, fork and clone the appropriate git repository or just clone repos</p> <ul> <li>https://github.com/OpenCTI-Platform/opencti/ - frontend / backend</li> <li>https://github.com/OpenCTI-Platform/connectors - connectors</li> <li>https://github.com/OpenCTI-Platform/docker - docker stack</li> <li>https://github.com/OpenCTI-Platform/client-python/ - python client</li> </ul> <p>Example with the <code>opencti</code> repository:</p> <pre><code>git clone git@github.com:YOUR-USERNAME/opencti.git\ncd ~/opencti\ngit remote add upstream https://github.com/OpenCTI-Platform/opencti.git\n\ncd\ngit clone https://github.com/opencti/connectors.git\ngit clone https://github.com/opencti/docker.git\ngit clone https://github.com/opencti/client-python.git\n</code></pre>"},{"location":"development/environment/#application-dependencies","title":"Application dependencies","text":""},{"location":"development/environment/#install-the-backend-graphql-api-dependencies","title":"Install the backend GraphQL API dependencies","text":"<p>The GraphQL API is developped in JS and with some python code. As it's an \"all-in-one\" installation, the python environment will be installed in a virtual environment.</p> <pre><code>cd ~/opencti/opencti-platform/opencti-graphql\npython3 -m venv .venv --prompt \"graphql\"\nsource .venv/bin/activate\npip install --upgrade pip wheel setuptools\nyarn install\nyarn install:python deactivate\n</code></pre>"},{"location":"development/environment/#install-the-frontend-dependencies-and-build-it","title":"Install the frontend dependencies and build it","text":"<pre><code>cd ~/opencti/opencti-platform/opencti-front\nyarn install\nyarn build\n# The resulting build is then copied to ../../opencti-graphql/public/\n</code></pre>"},{"location":"development/environment/#install-the-worker-dependencies","title":"Install the worker dependencies","text":"<pre><code>cd ~/opencti/opencti-worker/src\npython3 -m venv .venv --prompt \"worker\"\nsource .venv/bin/activate\npip3 install --upgrade pip wheel setuptools\npip3 install -r requirements.txt\ndeactivate\n</code></pre>"},{"location":"development/environment/#configure-the-stack","title":"Configure the stack","text":""},{"location":"development/environment/#configure-docker","title":"Configure Docker","text":"<p>Create a config file which contains:</p> <ul> <li>the opencti admin user/pass</li> <li>user/pass for minio, rabbitmq</li> <li>an UUID for each connector</li> </ul> <pre><code>sudo apt install -y jq\ncd ~/docker\n(cat &lt;&lt;EOF\nOPENCTI_ADMIN_EMAIL=admin@opencti.io\nOPENCTI_ADMIN_PASSWORD=CHANGEMEPLEASE\nOPENCTI_ADMIN_TOKEN=$(cat /proc/sys/kernel/random/uuid)\nMINIO_ROOT_USER=$(cat /proc/sys/kernel/random/uuid)\nMINIO_ROOT_PASSWORD=$(cat /proc/sys/kernel/random/uuid)\nRABBITMQ_DEFAULT_USER=guest\nRABBITMQ_DEFAULT_PASS=guest\nCONNECTOR_HISTORY_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_EXPORT_FILE_STIX_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_EXPORT_FILE_CSV_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_IMPORT_FILE_STIX_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_IMPORT_REPORT_ID=$(cat /proc/sys/kernel/random/uuid)\nDOCKER_IP=$(ip -j a show dev docker0 |jq -r '.[0].addr_info[0].local')\nEOF\n) &gt; .env\n\ncd ~/docker # trick to export the .env \nexport $(cat .env | grep -v \"#\" | xargs)\necho \"\"\"admin username: ${OPENCTI_ADMIN_EMAIL}\nadmin password: ${OPENCTI_ADMIN_PASSWORD}\nminio user : ${MINIO_ROOT_USER}\nminio password : ${MINIO_ROOT_PASSWORD}\"\"\"\n</code></pre>"},{"location":"development/environment/#configure-the-backend-graphql-api","title":"Configure the backend (GraphQL API)","text":"<p>We use the credentials defined in <code>~/docker/.env</code> to update the configuration of the backend.</p> <pre><code>sudo apt install -y jq moreutils\ncd ~/opencti/opencti-platform/opencti-graphql/config\njq '.app.admin.token = $newtoken' --arg newtoken ${OPENCTI_ADMIN_TOKEN} \\\ndefault.json &gt; development.json\njq '.app.admin.password = $newtoken' --arg newtoken ${OPENCTI_ADMIN_PASSWORD} \\\ndevelopment.json | sponge development.json\njq '.minio.access_key = $newtoken' --arg newtoken ${MINIO_ROOT_USER} \\\ndevelopment.json | sponge development.json\njq '.minio.secret_key = $newtoken' --arg newtoken ${MINIO_ROOT_PASSWORD} \\\ndevelopment.json | sponge development.json\n\njq '.redis.hostname = $newtoken' --arg newtoken ${DOCKER_IP} \\\ndevelopment.json | sponge development.json\njq '.rabbitmq.hostname = $newtoken' --arg newtoken ${DOCKER_IP} \\\ndevelopment.json | sponge development.json\njq '.minio.hostname = $newtoken' --arg newtoken ${DOCKER_IP} \\\ndevelopment.json | sponge development.json\njq '.elasticsearch.url = $newtoken' --arg newtoken \"http://${DOCKER_IP}:9200\" \\\ndevelopment.json | sponge development.json\n</code></pre> <p>Skip this command if you have a SMTP server or if you install local SMTP (see \"Local SMTP (Optionnal)\") </p> <pre><code>jq '.subscription_scheduler.enabled = $newtoken' --arg newtoken \"false\" \\\ndevelopment.json | sponge development.json\n</code></pre>"},{"location":"development/environment/#configure-the-backend-worker","title":"Configure the backend (worker)","text":"<pre><code>cd ~/opencti/opencti-worker/src\nsed \"s/ChangeMe/${OPENCTI_ADMIN_TOKEN}/g\" config.yml.sample &gt; config.yml\n</code></pre>"},{"location":"development/environment/#start-the-stack","title":"Start the stack !","text":""},{"location":"development/environment/#start-the-database","title":"Start the database","text":"<pre><code>cd ~/docker\n#Start the stack in background\ndocker-compose -f ./docker-compose-dev.yml up -d\n\ndocker ps\n#&gt; CONTAINER ID   IMAGE                                                  COMMAND                  CREATED       STATUS                            PORTS                                                                                                                                                 NAMES\n#&gt; 11d6b3dfda99   redis:6.2.4                                            \"docker-entrypoint.s\u2026\"   9 hours ago   Up 8 seconds                      0.0.0.0:6379-&gt;6379/tcp, :::6379-&gt;6379/tcp                                                                                                             opencti-dev-redis\n#&gt; e0dc9983e855   rabbitmq:3.8-management                                \"docker-entrypoint.s\u2026\"   9 hours ago   Up 8 seconds                      4369/tcp, 5671/tcp, 0.0.0.0:5672-&gt;5672/tcp, :::5672-&gt;5672/tcp, 15671/tcp, 15691-15692/tcp, 25672/tcp, 0.0.0.0:15672-&gt;15672/tcp, :::15672-&gt;15672/tcp   opencti-dev-rabbitmq\n#&gt; 19a620bc0b0e   docker.elastic.co/kibana/kibana:7.13.1                 \"/bin/tini -- /usr/l\u2026\"   9 hours ago   Up 8 seconds                      0.0.0.0:5601-&gt;5601/tcp, :::5601-&gt;5601/tcp                                                                                                             opencti-dev-kibana\n#&gt; 024f3be652e2   minio/minio:RELEASE.2021-06-14T01-29-23Z               \"/usr/bin/docker-ent\u2026\"   9 hours ago   Up 8 seconds (health: starting)   0.0.0.0:9000-&gt;9000/tcp, :::9000-&gt;9000/tcp                                                                                                             opencti-dev-minio\n#&gt; 4e84dcabb42e   docker.elastic.co/elasticsearch/elasticsearch:7.13.1   \"/bin/tini -- /usr/l\u2026\"   9 hours ago   Up 8 seconds                      0.0.0.0:9200-&gt;9200/tcp, :::9200-&gt;9200/tcp, 0.0.0.0:9300-&gt;9300/tcp, :::9300-&gt;9300/tcp                                                                  opencti-dev-elasticsearch\ndocker logs opencti-dev-redis\n#&gt; 1:C 11 Aug 2021 21:01:32.800 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n#&gt; 1:C 11 Aug 2021 21:01:32.800 # Redis version=6.2.4, bits=64, commit=00000000, modified=0, pid=1, just started\n#&gt; ...\n</code></pre>"},{"location":"development/environment/#start-the-frontend","title":"Start the frontend","text":"<pre><code>cd ~/opencti/opencti-platform/opencti-graphql\nsource .venv/bin/activate\n#yarn start\nexport NODE_OPTIONS=--max_old_space_size=8192\nexport NODE_ENV=development\nyarn serv --conf config/development.json\n</code></pre> <p>The first execution will create and migrate the schema.</p>"},{"location":"development/environment/#start-the-worker-backend","title":"Start the worker backend","text":"<pre><code>cd ~/opencti/opencti-worker/src\nsource .venv/bin/activate\npython worker.py\n</code></pre> <p>The web UI should be accessible on http://127.0.0.1:4000 </p>"},{"location":"development/environment/#build-for-production-use","title":"Build for production use","text":""},{"location":"development/environment/#build-the-application","title":"Build the application","text":"<pre><code>$ cd opencti-frontend\n$ yarn build\n$ cd ../opencti-graphql\n$ yarn build\n</code></pre>"},{"location":"development/environment/#start-the-production-package","title":"Start the production package","text":"<pre><code>$ yarn serv\n</code></pre>"},{"location":"development/environment/#tips","title":"Tips","text":""},{"location":"development/environment/#update-all-repositories","title":"Update all repositories","text":"<pre><code>cd ~/docker\ngit fetch upstream\ngit merge upstream/master\ngit push origin master\n\ncd ~/opencti/\ngit fetch upstream\ngit merge upstream/master\ngit push origin master\n\ncd ~/client-python\ngit fetch upstream\ngit merge upstream/master\ngit push origin master\n\ncd ~/connectors\ngit fetch upstream\ngit merge upstream/master\ngit push origin master\n\n# the hard way\ngit fetch upstream\ngit checkout master\ngit reset --hard upstream/master  git push origin master --force\n</code></pre>"},{"location":"development/environment/#working-on-the-latest-stable-version-tag","title":"Working on the latest stable version (tag)","text":"<pre><code>cd ~/opencti\nLATEST_TAG=$(git describe --abbrev=0 --tags)\necho \"Working on version ${LATEST_TAG}\"\ngit checkout tags/${LATEST_TAG} -b ${LATEST_TAG}-branch\n\ncd ~/client-python &amp;&amp; git checkout tags/${LATEST_TAG} -b ${LATEST_TAG}-branch\ncd ~/connectors &amp;&amp; git checkout tags/${LATEST_TAG} -b ${LATEST_TAG}-branch\ncd ~/docker &amp;&amp; git checkout tags/${LATEST_TAG} -b ${LATEST_TAG}-branch\n</code></pre>"},{"location":"development/environment/#testing-a-connector-in-the-docker-stack","title":"Testing a connector in the docker stack","text":"<p>put the conf of the connector in a separate file:</p> <pre><code>docker-compose -f ./docker-compose-dev.yml -f ./docker-compose-connectors.yml up\n</code></pre>"},{"location":"development/environment/#other-docker-commands","title":"Other docker commands","text":""},{"location":"usage/cases-reports/","title":"Cases and reports","text":""},{"location":"usage/dashboards/","title":"Platform","text":""},{"location":"usage/import-export/","title":"Import &amp; Export","text":""},{"location":"usage/import-export/#import-knowledge","title":"Import knowledge","text":""},{"location":"usage/import-export/#introduction","title":"Introduction","text":"<p>Before setting up OpenCTI in a production environment, it is highly recommended to first define the requirements for your platform. A knowledge database is only as good as the information's quality, hence sometime it is better to have less data, but of high quality than a lot of mixed quality data. By first thinking about the concept behind your OpenCTI you avoid simply pumping any kind of information into OpenCTI resulting in a \"Data Swamp\".</p> <p>Here are some possible requirements for an OpenCTI instance:</p> <ol> <li>I want to store my own analysis reports and correlate my findings with other reports</li> <li>I want to visualize information and query my knowledge base for new leads</li> <li>I want to share knowledge with others</li> </ol>"},{"location":"usage/import-export/#base-dataset","title":"Base dataset","text":"<p>Before we will start importing reports and SDOs, we have prepare the rest of the system, so that the ingested data can be easily migrated into knowledge. For this we first have to import a base dataset for the \"surrounding\" entities like Attack Patterns, sectors, countries and so on. To do this, we have to add a few connectors to import the necessary files.</p> <p>After those connectors have run, the necessary SDOs are imported which are needed to sufficiently describe observables and indicators.</p>"},{"location":"usage/import-export/#importing-threat-knowledge","title":"Importing Threat knowledge","text":"<p>The basic idea behind importing threat intelligence is that once an analysis on a certain threat is finished a report is written which summarizes the findings. Thus knowledge which is about to be imported comes always as a report.</p> <p>if you are aiming for a high quality knowledge management system, this is the point where you should first evaluate which sources you are using and what kind of information you want to import.</p>"},{"location":"usage/import-export/#manual-import-attached-report","title":"Manual import - Attached Report","text":"<p>One of the two ways of manually importing reports with the support of an internal import file connector. One is with the support of the ImportReport connector which extracts relevant information from the attached files to reports.</p> <p>This approach will be shown with ESET's report on FontOnLake. To properly import the knowledge from this report, please follow the upcoming description.</p> <p>1) [Reports List] Create new report and specify the details like the TLP defintion, labels or external references. We will add the link to the overview as well as to the PDF report as external reference.</p> <p>2) [Report Entities] Since the malware is new, we have to first create that malware entity, otherwise the import report parser won't recognize it later on</p> <p></p> <p>Create Report</p> <p></p> <p>Add new malware</p> <p>3) [Report Entities] Select the newly created malware</p> <p>4) [Report Overview] Import the external reference to the PDF report</p> <p></p> <p></p> <p>5) [Report Files &amp; History] Run the ImportReport parser on the newly imported PDF file</p> <p>6) [Report Files &amp; History] After the parsing process is finished, the mouse over show you the details of the parsed results</p> <p></p> <p></p> <p>7) [Report Observables] Remove observables the parser wrongly classified</p> <p>8) [Report Entities] Remove entities the parser wrongly classified</p> <p></p> <p></p> <p>10) [Report Overview] Imported result</p> <p>11) [Report Knowledge] Mitre ATT&amp;CK mapping</p> <p></p> <p>Final imported report</p> <p></p> <p>MITRE ATT&amp;CK mapping</p>"},{"location":"usage/import-export/#manual-import-stix-file","title":"Manual import - STIX File","text":"<p>Using the ImportFileStix connector, it is possible to import STIX bundles containing any kinds of STIX objects into a report. For this doing this, there are two approaches:</p> <p>a) STIX bundle contains a report</p> <p>Go to the \"Data Import\" section and upload the STIX JSON file. If the STIX JSON file contains a Report object, then this report will be created and all information will be attached to this report.</p> <p>1) [Data import] Launching STIX import connector</p> <p>2) [Report overview] After the STIX JSON file is imported, look for the report in the reports overview and select it. </p> <p></p> <p>Import launch</p> <p></p> <p>b) STIX bundle doesn't contain a report</p> <p>Create a report and attach the STIX JSON file as shown in the above example, then launch the import of the STIX objects which will be referenced to the current report.</p>"},{"location":"usage/import-export/#automatic-connectors","title":"Automatic Connectors","text":"<p>Besides manually importing threat reports, it is possible to use other external import connectors to automatically import reports from external sources. Have a look at the different existing connectors available for different threat intel platforms.</p>  \u26a0\ufe0f As mentioned above, it is highly recommended to evaluate the amount and quality of data about to imported. It is possible that the knowledge management approach of the external service is different to your own, so we really recommend to test and evaluate if those two approaches are compatible before you automatically import external knowledge into your production environment.   <p>OpenCTI has a growing number of connectors, available in the dedicated Github repository. The connectors with type <code>EXTERNAL_IMPORT</code> allow you to automatically import CTI data from external services (ie. AlienVault, MISP, TheHive, etc.).</p>"},{"location":"usage/import-export/#importing-knowledge-via-clients-api","title":"Importing Knowledge via Clients / API","text":"<p>For instance, in the Python library, you can use the methods:</p> <pre><code>from pycti import OpenCTIApiClient\n# Variables\napi_url = \"&lt;https://demo.opencti.io&gt;\"\napi_token = \"2b4f29e3-5ea8-4890-8cf5-a76f61f1e2b2\"\n# OpenCTI initialization\nopencti_api_client = OpenCTIApiClient(api_url, api_token)\n# File to import\nfile_to_import = \"./test.json\"\n# Import the bundle\nopencti_api_client.stix2.import_bundle_from_file(file_to_import)\n</code></pre>"},{"location":"usage/import-export/#export-knowledge","title":"Export knowledge","text":"<p>TODO</p>"},{"location":"usage/knowledge/","title":"Create knowledge","text":""},{"location":"usage/knowledge/#creating-an-entity-from-any-page","title":"Creating an entity from any page","text":"<p>The knowledge on the OpenCTI platform can be added by manually creating new entities or relationships.</p> <p>In each list of entities, you can add new entities of the corresponding type by clicking on the \"+\" button on the bottom right of the page. For instance, if you are in the reports section, you will only be able to create reports. </p> <p></p> <p>A menu will appear and need to be filled out with information on the new entity, as shown in the image below. Only the name and the description are mandatory fields.</p> <p></p> <p>Labels and authors can be chosen from the scrolling menu, or created directly from this window, using the small \"+\" button, as shown below. In this example, you can see the temporary window for creating a new \"author\" while creating a new \"intrusion set\".</p> <p>New marking levels cannot be added from this menu directly. Adding and editig marking levels is available in the \"Settings\" menu. Admin level-rights are required to edit the list of marking levels.</p> <p></p> <p>The creation menu contains the bare minimum of fields necessary to create the entity. More fields are available for modification once the entity is created, in the \"editing\" mode (see below for more informaiton on editing)</p>  \ud83d\udca1 If you are looking for the whole OpenCTI data model (entities, properties), please refer to the dedicated documentation, which you can find here : [https://www.notion.so/luatix/Data-model-4427344d93a74fe194d5a52ce4a41a8d](https://www.notion.so/Data-model-a84f286a4e1641728ee3951120d45448)"},{"location":"usage/knowledge/#creating-an-entity-within-the-knowledge-tab-of-a-report","title":"Creating an entity within the knowledge tab of a report","text":"<p>Reports are a specific entity in the platform, allowing to trace back the source of a relation between two entities. The knowledge tab of a report is specific to this entity and different from the knwoledge tab of all other entities. </p> <p>The use of this tab is documented in a dedicated page. Please refer to the Adding entities and relations within a report section.</p>"},{"location":"usage/knowledge/#editing-the-knowledge","title":"Editing the knowledge","text":"<p>You can edit any entity at any time using the three vertical dots right of the name of the entity, or the \"pen\" button at the bottom left of the page.</p> <p></p> <p>The editing mode allows the user to modify any of  the fields characterizing an entity, by giving access to two menus: </p> <ul> <li>the \"overview\" menu is the same than the one for the creating of the entity. It allows to modify most of the \"basic information\" on the entity, except fields such as STIX IDS and the date of creation.</li> <li>the \"details\" menu is only accessible from the editing mode and allows to edit details on the entity, such as its motivations for an intrusion set etc.</li> </ul> <p></p> <p>A few fields are specific and can only be edited by clicking on the small orange \"+\" next to tem, which is dedicated to this field. The fields are :</p> <ul> <li>aliases</li> <li>labels</li> <li>external references (URL)</li> <li>notes</li> <li>for some entities, the \"originates from\" in the \"details\" section can also be edited only using such a \"+\" button</li> </ul> <p></p> <p></p>"},{"location":"usage/knowledge/#duplicate-alert-while-creating-a-new-entity","title":"Duplicate alert while creating a new entity","text":"<p>The platform warns you of potential duplicates when you create a new entity. The platform will give a warning if others entities with the same string already exists. </p> <p></p> <p>The alert about duplicates is cliquable. Doing so will open a temporary scrolling menu, displaying all entities already containing this string. Entities can be of different types than the one currently being created. For instance, on the image below, malware containing the \"APT1\" string are also shown.</p> <p></p> <p>It is not possible to directly click on the entity of your choice if it already exists. You will need to abandon the creation you are currently doing by closing the window without validating the creation and afterwards search for the desired entity.</p> <p>You can chose to ignore the alert by closing simply closing the temporary menu and continue adding information in the creation menu. </p>  \ud83d\udca1 \u26a0\ufe0f If the new entity has exactly the same name and the same type as one already existing in the platform, will will be automatically merged at creation.   <p>For any other case (same name but different type, or different name, but the result appeared in the alert because the string exists in the other entity), no merge will be done, and your new entity will exists along the others.</p> <p>To have more information on managing duplicates from the dedicated menu, refer to the page Managing duplicates</p>"},{"location":"usage/notifications/","title":"Platform","text":""},{"location":"usage/platform/","title":"Platform","text":""},{"location":"usage/platform/#ntroduction","title":"ntroduction","text":"<p>The following chapter aims at giving the reader a step-by-step description of what is available on the platform and the meaning of the different tabs and entries.</p> <p>When the user connects to the platform, the home page is the <code>Dashboard</code>. This <code>Dashboard</code> contains several visuals summarizing the types and quantity of data recently imported into the platform. It is described below.</p> <p>The left side panel allows the user to navigate through different windows and access different views and categories of knowledge. These windows are detailed in the different pages linked below.</p>  \ud83d\udc49 If you are looking for the full list of possible entities or relations, please refer to the page [Data model](https://www.notion.so/Data-model-a84f286a4e1641728ee3951120d45448)."},{"location":"usage/platform/#general-information-on-browsing","title":"General information on browsing","text":""},{"location":"usage/platform/#description-of-the-welcome-dashboard","title":"Description of the welcome <code>Dashboard</code>","text":"<p>The welcome <code>Dashboard</code> gives any visitor on the OpenCTI platform an outlook on the live of the platform. The widgets which are displayed cannot be changed, suppressed, resized or moved around. They cannot be clicked except for one (ingested analysis). They are the following:</p> <ul> <li>Total entities: indicates the number of all entities present in the platform, with an indication the added entities in the last 24 hours.</li> <li>Total relationships: indicates the number of all relationships created in the platform, with an indication of added relationships in the last 24 hours.</li> <li>Total reports: indicates the number of total reports in the platform and the number of newly ingested reports in the last 24 hours.</li> <li>Total observables: indicates the number of total observables in the platform and the number of newly ingested observables in the last 24 hours.</li> </ul> <p>The numbers indicating the variation only give how many new objects were added to the platform manually or using connectors. It compares the number of objects at D-1 and at D and establishes the variation number, therefore the variation will never be bellow 0.</p> <ul> <li>Top labels: indicates which are the top labels given to entities during the last 3 months. The top 9 labels are shown, with the number of entities having that label.</li> <li>Ingested entities: indicates how many entities were ingested and when over the last year.</li> <li>Top ten active entities (last 3 months): name and list of the entities with the greatest number of relations created to it in the platform over the last 3 months. The type of the entity and the exact number of relations is displayed if the mouse is moved over one bar. The entities can be any entity.</li> <li>Targeted countries: the map can be zoomed in and out, and display targeted countries in the world over the last 3 months. The intensity of the targeting, meaning the number of relations \"targets\" towards these countries, is reflect by 3 colors. Orange is for heavy targeting, pale orange of medium and yellow for low.</li> <li>Last ingested analysis: display the list of the last 8 objects belonging o the analysis section which have been created (manually or by a connector) in the platform. This included reports but also notes, opinions and external references. These can be clicked to access directly the page of the analysis.</li> <li>Observable distribution: indicates the 10 top observable types in the platform and the absolute number of entities for each type. As for the top 10 active entities, the value is displayed when the mouse is run over.</li> </ul> <p></p>"},{"location":"usage/platform/#presentation-of-a-typical-page-in-opencti","title":"Presentation of a typical page in OpenCTI","text":"<p>Although there are many different entities in OpenCTI and many different tabs, most of them are quite similar and only have minor differences from the other, mostly due to some of their characteristics, which requires specific fields or do not require some fields which are necessary for the other. </p> <p>In this part will only be detailed a general outline of a \"typical\" OpenCTI page. The specifies of the different entities will be detailed in the corresponding pages below (Activities and Knowledge).</p> <p>Entities are usually presented as such:</p> <ul> <li>an <code>Overview</code> tab, general page on the entity. Just as the welcome dashboard gives an overview of the whole platform, the <code>Overview</code> page of the entity gives an idea of the activity regading this entity. You can find general information on the entity such as the ID of the entity, the confidence level, the markings, the author and the creator, dates, description etc. as well as widgets that show the general activity on the entity, such as last relations created, latest reports mentionning the entity, most recent history and external references.</li> </ul> <p>Below are two images showing an \"overview\" tab of an intrusion set.</p> <p></p> <p><code>Overview</code> tab of an intrusion set (top part)</p> <p></p> <p><code>Overview</code> tab of an intrusion set (bottom part)</p> <ul> <li> <p>A <code>Knowledge</code> tab, which is the central part of the entity. The <code>Knowledge</code> tab is different for a <code>Report</code> entity than for all the other tabs.</p> <ul> <li><code>Knowledge</code> tabs of any entity except for reports gather all the entities which have been at some point linked to the entity the user is looking at (for instance, as shown in the following capture, the <code>Knowledge</code> tab of Intrusion set APT29) gives access to the list of all entities APT29 is attributed to, all victims the intrusion set has targeted, all its campaigns, TTPs, malwares etc. . For entities to appear in theses tabs under <code>Knowledge</code>, they need to have been linked to the entity directly or have to be computed with the inference engine (to come).</li> </ul> <p></p> <ul> <li>The <code>Knowledge</code> tab of reports is the place to integrate and link together entities. For more information on how to integrate information in OpenCTI using the knowledge tab of a report, please refer to the part Update the knowledge</li> </ul> </li> <li> <p>The <code>Analysis</code> tab contains the list of all the reports in which the entity has been identified. The list can be ordered only by dates.</p> </li> </ul> <p>Example of the list of reports in which the attack pattern \"data obfuscation\" has been identified.</p> <p></p> <ul> <li>The <code>Files</code> tab</li> </ul> <p>The file tab contains documents that are associated to the object and were either :</p> <ul> <li>Uploaded to the platform : for instance the PDF document containing the text of the report</li> <li>Generated from the platform to be downloaded : a JSON or CSV file containing information on the object and generatedby the user.</li> </ul> <p></p> <ul> <li>The <code>History</code> tab</li> </ul> <p>This tab display the history of change of the element, update of attributes, creation of relations, ...</p> <p>Because of the volumes of information the history is written in a specific index by the history connector (https://www.notion.so/luatix/History-17503579a70c467ba02ec11350c593bf) that consume the redis stream to rebuild the history for the UI.</p> <p></p> <p>Less frequent tabs are the following:</p> <ul> <li>The <code>Indicators</code> tab (for all the threats and the entities in arsenal - except the courses of action -)</li> <li>The <code>Observables</code> tab (for reports, observed data</li> <li>the <code>Entities</code> tab (for reports and observed data)</li> <li>the <code>Sightings</code> tab (for Indicators and observables)</li> </ul>"}]}