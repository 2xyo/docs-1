{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"OpenCTI Documentation Space","text":"<p>Welcome to the OpenCTI Documentation space. Here you will be able to find all documents, meeting notes and presentations about the platform.</p> <p>Need more help?</p> <p>We are doing our best to keep this documentation complete, accurate and up to date. If you still have questions or you find something which is not sufficiently explained, join the Filigran Community on Slack.</p>"},{"location":"#introduction","title":"Introduction","text":"<p>OpenCTI is an open source platform allowing organizations to manage their cyber threat intelligence knowledge and observables. It has been created in order to structure, store, organize and visualize technical and non-technical information about cyber threats.</p>"},{"location":"#getting-started","title":"Getting started","text":"<ul> <li> <p> Deployement &amp; Setup</p> <p>Learn how to deploy and configure the platform as well as launch connectors to get the first data in OpenCTI.</p> <p> Deploy now</p> </li> <li> <p> User Guide</p> <p>Understand how to use the platform, explore the knowledge, import and export information, create dashboard, etc.</p> <p> Explore</p> </li> <li> <p> Administration</p> <p>Know how to administrate OpenCTI, create users and groups using RBAC / segregation, put retention policies and custom taxonomies.</p> <p> Customize</p> </li> </ul>"},{"location":"#latest-blog-posts","title":"Latest blog posts","text":"<p>Articles</p> <p>All tutorials are published directly on the Medium blog, this section provides a comprehensive list of the most important ones.</p> <ul> <li> <p>OpenCTI knowledge streams can now be turned into public feeds! <sub><sup>Apr 18, 2023</sup></sub></p> <p>OpenCTI has multiple ways of sharing data with other platform and third-party systems: TAXII collections, CSV feeds, custom connectors and live streams...</p> <p> Read</p> </li> <li> <p>OCTI notifications and digests: a new powerful engine for the knowledge graph <sub><sup>Feb 7, 2023</sup></sub></p> <p>For more and more organizations, OpenCTI is (or starts to be) the nervous system of cyber intelligence knowledge (for both threats and operational data)...</p> <p> Read</p> </li> <li> <p>New OCTI dashboards: the first graph dashboarding engine for the STIX model <sub><sup>Jan 15, 2023</sup></sub></p> <p>When we\u2019ve started working on Key Performance Indicators (KPI), trends modelization and graphical representation of the Cyber Threat Intelligence knowledge...</p> <p> Read</p> </li> </ul>"},{"location":"#additional-resources","title":"Additional resources","text":"<p>Below, you will find external resources which may be useful along your OpenCTI journey.</p> <p> OpenCTI Ecosystem List of available connectors and integrations to expand platform usage.</p> <p> Training Courses Training courses for analysts and administrators in the Filigran training center.</p> <p> Performances tests &amp; metrics Regular performance tests based on default configuration and datasets.</p> <p></p>"},{"location":"administration/introduction/","title":"Introduction","text":"<p>This guide aims to give you a full overview of the OpenCTI features and workflows. The platform can be used in various contexts to handle threats management use cases from a technical to a more strategic level.</p>"},{"location":"administration/parameters/","title":"Platform","text":""},{"location":"deployment/authentication/","title":"Authentication","text":""},{"location":"deployment/authentication/#introduction","title":"Introduction","text":"<p>OpenCTI supports several authentication providers. If you configure multiple strategies, they will be tested in the order you declared them.</p> <p>Activation</p> <p>You need to configure/activate only that you really want to propose to your users in term of authentication</p> <p>The product proposes two kind of authentication strategy:</p> <ul> <li>Form (asking user for a user/password)</li> <li>Buttons (click with authentication on an external system)</li> </ul>"},{"location":"deployment/authentication/#supported-strategies","title":"Supported Strategies","text":"<p>Under the hood we technically use the strategies provided by PassportJS. We integrate a subset of the strategies available with passport we if you need more we can theatrically integrate all the passport strategies.</p>"},{"location":"deployment/authentication/#local-users-form","title":"Local users (form)","text":"<p>This strategy used the OpenCTI database as user management.</p> <p>OpenCTI use this strategy as the default but its not the one we recommend for security reason.</p> <pre><code>\"local\": {\n\"strategy\": \"LocalStrategy\",\n\"config\": {\n\"disabled\": false\n}\n}\n</code></pre> <p>Production deployment</p> <p>Please use the LDAP/Auth0/OpenID/SAML strategy for production deployment.</p>"},{"location":"deployment/authentication/#ldap-form","title":"LDAP (form)","text":"<p>This strategy can be used to authenticate your user with your company LDAP and is based on Passport - LDAPAuth.</p> <pre><code>\"ldap\": {\n\"strategy\": \"LdapStrategy\",\n\"config\": {\n\"url\": \"ldaps://mydc.domain.com:686\",\n\"bind_dn\": \"cn=Administrator,cn=Users,dc=mydomain,dc=com\",\n\"bind_credentials\": \"MY_STRONG_PASSWORD\",\n\"search_base\": \"cn=Users,dc=mydomain,dc=com\",\n\"search_filter\": \"(cn={{username}})\",\n\"mail_attribute\": \"mail\",\n// \"account_attribute\": \"givenName\",\n// \"firstname_attribute\": \"cn\",\n// \"lastname_attribute\": \"cn\",\n\"account_attrgroup_search_filteribute\": \"givenName\",\n\"allow_self_signed\": true\n}\n}\n</code></pre> <p>If you would like to use LDAP groups to automatically associate LDAP groups and OpenCTI groups/organizations:</p> <pre><code>\"ldap\": {\n\"config\": {\n...\n\"group_search_base\": \"cn=Groups,dc=mydomain,dc=com\",\n\"group_search_filter\": \"(member={{dn}})\",\n\"groups_management\": { // To map LDAP Groups to OpenCTI Groups\n\"group_attribute\": \"cn\",\n\"groups_mapping\": [\"LDAP_Group_1:OpenCTI_Group_1\", \"LDAP_Group_2:OpenCTI_Group_2\", ...]\n},\n\"organizations_management\": { // To map LDAP Groups to OpenCTI Organizations\n\"group_attribute\": \"cn\",\n\"groups_mapping\": [\"LDAP_Group_1:OpenCTI_Organization_1\", \"LDAP_Group_2:OpenCTI_Organization_2\", ...]\n}\n}\n}\n</code></pre>"},{"location":"deployment/authentication/#saml-button","title":"SAML (button)","text":"<p>This strategy can be used to authenticate your user with your company SAML and is based on Passport - SAML.</p> <pre><code>\"saml\": {\n\"identifier\": \"saml\",\n\"strategy\": \"SamlStrategy\",\n\"config\": {\n\"issuer\": \"mytestsaml\",\n// \"account_attribute\": \"nameID\",\n// \"firstname_attribute\": \"nameID\",\n// \"lastname_attribute\": \"nameID\",\n\"entry_point\": \"https://auth.mydomain.com/auth/realms/mydomain/protocol/saml\",\n\"saml_callback_url\": \"http://localhost:4000/auth/saml/callback\",\n// \"private_key\": \"MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwg...\",\n\"cert\": \"MIICmzCCAYMCBgF2Qt3X1zANBgkqhkiG9w0BAQsFADARMQ8w...\"\n}\n}\n</code></pre> <p>For the SAML strategy to work:</p> <ul> <li>The <code>cert</code> parameter is mandatory (PEM format) because it is used to validate the SAML response.</li> <li>The <code>private_key</code> (PEM format) is optional and is only required if you want to sign the SAML client request.</li> </ul> <p>Certificates</p> <p>Be careful to put the <code>cert</code> / <code>private_key</code>  key in PEM format. Indeed, a lot of systems generally export the the keys in X509 / PCKS12 formats and so you will need to convert them.  Here is an example to extract PEM from PCKS12: <pre><code>openssl pkcs12 -in keystore.p12 -out newfile.pem -nodes\n</code></pre></p> <p>Here is an example of SAML configuration using environment variables:</p> <pre><code>- PROVIDERS__SAML__STRATEGY=SamlStrategy - \"PROVIDERS__SAML__CONFIG__LABEL=Login with SAML\"\n- PROVIDERS__SAML__CONFIG__ISSUER=mydomain\n- PROVIDERS__SAML__CONFIG__ENTRY_POINT=https://auth.mydomain.com/auth/realms/mydomain/protocol/saml\n- PROVIDERS__SAML__CONFIG__SAML_CALLBACK_URL=http://opencti.mydomain.com/auth/saml/callback\n- PROVIDERS__SAML__CONFIG__CERT=MIICmzCCAYMCBgF3Rt3X1zANBgkqhkiG9w0BAQsFADARMQ8w\n</code></pre> <p>OpenCTI support mapping SAML Roles/Groups on OpenCTI Groups. Here is an example:</p> <pre><code>\"saml\": {\n\"config\": {\n...,\n// Groups mapping\n\"groups_management\": { // To map SAML Groups to OpenCTI Groups\n\"group_attributes\": [\"Group\"],\n\"groups_mapping\": [\"SAML_Group_1:OpenCTI_Group_1\", \"SAML_Group_2:OpenCTI_Group_2\", ...]\n},\n\"groups_management\": { // To map SAML Roles to OpenCTI Groups\n\"group_attributes\": [\"Role\"],\n\"groups_mapping\": [\"SAML_Role_1:OpenCTI_Group_1\", \"SAML_Role_2:OpenCTI_Group_2\", ...]\n},\n// Organizations mapping\n\"organizations_management\": { // To map SAML Groups to OpenCTI Organizations\n\"group_attributes\": [\"Group\"],\n\"groups_mapping\": [\"SAML_Group_1:OpenCTI_Organization_1\", \"SAML_Group_2:OpenCTI_Organization_2\", ...]\n},\n\"organizations_management\": { // To map SAML Roles to OpenCTI Organizations\n\"group_attributes\": [\"Role\"],\n\"groups_mapping\": [\"SAML_Role_1:OpenCTI_Organization_1\", \"SAML_Role_2:OpenCTI_Organization_2\", ...]\n}\n}\n}\n</code></pre> <p>Here is an example of SAML Groups mapping configuration using environment variables:</p> <pre><code>- \"PROVIDERS__SAML__CONFIG__GROUPS_MANAGEMENT__GROUPS_ATTRIBUTES=[\\\"Group\\\"]\"\n- \"PROVIDERS__SAML__CONFIG__GROUPS_MANAGEMENT__GROUPS_MAPPING=[\\\"SAML_Group_1:OpenCTI_Group_1\\\", \\\"SAML_Group_2:OpenCTI_Group_2\\\", ...]\"\n</code></pre>"},{"location":"deployment/authentication/#auth0-button","title":"Auth0 (button)","text":"<p>This strategy allows to use Auth0 Service to handle the authentication and is based on Passport - Auth0.</p> <pre><code>\"authzero\": {\n\"identifier\": \"auth0\",\n\"strategy\": \"Auth0Strategy\",\n\"config\": {\n\"clientID\": \"XXXXXXXXXXXXXXXXXX\",\n\"baseURL\": \"https://opencti.mydomain.com\",\n\"clientSecret\": \"XXXXXXXXXXXXXXXXXX\",\n\"callback_url\": \"https://opencti.mydomain.com/auth/auth0/callback\",\n\"domain\": \"mycompany.eu.auth0.com\",\n\"audience\": \"XXXXXXXXXXXXXXX\",\n\"scope\": \"openid email profile XXXXXXXXXXXXXXX\"\n}\n}\n</code></pre>"},{"location":"deployment/authentication/#openid-connect-button","title":"OpenID Connect (button)","text":"<p>This strategy allows to use the OpenID Connect Protocol to handle the authentication and is based on Node OpenID Client that is more powerful than the passport one.</p> <pre><code>\"oic\": {\n\"identifier\": \"oic\",\n\"strategy\": \"OpenIDConnectStrategy\",\n\"config\": {\n\"label\": \"Login with OpenID\",\n\"issuer\": \"https://auth.mydomain.com/auth/realms/mydomain\",\n\"client_id\": \"XXXXXXXXXXXXXXXXXX\",\n\"client_secret\": \"XXXXXXXXXXXXXXXXXX\",\n\"redirect_uris\": [\"https://opencti.mydomain.com/auth/oic/callback\"]\n}\n}\n</code></pre> <p>Here is an example of OpenID configuration using environment variables:</p> <pre><code>- PROVIDERS__OPENID__STRATEGY=OpenIDConnectStrategy - \"PROVIDERS__OPENID__CONFIG__LABEL=Login with OpenID\"\n- PROVIDERS__OPENID__CONFIG__ISSUER=https://auth.mydomain.com/auth/realms/xxxx\n- PROVIDERS__OPENID__CONFIG__CLIENT_ID=XXXXXXXXXXXXXXXXXX\n- PROVIDERS__OPENID__CONFIG__CLIENT_SECRET=XXXXXXXXXXXXXXXXXX\n- \"PROVIDERS__OPENID__CONFIG__REDIRECT_URIS=[\\\"https://opencti.mydomain.com/auth/oic/callback\\\"]\"\n</code></pre> <p>OpenCTI support mapping OpenID Roles/Groups on OpenCTI Groups (everything is tied to a group in the platform). Here is an example:</p> <pre><code>\"oic\": {\n\"config\": {\n...,\n// Groups mapping\n\"groups_management\": { // To map OpenID Groups to OpenCTI Groups\n\"groups_scope\": \"groups\",\n\"groups_path\": [\"groups\", \"realm_access.groups\", \"resource_access.account.groups\"],\n\"groups_mapping\": [\"OpenID_Group_1:OpenCTI_Group_1\", \"OpenID_Group_2:OpenCTI_Group_2\", ...]\n},\n\"groups_management\": { // To map OpenID Roles to OpenCTI Groups\n\"groups_scope\": \"roles\",\n\"groups_path\": [\"roles\", \"realm_access.roles\", \"resource_access.account.roles\"],\n\"groups_mapping\": [\"OpenID_Role_1:OpenCTI_Group_1\", \"OpenID_Role_2:OpenCTI_Group_2\", ...]\n},\n// Organizations mapping  \n\"organizations_management\": { // To map OpenID Groups to OpenCTI Organizations\n\"organizations_scope\": \"groups\",\n\"organizations_path\": [\"groups\", \"realm_access.groups\", \"resource_access.account.groups\"],\n\"organizations_mapping\": [\"OpenID_Group_1:OpenCTI_Group_1\", \"OpenID_Group_2:OpenCTI_Group_2\", ...]\n},\n\"organizations_management\": { // To map OpenID Roles to OpenCTI Organizations\n\"organizations_scope\": \"roles\",\n\"organizations_path\": [\"roles\", \"realm_access.roles\", \"resource_access.account.roles\"],\n\"organizations_mapping\": [\"OpenID_Role_1:OpenCTI_Group_1\", \"OpenID_Role_2:OpenCTI_Group_2\", ...]\n},\n}\n}\n</code></pre> <p>Here is an example of OpenID Groups mapping configuration using environment variables:</p> <pre><code>- \"PROVIDERS__OPENID__CONFIG__GROUPS_MANAGEMENT__GROUPS_SCOPE=groups\"\n- \"PROVIDERS__OPENID__CONFIG__GROUPS_MANAGEMENT__GROUPS_PATH=[\\\"groups\\\", \\\"realm_access.groups\\\", \\\"resource_access.account.groups\\\"]\"\n- \"PROVIDERS__OPENID__CONFIG__GROUPS_MANAGEMENT__GROUPS_MAPPING=[\\\"OpenID_Group_1:OpenCTI_Group_1\\\", \\\"OpenID_Group_2:OpenCTI_Group_2\\\", ...]\"\n</code></pre>"},{"location":"deployment/authentication/#facebook-button","title":"Facebook (button)","text":"<p>This strategy can authenticate your users with Facebook and is based on Passport - Facebook</p> <pre><code>\"facebook\": {\n\"identifier\": \"facebook\",\n\"strategy\": \"FacebookStrategy\",\n\"config\": {\n\"client_id\": \"XXXXXXXXXXXXXXXXXX\",\n\"client_secret\": \"XXXXXXXXXXXXXXXXXX\",\n\"callback_url\": \"https://opencti.mydomain.com/auth/facebook/callback\"\n}\n}\n</code></pre>"},{"location":"deployment/authentication/#google-button","title":"Google (button)","text":"<p>This strategy can authenticate your users with Google and is based on Passport - Google</p> <pre><code>\"google\": {\n\"identifier\": \"google\",\n\"strategy\": \"GoogleStrategy\",\n\"config\": {\n\"client_id\": \"XXXXXXXXXXXXXXXXXX\",\n\"client_secret\": \"XXXXXXXXXXXXXXXXXX\",\n\"callback_url\": \"https://opencti.mydomain.com/auth/google/callback\"\n}\n}\n</code></pre>"},{"location":"deployment/authentication/#github-button","title":"GitHub (button)","text":"<p>This strategy can authenticate your users with GitHub and is based on Passport - GitHub</p> <pre><code>\"github\": {\n\"identifier\": \"github\",\n\"strategy\": \"GithubStrategy\",\n\"config\": {\n\"client_id\": \"XXXXXXXXXXXXXXXXXX\",\n\"client_secret\": \"XXXXXXXXXXXXXXXXXX\",\n\"callback_url\": \"https://opencti.mydomain.com/auth/github/callback\"\n}\n}\n</code></pre>"},{"location":"deployment/authentication/#client-certificate-button","title":"Client certificate (button)","text":"<p>This strategy can authenticate a user based on SSL client certificates. For this you need to configure your OCTI to start in HTTPS, for example:</p> <pre><code>\"port\": 443,\n\"https_cert\": {\n\"key\": \"/cert/server_key.pem\",\n\"crt\": \"/cert/server_cert.pem\",\n\"reject_unauthorized\":true\n}\n</code></pre> <p>And then add the <code>ClientCertStrategy</code>:</p> <pre><code>\"cert\": {\n\"strategy\":\"ClientCertStrategy\",\n\"config\": {\n\"label\":\"CLIENT CERT\"\n}\n}\n</code></pre> <p>Then when accessing for the first time OCTI, the browser will ask for the certificate you want to use.</p>"},{"location":"deployment/authentication/#examples","title":"Examples","text":""},{"location":"deployment/authentication/#ldap-then-fallback-to-local","title":"LDAP then fallback to local","text":"<p>In this example the users have a login form and need to enter login and password. The authentication is done on LDAP first, then locally if user failed to authenticate and finally fail if none of them succeded. Here is an example for the <code>production.json</code> file:</p> <pre><code>\"providers\": {\n\"ldap\": {\n\"strategy\": \"LdapStrategy\",\n\"config\": {\n\"url\": \"ldaps://mydc.mydomain.com:636\",\n\"bind_dn\": \"cn=Administrator,cn=Users,dc=mydomain,dc=com\",\n\"bind_credentials\": \"MY_STRONG_PASSWORD\",\n\"search_base\": \"cn=Users,dc=mydomain,dc=com\",\n\"search_filter\": \"(cn={{username}})\",\n\"mail_attribute\": \"mail\",\n\"account_attribute\": \"givenName\"\n}\n},\n\"local\": {\n\"strategy\": \"LocalStrategy\",\n\"config\": {\n\"disabled\": false\n}\n}\n}\n</code></pre> <p>If you use a container deployment, here is an example using environment variables:</p> <pre><code>- PROVIDERS__LDAP__STRATEGY=LdapStrategy\n- PROVIDERS__LDAP__CONFIG__URL=ldaps://mydc.mydomain.org:636\n- PROVIDERS__LDAP__CONFIG__BIND_DN=cn=Administrator,cn=Users,dc=mydomain,dc=com\n- PROVIDERS__LDAP__CONFIG__BIND_CREDENTIALS=XXXXXXXXXX\n- PROVIDERS__LDAP__CONFIG__SEARCH_BASE=cn=Users,dc=mydomain,dc=com\n- PROVIDERS__LDAP__CONFIG__SEARCH_FILTER=(cn={{username}})\n- PROVIDERS__LDAP__CONFIG__MAIL_ATTRIBUTE=mail\n- PROVIDERS__LDAP__CONFIG__ACCOUNT_ATTRIBUTE=givenName\n- PROVIDERS__LDAP__CONFIG__ALLOW_SELF_SIGNED=true\n- PROVIDERS__LOCAL__STRATEGY=LocalStrategy\n</code></pre>"},{"location":"deployment/clustering/","title":"Clustering","text":"<p>Under construction</p>"},{"location":"deployment/configuration/","title":"Configuration","text":"<p>The purpose of this section is to learn how to configure OpenCTI to have it tailored for your production and development needs. </p> <p>Here are the configuration keys, for both containers (environment variables) and manual deployment.</p> <p>Parameters equivalence</p> <p>The equivalent of a config variable in environment variables is the usage of a double underscores (<code>__</code>) for a level of config.</p> <p>For example: <pre><code>\"providers\": {\n\"ldap\": {\n\"strategy\": \"LdapStrategy\"\n}\n}\n</code></pre></p> <p>will become: <pre><code>PROVIDERS__LDAP__STRATEGY=LdapStrategy\n</code></pre></p> <p>If you need to put a list of elements for the key, it must have a special formatting. Here is an example for redirect URIs for OpenID config: <pre><code>\"PROVIDERS__OPENID__CONFIG__REDIRECT_URIS=[\\\"https://demo.opencti.io/auth/oic/callback\\\"]\"\n</code></pre></p>"},{"location":"deployment/configuration/#platform","title":"Platform","text":""},{"location":"deployment/configuration/#api-frontend","title":"API &amp; Frontend","text":""},{"location":"deployment/configuration/#basic-parameters","title":"Basic parameters","text":"Parameter Environment variable Default value Description app:port APP__PORT 4000 Listen port of the application app:base_path APP__BASE_PATH Specific URI (ie. /opencti) app:base_url APP__BASE_URL http://localhost:4000 Full URL of the platform (should include the <code>base_path</code> if any) app:request_timeout APP__REQUEST_TIMEOUT 1200000 Request timeout, in ms (default 20 minutes) app:session_timeout APP__SESSION_TIMEOUT 1200000 Session timeout, in ms (default 20 minutes) app:admin:email APP__ADMIN__EMAIL admin@opencti.io Default login email of the admin user app:admin:password APP__ADMIN__PASSWORD ChangeMe Default password of the admin user app:admin:token APP__ADMIN__TOKEN ChangeMe Default token (must be a valid UUIDv4)"},{"location":"deployment/configuration/#ssl-tls","title":"SSL / TLS","text":"Parameter Environment variable Default value Description app:https_cert:ca APP__HTTPS_CERT__CA Empty list [] Certificate authority paths, only if the client uses a self-signed certificate. app:https_cert:key APP__HTTPS_CERT__KEY Certificate key path app:https_cert:crt APP__HTTPS_CERT__CRT Certificate crt path app:https_cert:reject_unauthorized APP__HTTPS_CERT__REJECT_UNAUTHORIZED If not false, the server certificate is verified against the list of supplied CAs"},{"location":"deployment/configuration/#logging","title":"Logging","text":""},{"location":"deployment/configuration/#errors","title":"Errors","text":"Parameter Environment variable Default value Description app:app_logs:logs_level APP__APP_LOGS__LOGS_LEVEL info The application log level app:app_logs:logs_files APP__APP_LOGS__LOGS_FILES <code>true</code> If application logs is logged into files app:app_logs:logs_console APP__APP_LOGS__LOGS_CONSOLE <code>true</code> If application logs is logged to console (useful for containers) app:app_logs:logs_max_files APP__APP_LOGS__LOGS_MAX_FILES 7 Maximum number of daily files in logs app:app_logs:logs_directory APP__APP_LOGS__LOGS_DIRECTORY ./logs File logs directory"},{"location":"deployment/configuration/#audit","title":"Audit","text":"Parameter Environment variable Default value Description app:audit_logs:logs_files APP__AUDIT_LOGS__LOGS_FILES <code>true</code> If audit logs is logged into files app:audit_logs:logs_console APP__AUDIT_LOGS__LOGS_CONSOLE <code>true</code> If audit logs is logged to console (useful for containers) app:audit_logs:logs_max_files APP__AUDIT_LOGS__LOGS_MAX_FILES 7 Maximum number of daily files in logs app:audit_logs:logs_directory APP__AUDIT_LOGS__LOGS_DIRECTORY ./logs Audit logs directory"},{"location":"deployment/configuration/#maps-references","title":"Maps &amp; references","text":"Parameter Environment variable Default value Description app:map_tile_server_dark APP__MAP_TILE_SERVER_DARK https://map.opencti.io/styles/luatix-dark/{z}/{x}/{y}.png The address of the OpenStreetMap provider with dark theme style app:map_tile_server_light APP__MAP_TILE_SERVER_LIGHT https://map.opencti.io/styles/luatix-light/{z}/{x}/{y}.png The address of the OpenStreetMap provider with light theme style app:reference_attachment APP__REFERENCE_ATTACHMENT <code>false</code> External reference mandatory attachment"},{"location":"deployment/configuration/#technical-customization","title":"Technical customization","text":"Parameter Environment variable Default value Description app:graphql:playground:enabled APP__GRAPHQL__PLAYGROUND__ENABLED <code>true</code> Enable the playground on /graphql app:graphql:playground:force_disabled_introspection APP__GRAPHQL_PLAYGROUND__FORCE_DISABLED_INTROSPECTION <code>false</code> Introspection is allowed to auth users but can be disabled in needed app:concurrency:retry_count APP__CONCURRENCY__RETRY_COUNT 200 Number of try to get the lock to work an element (create/update/merge, ...) app:concurrency:retry_delay APP__CONCURRENCY__RETRY_DELAY 100 Delay between 2 lock retry (in milliseconds) app:concurrency:retry_jitter APP__CONCURRENCY__RETRY_JITTER 50 Random jitter to prevent concurrent retry  (in milliseconds) app:concurrency:max_ttl APP__CONCURRENCY__MAX_TTL 30000 Global maximum time for lock retry (in milliseconds)"},{"location":"deployment/configuration/#dependencies","title":"Dependencies","text":""},{"location":"deployment/configuration/#elasticsearch","title":"ElasticSearch","text":"Parameter Environment variable Default value Description elasticsearch:url ELASTICSEARCH__URL http://localhost:9200 URL(s) of the ElasticSearch (supports http://user:pass@localhost:9200 and list of URLs) elasticsearch:username ELASTICSEARCH__USERNAME Username can be put in the URL or with this parameter elasticsearch:password ELASTICSEARCH__PASSWORD Password can be put in the URL or with this parameter elasticsearch:index_prefix ELASTICSEARCH__INDEX_PREFIX opencti Prefix for the indices elasticsearch:ssl:reject_unauthorized ELASTICSEARCH__SSL__REJECT_UNAUTHORIZED <code>true</code> Enable TLS certificate check elasticsearch:ssl:ca ELASTICSEARCH__SSL__CA Custom certificate path elasticsearch:ssl:ca_plain ELASTICSEARCH__SSL__CA_PLAIN Custom certificate (plain texc)"},{"location":"deployment/configuration/#redis","title":"Redis","text":"Parameter Environment variable Default value Description redis:mode REDIS__MODE single Connect to redis \"single\" or \"cluster\" redis:namespace REDIS__NAMESPACE Namespace (to use as prefix) redis:hostname REDIS__HOSTNAME localhost Hostname of the Redis Server redis:hostnames REDIS__HOSTNAMES Hostnames definition for Redis cluster mode: a list of host/port objects. redis:port REDIS__PORT 6379 Port of the Redis Server redis:use_ssl REDIS__USE_SSL <code>false</code> Is the Redis Server has TLS enabled redis:username REDIS__USERNAME Username of the Redis Server redis:password REDIS__PASSWORD Password of the Redis Server redis:ca REDIS__CA Path of the CA certificate redis:trimming REDIS__TRIMMING 2000000 Number of elements to maintain in the stream. (0 = unlimited)"},{"location":"deployment/configuration/#rabbitmq","title":"RabbitMQ","text":"Parameter Environment variable Default value Description rabbitmq:hostname RABBITMQ__HOSTNAME localhost Hostname of the RabbitMQ server rabbitmq:port RABBITMQ__PORT 5672 Port of the RabbitMQ server rabbitmq:use_ssl RABBITMQ__USE_SSL <code>false</code> Use TLS connection rabbitmq:port_management RABBITMQ__PORT_MANAGEMENT 15672 Port of the RabbitMQ Management Plugin rabbitmq:management_ssl RABBITMQ__MANAGEMENT_SSL <code>false</code> Is the Management Plugin has TLS enabled rabbitmq:username RABBITMQ__USERNAME guest RabbitMQ user rabbitmq:password RABBITMQ__PASSWORD guest RabbitMQ password rabbitmq:queue_type RABBITMQ__QUEUE_TYPE \"classic\" RabbitMQ Queue Type (\"classic\" or \"quorum\" rabbitmq:ca RABBITMQ__CA Empty list [] Custom CA certificates files"},{"location":"deployment/configuration/#s3-bucket","title":"S3 Bucket","text":"Parameter Environment variable Default value Description minio:endpoint MINIO__ENDPOINT localhost Hostname of the S3 Service minio:port MINIO__PORT 9000 Port of the S3 Service minio:use_ssl MINIO__USE_SSL <code>false</code> Is the S3 Service has TLS enabled minio:access_key MINIO__ACCESS_KEY ChangeMe The S3 Service access key minio:secret_key MINIO__SECRET_KEY ChangeMe The S3 Service secret key minio:bucket_name MINIO__BUCKET_NAME opencti-bucket The S3 bucket name (useful to change if you use AWS) minio:bucket_region MINIO__BUCKET_REGION us-east-1 The S3 bucket region if you use AWS minio:use_aws_role MINIO__USE_AWS_ROLE <code>false</code> To use AWS role auto credentials"},{"location":"deployment/configuration/#smtp-service","title":"SMTP Service","text":"Parameter Environment variable Default value Description smtp:hostname SMTP__HOSTNAME SMTP Server hostname smtp:port SMTP__PORT 9000 SMTP Port (25 or 465 for TLS) smtp:use_ssl SMTP__USE_SSL <code>false</code> SMTP over TLS smtp:reject_unauthorized SMTP__REJECT_UNAUTHORIZED <code>false</code> Enable TLS certificate check smtp:username SMTP__USERNAME SMTP Username if authentication is needed smtp:password SMTP__PASSWORD SMTP Password if authentication is needed smtp:from_email SMTP__FROM_EMAIL notifications@opencti.io Sender email address"},{"location":"deployment/configuration/#schedules-engines","title":"Schedules &amp; Engines","text":"Parameter Environment variable Default value Description rule_engine:enabled RULE_ENGINE__ENABLED <code>true</code> Enable/disable the rule engine rule_engine:lock_key RULE_ENGINE__LOCK_KEY rule_engine_lock Lock key of the engine in Redis - - - - history_manager:enabled HISTORY_MANAGER__ENABLED <code>true</code> Enable/disable the history manager history_manager:lock_key HISTORY_MANAGER__LOCK_KEY history_manager_lock Lock key for the manager in Redis - - - - task_scheduler:enabled TASK_SCHEDULER__ENABLED <code>true</code> Enable/disable the task scheduler task_scheduler:lock_key TASK_SCHEDULER__LOCK_KEY task_manager_lock Lock key for the scheduler in Redis task_scheduler:interval TASK_SCHEDULER__INTERVAL 10000 Interval to check new task to do (in ms) - - - - sync_manager:enabled SYNC_MANAGER__ENABLED <code>true</code> Enable/disable the sync manager sync_manager:lock_key SYNC_MANAGER__LOCK_KEY sync_manager_lock Lock key for the manager in Redis sync_manager:interval SYNC_MANAGER__INTERVAL 10000 Interval to check new sync feeds to consume (in ms) - - - - expiration_scheduler:enabled EXPIRATION_SCHEDULER__ENABLED <code>true</code> Enable/disable the scheduler expiration_scheduler:lock_key EXPIRATION_SCHEDULER__LOCK_KEY expired_manager_lock Lock key for the scheduler in Redis expiration_scheduler:interval EXPIRATION_SCHEDULER__INTERVAL 300000 Interval to check expired indicators - - - - retention_manager:enabled RETENTION_MANAGER__ENABLED <code>true</code> Enable/disable the manager retention_manager:lock_key RETENTION_MANAGER__LOCK_KEY retention_manager_lock Lock key for the manager in Redis retention_manager:interval RETENTION_MANAGER__INTERVAL 60000 Interval to check items to be deleted - - - - notification_manager:enabled NOTIFICATION_MANAGER__ENABLED <code>true</code> Enable/disable the notification manager notification_manager:lock_key NOTIFICATION_MANAGER__LOCK_KEY notification_manager_lock Lock key for the manager in Redis notification_manager:interval NOTIFICATION_MANAGER__INTERVAL 10000 Sender email address - - - - publisher_manager:enabled PUBLISHER_MANAGER__ENABLED <code>true</code> Enable/disable the publisher manager publisher_manager:lock_key PUBLISHER_MANAGER__LOCK_KEY publisher_manager_lock Sender email address publisher_manager:interval PUBLISHER_MANAGER__INTERVAL 10000 Sender email address <p>Default file</p> <p>It is possible to check all default parameters implemented in the platform in the <code>default.json</code> file.</p>"},{"location":"deployment/configuration/#worker","title":"Worker","text":"<p>The Python worker can be configured manually using the configuration file <code>config.yml</code> or through environment variables.</p> Parameter Environment variable Default value Description opencti:url OPENCTI_URL The URL of the OpenCTI platform opencti:token OPENCTI_TOKEN A token of an administrator account with bypass capability worker:log_level WORKER_LOG_LEVEL info The log level (error, warning, info or debug)"},{"location":"deployment/configuration/#elasticsearch_1","title":"ElasticSearch","text":"<p>If you want to adapt the memory consumption of ElasticSearch, you can use theses options:</p> <pre><code># Add the followiung environment variable:\n\"ES_JAVA_OPTS=-Xms8g -Xmx8g\"\n</code></pre> <p>This can be done in configuration file in the <code>jvm.conf</code> file.</p>"},{"location":"deployment/connectors/","title":"Connectors","text":""},{"location":"deployment/connectors/#introduction","title":"Introduction","text":"<p>Connectors list</p> <p>You are looking for the available connectors? The list is in the OpenCTI Ecosystem.</p> <p>Connectors are the cornerstone of the OpenCTI platform and allow organizations to easily ingest, enrich or export data in the platform. According to their functionality and use case, they are categorized in following classes.</p> <p></p>"},{"location":"deployment/connectors/#import","title":"Import","text":"<p>These connectors automatically retrieve information from an external organization, application or service, convert it to STIX 2.1 bundles and import it into OpenCTI using the workers.</p>"},{"location":"deployment/connectors/#enrichment","title":"Enrichment","text":"<p>When a new object is created in the platform or on the user request, it is possible to trigger the internal enrichment connector to lookup and/or search the object in external organizations, applications or services. If the object is found, the connectors will generate a STIX 2.1 bundle which will increase the level of knowledge about the concerned object.</p>"},{"location":"deployment/connectors/#stream","title":"Stream","text":"<p>These connectors connect to a platform data stream and continously do something with the received events. In most cases, they are used to consume OpenCTI data and insert them in third-party platforms such as SIEMs, XDRs, EDRS, etc. In some cases, stream connectors can also query the external system on a regular basis and act as import connector for instance to gather alerts and sightings related to CTI data and push them to OpenCTI (bi-directional).</p>"},{"location":"deployment/connectors/#import-files","title":"Import files","text":"<p>Information from an uploaded file can be extracted and ingested into OpenCTI. Examples are files attached to a report or a STIX 2.1 file.</p>"},{"location":"deployment/connectors/#export-files","title":"Export files","text":"<p>Information stored in OpenCTI can be extracted into different file formats like .csv or .json (STIX 2).</p>"},{"location":"deployment/connectors/#connector-configuration","title":"Connector configuration","text":"<p>All connectors have to be able to access to the OpenCTI API. To allow this connection, they have 2 mandatory configuration parameters, the <code>OPENCTI_URL</code> and the <code>OPENCTI_TOKEN</code>. In addition of these 2 parameters, connectors have other mandatory parameters that need to be set in order to get them work.</p> <p>Connectors tokens</p> <p>Be careful, we strongly recommend to use a dedicated token for each connector running in the platform. So you have to create a specific user for each of them.</p> <p>Also, if all connectors users can run in with a user belonging to the <code>Connectors</code> group (with the <code>Connector</code> role), the <code>Internal Export Files</code> should be run with a user who is Administrator (with bypass capability) because they imperstonate the user requesting the export to avoid data leak.</p> Type Required role Used permissions EXTERNAL_IMPORT Connector Import data with the connector user. INTERNAL_ENRICHMENT Connector Enrich data with the connector user. INTERNAL_IMPORT_FILE Connector Import data with the connector user. INTERNAL_EXPORT_FILE Administrator Export data with the user who requested the export. STREAM Connector Consume the streams the connector user. <p>Here is an example of a connector <code>docker-compose.yml</code> file: <pre><code>- CONNECTOR_ID=ChangeMe\n- CONNECTOR_TYPE=EXTERNAL_IMPORT\n- CONNECTOR_NAME=MITRE ATT&amp;CK\n- CONNECTOR_SCOPE=identity,attack-pattern,course-of-action,intrusion-set,malware,tool,report\n- CONNECTOR_CONFIDENCE_LEVEL=3\n- CONNECTOR_UPDATE_EXISTING_DATA=true\n- CONNECTOR_LOG_LEVEL=info\n</code></pre></p> <p>Here is an example in a connector <code>config.yml</code> file:</p> <pre><code>-connector:\nid: 'ChangeMe'\ntype: 'EXTERNAL_IMPORT'\nname: 'MITRE ATT&amp;CK'\nscope: 'identity,attack-pattern,course-of-action,intrusion-set,malware,tool,report'\nconfidence_level: 3\nupdate_existing_data: true\nlog_level: 'info'\n</code></pre>"},{"location":"deployment/connectors/#networking","title":"Networking","text":"<p>Be aware that all connectors are reaching RabbitMQ based the RabbitMQ configuration provided by the OpenCTI platform. The connector must be able to reach RabbitMQ on the specified hostname and port. If you have a specific Docker network configuration, please be sure to adapt your <code>docker-compose.yml</code> file in such way that the connector container gets attached to the OpenCTI Network, e.g.:</p> <pre><code>networks:\ndefault:\nexternal: true\nname: opencti-docker_default\n</code></pre>"},{"location":"deployment/connectors/#connector-token","title":"Connector token","text":""},{"location":"deployment/connectors/#create-the-user","title":"Create the user","text":"<p>As mentionned previously, it is strongly recommended to run each connector with its own user. The <code>Internal Export File</code> connectors should be launched with a user that belongs to a group which has an \u201cAdministrator\u201d role (with bypass all capabilities enabled).</p> <p>By default in platform, a group named \"Connectors\" already exists. So just create a new user with the name <code>[C] Name of the connector</code> in Settings &gt; Security &gt; Users.</p> <p></p>"},{"location":"deployment/connectors/#put-the-user-in-the-group","title":"Put the user in the group","text":"<p>Just go to the user you have just created and add it to the <code>Connectors</code> group.</p> <p></p> <p>Then just get the token of the user displayed in the interface.</p> <p></p>"},{"location":"deployment/connectors/#docker-activation","title":"Docker activation","text":"<p>You can either directly run the Docker image of connectors or add them to your current <code>docker-compose.yml</code> file.</p>"},{"location":"deployment/connectors/#add-a-connector-to-your-deployment","title":"Add a connector to your deployment","text":"<p>For instance, to enable the MISP connector, you can add a new service to your <code>docker-compose.yml</code> file:</p> <pre><code>  connector-misp:\n    image: opencti/connector-misp:latest\n    environment:\n      - OPENCTI_URL=http://localhost\n      - OPENCTI_TOKEN=ChangeMe\n      - CONNECTOR_ID=ChangeMe\n      - CONNECTOR_TYPE=EXTERNAL_IMPORT\n      - CONNECTOR_NAME=MISP\n      - CONNECTOR_SCOPE=misp\n      - CONNECTOR_CONFIDENCE_LEVEL=3\n- CONNECTOR_UPDATE_EXISTING_DATA=false\n      - CONNECTOR_LOG_LEVEL=info\n      - MISP_URL=http://localhost # Required\n      - MISP_KEY=ChangeMe # Required\n      - MISP_SSL_VERIFY=False # Required\n      - MISP_CREATE_REPORTS=True # Required, create report for MISP event\n      - MISP_REPORT_CLASS=MISP event # Optional, report_class if creating report for event\n      - MISP_IMPORT_FROM_DATE=2000-01-01 # Optional, import all event from this date\n      - MISP_IMPORT_TAGS=opencti:import,type:osint # Optional, list of tags used for import events\n      - MISP_INTERVAL=1 # Required, in minutes\n    restart: always\n</code></pre>"},{"location":"deployment/connectors/#launch-a-standalone-connector","title":"Launch a standalone connector","text":"<p>To launch standalone connector, you can use the <code>docker-compose.yml</code> file of the connector itself. Just download the latest release and start the connector:</p> <pre><code>$ wget https://github.com/OpenCTI-Platform/connectors/archive/{RELEASE_VERSION}.zip\n$ unzip {RELEASE_VERSION}.zip\n$ cd connectors-{RELEASE_VERSION}/misp/\n</code></pre> <p>Change the configuration in the <code>docker-compose.yml</code> according to the parameters of the platform and of the targeted service. Then launch the connector:</p> <pre><code>$ docker-compose up\n</code></pre>"},{"location":"deployment/connectors/#manual-activation","title":"Manual activation","text":"<p>If you want to manually launch connector, you just have to install Python 3 and pip3 for dependencies:</p> <pre><code>$ apt install python3 python3-pip\n</code></pre> <p>Download the release of the connectors:</p> <pre><code>$ wget &lt;https://github.com/OpenCTI-Platform/connectors/archive/{RELEASE_VERSION}.zip&gt;\n$ unzip {RELEASE_VERSION}.zip\n$ cd connectors-{RELEASE_VERSION}/misp/src/\n</code></pre> <p>Install dependencies and initialize the configuration:</p> <pre><code>$ pip3 install -r requirements.txt\n$ cp config.yml.sample config.yml\n</code></pre> <p>Change the <code>config.yml</code> content according to the parameters of the platform and of the targeted service and launch the connector:</p> <pre><code>$ python3 misp.py\n</code></pre>"},{"location":"deployment/connectors/#connectors-status","title":"Connectors status","text":"<p>The connector status can be displayed in the dedicated section of the platform available in Data &gt; Connectors. You will be able to see the statistics of the RabbitMQ queue of the connector:</p> <p></p> <p>Problem</p> <p>If you encounter problems deploying OpenCTI or connectors, you can consult the troubleshooting page page.</p>"},{"location":"deployment/installation/","title":"Installation","text":"<p>All components of OpenCTI are shipped both as Docker images and manual installation packages.</p> <p>Production deployment</p> <p>For production deployment, we recommend to deploy all components in containers, including dependencies, using native cloud services or orchestration systems such as Kubernetes.</p> <p>To have more details about deploying OpenCTI and its dependencies in cluster mode, please read the dedicated section.</p> <ul> <li> <p> Use Docker</p> <p>Deploy OpenCTI using Docker and the default <code>docker-compose.yml</code> provided in the docker.</p> <p> Setup</p> </li> <li> <p> Manual installation</p> <p>Deploy dependencies and launch the platform manually using the packages released in the GitHub releases.</p> <p> Explore</p> </li> </ul>"},{"location":"deployment/installation/#using-docker","title":"Using Docker","text":""},{"location":"deployment/installation/#introduction","title":"Introduction","text":"<p>OpenCTI can be deployed using the docker-compose command.</p>"},{"location":"deployment/installation/#pre-requisites","title":"Pre-requisites","text":"<p> Linux</p> <pre><code>$ sudo apt install docker-compose\n</code></pre> <p> Windows and MacOS</p> <p>Just download the appropriate Docker for Desktop version for your operating system.</p>"},{"location":"deployment/installation/#clone-the-repository","title":"Clone the repository","text":"<p>Docker helpers are available in the Docker GitHub repository.</p> <pre><code>$ mkdir -p /path/to/your/app &amp;&amp; cd /path/to/your/app\n$ git clone https://github.com/OpenCTI-Platform/docker.git\n$ cd docker\n</code></pre>"},{"location":"deployment/installation/#configure-the-environment","title":"Configure the environment","text":"<p>Before running the <code>docker-compose</code> command, the <code>docker-compose.yml</code> file should be configured. By default, the <code>docker-compose.yml</code> file is using environment variables available in the file <code>.env.sample</code>.</p> <p>You can either rename the file <code>.env.sample</code> in <code>.env</code> and put the expected values or just fill directly the <code>docker-compose.yml</code> with the values corresponding to your environment.</p> <p>Configuration static parameters</p> <p>The complete list of available static parameters is available in the configuration section.</p> <p>Here is an example to quickly generate the <code>.env</code> file under Linux, especially all the default UUIDv4:</p> <pre><code>$ sudo apt install -y jq\n$ cd ~/docker\n$ (cat &lt;&lt; EOF\nOPENCTI_ADMIN_EMAIL=admin@opencti.io\nOPENCTI_ADMIN_PASSWORD=ChangeMePlease\nOPENCTI_ADMIN_TOKEN=$(cat /proc/sys/kernel/random/uuid)\nMINIO_ROOT_USER=$(cat /proc/sys/kernel/random/uuid)\nMINIO_ROOT_PASSWORD=$(cat /proc/sys/kernel/random/uuid)\nRABBITMQ_DEFAULT_USER=guest\nRABBITMQ_DEFAULT_PASS=guest\nCONNECTOR_HISTORY_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_EXPORT_FILE_STIX_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_EXPORT_FILE_CSV_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_IMPORT_FILE_STIX_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_IMPORT_REPORT_ID=$(cat /proc/sys/kernel/random/uuid)\nEOF\n) &gt; .env\n</code></pre> <p>If your <code>docker-compose</code> deployment does not support <code>.env</code> files, just export all environment variables before launching the platform:</p> <pre><code>$ export $(cat .env | grep -v \"#\" | xargs)\n</code></pre>"},{"location":"deployment/installation/#memory-management-settings","title":"Memory management settings","text":"<p>As OpenCTI has a dependency on ElasticSearch, you have to set the <code>vm.max_map_count</code> before running the containers, as mentioned in the ElasticSearch documentation.</p> <pre><code>$ sudo sysctl -w vm.max_map_count=1048575\n</code></pre> <p>To make this parameter persistent, add the following to the end of your <code>/etc/sysctl.conf</code>:</p> <pre><code>$ vm.max_map_count=1048575\n</code></pre>"},{"location":"deployment/installation/#persist-data","title":"Persist data","text":"<p>The default for OpenCTI data is to be persistent.</p> <p>In the <code>docker-compose.yml</code>, you will find at the end the list of necessary persitent volumes for the dependencies:</p> <pre><code>volumes:\nesdata:     # ElasticSearch data\ns3data:     # S3 bucket data\nredisdata:  # Redis data\namqpdata:   # RabbitMQ data\n</code></pre>"},{"location":"deployment/installation/#run-opencti","title":"Run OpenCTI","text":""},{"location":"deployment/installation/#using-single-node-docker","title":"Using single node Docker","text":"<p>After changing your <code>.env</code> file run <code>docker-compose</code> in detached (-d) mode:</p> <pre><code>$ sudo systemctl start docker.service\n# Run docker-compose in detached \n$ docker-compose up -d\n</code></pre>"},{"location":"deployment/installation/#using-docker-swarm","title":"Using Docker swarm","text":"<p>In order to have the best experience with Docker, we recommend using the Docker stack feature. In this mode you will have the capacity to easily scale your deployment. </p> <pre><code># If your virtual machine is not a part of a Swarm cluster, please use:\n$ docker swarm init\n</code></pre> <p>Put your environment variables in <code>/etc/environment</code>:</p> <pre><code># If you already exported your variables to .env from above:\n$ sudo cat .env &gt;&gt; /etc/environment\n$ sudo bash -c 'cat .env &gt;&gt; /etc/environment\u2019\n$ sudo docker stack deploy --compose-file docker-compose.yml opencti\n</code></pre> <p>Installation done</p> <p>You can now go to http://localhost:8080 and log in with the credentials configured in your environment variables.</p>"},{"location":"deployment/installation/#manual-installation","title":"Manual installation","text":""},{"location":"deployment/installation/#prerequisites","title":"Prerequisites","text":""},{"location":"deployment/installation/#prepare-the-installation","title":"Prepare the installation","text":""},{"location":"deployment/installation/#installation-of-dependencies","title":"Installation of dependencies","text":"<p>You have to install all the needed dependencies for the main application and the workers. The example below is for Debian-based systems:</p> <pre><code>$ sudo apt-get install nodejs npm python3 python3-pip </code></pre>"},{"location":"deployment/installation/#download-the-application-files","title":"Download the application files","text":"<p>First, you have to download and extract the latest release file. Then select the version to install depending of your operating system: </p> <p>For Linux:</p> <ul> <li>If your OS support the libc (Ubuntu, Debian, ...) you have to install the <code>opencti-release_{RELEASE_VERSION}.tar.gz</code> version.</li> <li>If your OS uses musl (Alpine, ...) you have to install the <code>opencti-release-{RELEASE_VERSION}_musl.tar.gz</code> version</li> </ul> <p>For Windows:</p> <p>We don't provide any Windows release for now. However it is still possible to check the code out, manually install the dependencies and build the software.</p> <pre><code>$ mkdir /path/to/your/app &amp;&amp; cd /path/to/your/app\n$ wget &lt;https://github.com/OpenCTI-Platform/opencti/releases/download/{RELEASE_VERSION}/opencti-release-{RELEASE_VERSION}.tar.gz&gt;\n$ tar xvfz opencti-release-{RELEASE_VERSION}.tar.gz\n</code></pre>"},{"location":"deployment/installation/#install-the-main-platform","title":"Install the main platform","text":""},{"location":"deployment/installation/#configure-the-application","title":"Configure the application","text":"<p>The main application has just one JSON configuration file to change and a few Python modules to install</p> <pre><code>$ cd opencti\n$ cp config/default.json config/production.json\n</code></pre> <p>Change the config/production.json file according to your configuration of ElasticSearch, Redis, RabbitMQ and S3 bucket as well as default credentials (the <code>ADMIN_TOKEN</code> must be a valid UUID).</p>"},{"location":"deployment/installation/#install-the-python-modules","title":"Install the Python modules","text":"<pre><code>$ cd src/python\n$ pip3 install -r requirements.txt\n$ cd ../..\n</code></pre>"},{"location":"deployment/installation/#start-the-application","title":"Start the application","text":"<p>The application is just a NodeJS process, the creation of the database schema and the migration will be done at starting.</p> <pre><code>$ yarn install\n$ yarn build\n$ yarn serv\n</code></pre> <p>The default username and password are those you have put in the <code>config/production.json</code> file.</p>"},{"location":"deployment/installation/#install-the-worker","title":"Install the worker","text":"<p>The OpenCTI worker is used to write the data coming from the RabbitMQ messages broker.</p>"},{"location":"deployment/installation/#configure-the-worker","title":"Configure the worker","text":"<pre><code>$ cd worker\n$ pip3 install -r requirements.txt\n$ cp config.yml.sample config.yml\n</code></pre> <p>Change the config.yml file according to your OpenCTI token.</p>"},{"location":"deployment/installation/#start-as-many-workers-as-you-need","title":"Start as many workers as you need","text":"<pre><code>$ python3 worker.py &amp;\n$ python3 worker.py &amp;\n</code></pre> <p>Installation done</p> <p>You can now go to http://localhost:4000 and log in with the credentials configured in your <code>production.json</code> file.</p>"},{"location":"deployment/installation/#appendix","title":"Appendix","text":""},{"location":"deployment/installation/#community-contributions","title":"Community contributions","text":""},{"location":"deployment/installation/#terraform","title":"Terraform","text":"<ul> <li> <p> Multi-clouds Terraform scripts</p> <p>This repository is here to provide you with a quick and easy way to deploy an OpenCTI instance in the cloud (AWS, Azure, or GCP).</p> <p> GitHub Respository</p> </li> <li> <p> AWS Advanced Terraform scripts</p> <p>A Terraform deployment of OpenCTI designed to make use of native AWS Resources (where feasible). This includes AWS ECS Fargate, AWS OpenSearch, etc.</p> <p> GitHub Repository</p> </li> </ul>"},{"location":"deployment/installation/#helm-charts","title":"Helm Charts","text":"<ul> <li> <p> Kubernetes Helm Charts</p> <p>OpenCTI Helm Charts (may be out of date) for Kubernetes with a global configuration file.</p> <p> GitHub Repository</p> </li> </ul>"},{"location":"deployment/installation/#deploy-behind-a-reverse-proxy","title":"Deploy behind a reverse proxy","text":"<p>If you want to use OpenCTI behind a reverse proxy with a context path, like <code>https://domain.com/opencti</code>, please change the <code>base_path</code> static parameter.</p> <ul> <li><code>APP__BASE_PATH=/opencti</code></li> </ul> <p>By default OpenCTI use websockets so don't forget to configure your proxy for this usage, an example with <code>Nginx</code>:</p> <pre><code>location / {\nproxy_cache                 off;\nproxy_buffering             off;\nproxy_http_version          1.1;\nproxy_set_header Upgrade    $http_upgrade;\nproxy_set_header Connection \"upgrade\";\nproxy_set_header Host       $host;\nchunked_transfer_encoding   off;\nproxy_pass                  http://YOUR_UPSTREAM_BACKEND;\n}\n</code></pre>"},{"location":"deployment/installation/#additional-memory-information","title":"Additional memory information","text":""},{"location":"deployment/installation/#platform","title":"Platform","text":"<p>OpenCTI platform is based on a NodeJS runtime, with a memory limit of 8GB by default. If you encounter <code>OutOfMemory</code> exceptions, this limit could be changed:</p> <pre><code>- NODE_OPTIONS=--max-old-space-size=8096\n</code></pre>"},{"location":"deployment/installation/#workers-and-connectors","title":"Workers and connectors","text":"<p>OpenCTI workers and connectors are Python processes. If you want to limit the memory of the process, we recommend to directly use Docker to do that. You can find more information in the official Docker documentation.</p>"},{"location":"deployment/installation/#elasticsearch","title":"ElasticSearch","text":"<p>ElasticSearch is also a JAVA process. In order to setup the JAVA memory allocation, you can use the environment variable <code>ES_JAVA_OPTS</code>. You can find more information in the official ElasticSearch documentation.</p>"},{"location":"deployment/installation/#redis","title":"Redis","text":"<p>Redis has a very small footprint on keys but will consume memory for the stream. By default the size of the stream is limited to 2 millions which represents a memory footprint around <code>8 GB</code>. You can find more information in the Redis docker hub.</p>"},{"location":"deployment/installation/#minio-s3-bucket","title":"MinIO / S3 Bucket","text":"<p>MinIO is a small process and does not require a high amount of memory. More information are available for Linux here on the Kernel tuning guide.</p>"},{"location":"deployment/installation/#rabbitmq","title":"RabbitMQ","text":"<p>The RabbitMQ memory configuration can be find in the RabbitMQ official documentation. RabbitMQ will consumed memory until a specific threshold, therefore it should be configure along with the Docker memory limitation.</p>"},{"location":"deployment/integrations/","title":"Integrations","text":""},{"location":"deployment/integrations/#introduction","title":"Introduction","text":"<p>OpenCTI supports multiple ways to integrate with other systems which do not have native connectors or plugins to the platform. Here are the technical features available to ease the connection and the integration of the platform with other applications.</p> <p>Connectors list</p> <p>If you are looking to the list of OpenCTI connectors or native integration, please check the OpenCTI Ecosystem.</p>"},{"location":"deployment/integrations/#native-feeds-and-streams","title":"Native feeds and streams","text":"<p>To ease integrations with other products, OpenCTI has built-in capabilities to deliver the data to third-parties.</p>"},{"location":"deployment/integrations/#csv-feeds","title":"CSV Feeds","text":"<p>It is possible to create as many CSV feeds as needed, based on filters and accessible in HTTP. CSV feeds are available in Data &gt; Data sharing &gt; Feeds (CSV).</p> <p>When creating a CSV feed, you need to select one or multiple types of entity to make available. For all columns available in the CSV, you've to select which field will be used for each type of entity:</p> <p></p> <p>Details</p> <p>For more information about CSV feeds, filters and configuration, please check the Export in structured format section.</p>"},{"location":"deployment/integrations/#taxii-collections","title":"TAXII collections","text":"<p>Most of the moden cybersecurity systems such as SIEMs, EDRs, XDRs and even firewalls supports the TAXII protocol which is basically a paginated HTTP STIX feed. OpenCTI implements a TAXII 2.1 server with the ability to create as many TAXII collections as needed in Data &gt; Data sharing &gt; TAXII Collections?</p> <p>TAXII collections are a sub-selection of the knowledge available in the platform and relie on filters. For instance, it is possible to create TAXII collections for pieces of malware with a given label, for indicators with a score greater than n, etc.</p> <p></p>"},{"location":"deployment/integrations/#http-streams","title":"HTTP Streams","text":"<p>After implementing CSV feeds and TAXII collections, we figured out that those 2 stateless APIs are definitely not enough when it comes to tackle advanced information sharing challenges such as:</p> <ul> <li>Real time transmission of the information (ie. avoid hundreds of systems to pull data every 5 minutes).</li> <li>Dependencies resolution (ie. an intrusion created by an organization but the organization is not in the TAXII collection).</li> <li>Partial update for huge entities such as report (ie. just having the update event).</li> <li>Delete events when necessary (ie. to handle indicators expiration in third party systems for instance).</li> </ul> <p>Live streams are available in Data &gt; Data sharing &gt; Live streams. As TAXII collections, it is possible to create as many streams as needed using filters.</p> <p></p> <p>Streams implement the HTTP SSE (Server-sent events) protocol and give applications to consume a real time pure STIX 2.1 stream. Stream connectors in the OpenCTI Ecosystem are using live streams to consume data and do something such as create / update / delete information in SIEMs, XDRs, etc.</p>"},{"location":"deployment/integrations/#authentication","title":"Authentication","text":"<p>For all previously explained capabilities, as they are over the HTTP protocol, 3 authentication mechanisms are available to consume them.</p> <ol> <li> <p>Using a bearer header with your OpenCTI API key</p> <pre><code>Authorization: Bearer a17bc103-8420-4208-bd53-e1f80845d15f\n</code></pre> <p>API Key</p> <p>Your API key can be found in your profile available clicking on the top right icon.</p> </li> <li> <p>Using basic authentication</p> <pre><code>Username: Your platform username\nPassword: Your plafrom password\nAuthorization: Basic c2FtdWVsLmhhc3NpbmVBZmlsaWdyYW4uaW86TG91aXNlMTMwNCM=\n</code></pre> </li> <li> <p>Using client certificate authentication</p> <p>To know how to configure the client certificate authentication, please consult the authentication configuration section.</p> </li> </ol>"},{"location":"deployment/integrations/#api-and-libraries","title":"API and libraries","text":""},{"location":"deployment/integrations/#graphql-api","title":"GraphQL API","text":"<p>To allow analysts and developers to implement more custom or complex use cases, a full GraphQL API is available in the application on the <code>/graphql</code> endpoint.</p> <p>The API can be queried using various GraphQL client such as Postman but you can leverage any HTTP client to forge GraphQL queries using <code>POST</code> methods.</p>"},{"location":"deployment/integrations/#authentication_1","title":"Authentication","text":"<p>The API authentication can be performed using the token of a user and a classic Authorization header:</p> <pre><code>Content-Type: application/json\nAuthorization: Bearer 6b6554c4-bb2c-4c80-9cd3-30288c8bf424\n</code></pre>"},{"location":"deployment/integrations/#playground","title":"Playground","text":"<p>The playground is available on the <code>/graphql</code> endpoint. A link button is also available in the profile of your user.</p> <p></p> <p>All the schema documentation is directly available in the playground.</p> <p></p> <p>If you already logged to OpenCTI with the same browser you should be able to directly do some requests. If you are not authenticated or want to authenticate only through the playground you can use a header configuration using your profile token</p> <p>Example of configuration (bottom left of the playground):</p> <p></p>"},{"location":"deployment/integrations/#python-library","title":"Python library","text":"<p>Since not everyone is familiar with GraphQL APIs, we've developed a Python library to ease the interaction with it. The library is pretty easy to use. To initiate the client:</p> <pre><code># coding: utf-8\nfrom pycti import OpenCTIApiClient\n# Variables\napi_url = \"http://opencti:4000\"\napi_token = \"bfa014e0-e02e-4aa6-a42b-603b19dcf159\"\n# OpenCTI initialization\nopencti_api_client = OpenCTIApiClient(api_url, api_token)\n</code></pre> <p>Then just use the available helpers: <pre><code># Search for malware with the keyword \"windows\"\nmalwares = opencti_api_client.malware.list(search=\"windows\")\n# Print\nprint(malwares)\n</code></pre></p> <p>Details</p> <p>For more detailed information about the Python library, please read the dedicated section.</p>"},{"location":"deployment/overview/","title":"Overview","text":"<p>Before starting the installation, let's discover how OpenCTI is working, which dependencies are needed and what are the minimal requirements to deploy it in production.</p>"},{"location":"deployment/overview/#architecture","title":"Architecture","text":"<p>The OpenCTI platform relies on several external databases and services in order to work.</p> <p></p>"},{"location":"deployment/overview/#platform","title":"Platform","text":"<p>The platform is the central part of the OpenCTI technological stack. It allows users to access to the user interface but also provides the GraphQL API used by connectors and workers to insert data. In the context of a production deployment, you may need to scale horizontally and launch multiple platforms behind a load balancer connected to the same databases (ElasticSearch, Redis, S3, RabbitMQ).</p>"},{"location":"deployment/overview/#workers","title":"Workers","text":"<p>The workers are standalone Python processes consuming messages from the RabbitMQ broker in order to do asynchronous write queries. You can launch as many workers as you need to increase the write performances. At some point, the write performances will be limited by the throughput of the ElasticSearch database cluster.</p> <p>Number of workers</p> <p>If you need to increase performances, it is better to launch more platforms to handle worker queries. The recommended setup is to have at least one platform for 3 workers (ie. 9 workers distributed over 3 platforms).</p>"},{"location":"deployment/overview/#connectors","title":"Connectors","text":"<p>The connectors are third-party pieces of software (Python processes) that can play four different roles on the platform:</p> Type Description Examples EXTERNAL_IMPORT Pull data from remote sources, convert it to STIX2 and insert it on the OpenCTI platform. MITRE Datasets, MISP, CVE, AlienVault, Mandiant, etc. INTERNAL_ENRICHMENT Listen for new OpenCTI entities or users requests, pull data from remote sources to enrich. Shodan, DomainTools, IpInfo, etc. INTERNAL_IMPORT_FILE Extract data from files uploaded on OpenCTI trough the UI or the API. STIX 2.1, PDF, Text, HTML, etc. INTERNAL_EXPORT_FILE Generate export from OpenCTI data, based on a single object or a list. STIX 2.1, CSV, PDF, etc. STREAM Consume a platform data stream an do something with events. Splunk, Elastic Security, Q-Radar, etc. <p>List of connectors</p> <p>You can find all currently available connector in the OpenCTI Ecosystem.</p>"},{"location":"deployment/overview/#infrastructure-requirements","title":"Infrastructure requirements","text":""},{"location":"deployment/overview/#dependencies","title":"Dependencies","text":"Component CPU RAM Disk type Disk space ElasticSearch 2 cores \u2265 8GB SSD \u2265 16GB Redis 1 core \u2265 1GB SSD \u2265 16GB RabbitMQ 1 core \u2265 512MB Standard \u2265 2GB S3 / MinIO 1 core \u2265 128MB SSD \u2265 16GB"},{"location":"deployment/overview/#platform_1","title":"Platform","text":"Component CPU RAM Disk type Disk space OpenCTI Core 2 cores \u2265 8GB None (stateless) - Worker(s) 1 core \u2265 128MB None (stateless) - Connector(s) 1 core \u2265 128MB None (stateless) - <p>Clustering</p> <p>To have more details about deploying OpenCTI and its dependencies in cluster mode, please read the dedicated section.</p>"},{"location":"deployment/rollover/","title":"Rollover policies","text":"<p>Under construction</p>"},{"location":"deployment/third-party/","title":"Third-party systems","text":""},{"location":"deployment/third-party/#introduction","title":"Introduction","text":"<p>Under construction</p>"},{"location":"deployment/troubleshooting/","title":"Troubleshooting","text":"<p>This page aims to explains the typical errors you can have with your OpenCTI platform.</p>"},{"location":"deployment/troubleshooting/#common-errors","title":"Common errors","text":"<p>Missing reference to handle creation</p> <p>After 5 retries, if an element required to create another element is missing, the platform raises an exception. It usually comes from a connector that generates inconsistent STIX 2.1 bundles.</p> <p>Cant upsert entity. Too many entities resolved</p> <p>OpenCTI received an entity which is matching too many other entities in the platform. In this condition we cannot take a decision. We need to dig into the data bundle to identify why he match too much entities and fix the data in the bundle / or the platform according to what you expect.</p> <p>Execution timeout, too many concurrent call on the same entities</p> <p>The platform supports multi workers and multiple parallel creation but different parameters can lead to some locking timeout in the execution. </p> <ul> <li>Throughput capacity of your ElasticSearch</li> <li>Number of workers started at the same time</li> <li>Dependencies between data</li> <li>Merging capacity of OpenCTI</li> </ul> <p>If you have this kind of error, limit the number of workers deployed. Try to find the right balance of the number of workers, connectors and elasticsearch sizing.</p> <p>Indicator of type yara is not correctly formatted</p> <p>OpenCTI check the validity of the indicator rule.</p> <p>Observable of type IPv4-Addr is not correctly formatted</p> <p>OpenCTI check the validity of the oversable value</p> <p>TOO_MANY_REQUESTS/12/disk usage exceeded flood-stage watermark, index has read-only-allow-delete block</p> <p>Disk full, no space left on the device for ElasticSearch.</p>"},{"location":"deployment/upgrade/","title":"Upgrade","text":"<p>Depending on your installation mode, upgrade path may change.</p> <p>Migrations</p> <p>The platform is taking care of all necessary underlying migrations in the databases if any, you can upgrade OpenCTI from any version to the latest one, including skipping multiple major releases.</p>"},{"location":"deployment/upgrade/#using-docker","title":"Using Docker","text":"<p>Before applying this procedure, please update your <code>docker-compose.yml</code> file with the new version number of container images.</p>"},{"location":"deployment/upgrade/#for-single-node-docker","title":"For single node Docker","text":"<pre><code>$ sudo docker-compose stop\n$ sudo docker-compose pull\n$ sudo docker-compose up -d\n</code></pre>"},{"location":"deployment/upgrade/#for-docker-swarm","title":"For Docker swarm","text":"<p>For each of services, you have to run the following command:</p> <pre><code>$ sudo docker service update --force service_name\n</code></pre>"},{"location":"deployment/upgrade/#manual-installation","title":"Manual installation","text":"<p>When upgrading the platform, you have to replace all files and restart the platform, the database migrations will be done automatically:</p> <pre><code>$ yarn serv\n</code></pre>"},{"location":"development/environment/","title":"Environment setup","text":"<p>This summary should give you a detailed setup description for initiating the OpenCTI setup environment necessary for developing on the OpenCTI platform, a client library or the connectors.</p> <p>This page document how to setting up an \"All-in-One\" development **environment for OpenCTI. Everything was done on a virtual machine (Virtualbox VM - 16 vCPU / 20Gb RAM) which contains:</p> <ul> <li>the OpenCTI project code base:<ul> <li>web frontend (nodejs / react)<ul> <li><code>~/opencti/opencti-platform</code></li> </ul> </li> <li>backend (nodejs / python)<ul> <li><code>~/opencti/opencti-worker</code></li> </ul> </li> <li>connectors (python)<ul> <li><code>~/connectors</code></li> </ul> </li> <li>python client<ul> <li><code>~/client-python</code></li> </ul> </li> </ul> </li> <li>docker-compose for the databases / broker<ul> <li>elasticsearch (and kibana)</li> <li>redis</li> <li>minio</li> <li>rabbitmq</li> </ul> </li> </ul>"},{"location":"development/environment/#prerequisites","title":"Prerequisites","text":""},{"location":"development/environment/#installation-of-dependencies-ubuntu-2004","title":"Installation of dependencies (Ubuntu 20.04)","text":"<p>If you are on a version of Debian/Ubuntu prior to 20, please refer to this GIthub issue.</p> <pre><code>$ sudo apt-get install docker docker-compose curl nodejs python3 python3-pip\n$ sudo curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -\n$ sudo echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n$ sudo apt-get update &amp;&amp; sudo apt-get install yarn\n</code></pre>"},{"location":"development/environment/#docker-stack","title":"Docker stack","text":"<p>As OpenCTI has a dependency to ElasticSearch, you have to set the vm.max_map_count before running the containers, as mentioned in the ElasticSearch documentation.</p> <pre><code>$ sudo sysctl -w vm.max_map_count=262144\n</code></pre> <p>Clone the latest version of the dev docker compose and start</p> <pre><code>$ git clone https://github.com/OpenCTI-Platform/docker.git\n$ cd docker\n$ docker-compose -f ./docker-compose-dev.yml up -d\n</code></pre>"},{"location":"development/environment/#clone-the-project","title":"Clone the project","text":"<p>Depending on the part of OpenCTI to which you want to contribute, fork and clone the appropriate git repository or just clone repos</p> <ul> <li>https://github.com/OpenCTI-Platform/opencti/ - frontend / backend</li> <li>https://github.com/OpenCTI-Platform/connectors - connectors</li> <li>https://github.com/OpenCTI-Platform/docker - docker stack</li> <li>https://github.com/OpenCTI-Platform/client-python/ - python client</li> </ul> <p>Example with the <code>opencti</code> repository:</p> <pre><code>git clone git@github.com:YOUR-USERNAME/opencti.git\ncd ~/opencti\ngit remote add upstream https://github.com/OpenCTI-Platform/opencti.git\n\ncd\ngit clone https://github.com/opencti/connectors.git\ngit clone https://github.com/opencti/docker.git\ngit clone https://github.com/opencti/client-python.git\n</code></pre>"},{"location":"development/environment/#application-dependencies","title":"Application dependencies","text":""},{"location":"development/environment/#install-the-backend-graphql-api-dependencies","title":"Install the backend GraphQL API dependencies","text":"<p>The GraphQL API is developped in JS and with some python code. As it's an \"all-in-one\" installation, the python environment will be installed in a virtual environment.</p> <pre><code>cd ~/opencti/opencti-platform/opencti-graphql\npython3 -m venv .venv --prompt \"graphql\"\nsource .venv/bin/activate\npip install --upgrade pip wheel setuptools\nyarn install\nyarn install:python deactivate\n</code></pre>"},{"location":"development/environment/#install-the-frontend-dependencies-and-build-it","title":"Install the frontend dependencies and build it","text":"<pre><code>cd ~/opencti/opencti-platform/opencti-front\nyarn install\nyarn build\n# The resulting build is then copied to ../../opencti-graphql/public/\n</code></pre>"},{"location":"development/environment/#install-the-worker-dependencies","title":"Install the worker dependencies","text":"<pre><code>cd ~/opencti/opencti-worker/src\npython3 -m venv .venv --prompt \"worker\"\nsource .venv/bin/activate\npip3 install --upgrade pip wheel setuptools\npip3 install -r requirements.txt\ndeactivate\n</code></pre>"},{"location":"development/environment/#configure-the-stack","title":"Configure the stack","text":""},{"location":"development/environment/#configure-docker","title":"Configure Docker","text":"<p>Create a config file which contains:</p> <ul> <li>the opencti admin user/pass</li> <li>user/pass for minio, rabbitmq</li> <li>an UUID for each connector</li> </ul> <pre><code>sudo apt install -y jq\ncd ~/docker\n(cat &lt;&lt;EOF\nOPENCTI_ADMIN_EMAIL=admin@opencti.io\nOPENCTI_ADMIN_PASSWORD=CHANGEMEPLEASE\nOPENCTI_ADMIN_TOKEN=$(cat /proc/sys/kernel/random/uuid)\nMINIO_ROOT_USER=$(cat /proc/sys/kernel/random/uuid)\nMINIO_ROOT_PASSWORD=$(cat /proc/sys/kernel/random/uuid)\nRABBITMQ_DEFAULT_USER=guest\nRABBITMQ_DEFAULT_PASS=guest\nCONNECTOR_HISTORY_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_EXPORT_FILE_STIX_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_EXPORT_FILE_CSV_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_IMPORT_FILE_STIX_ID=$(cat /proc/sys/kernel/random/uuid)\nCONNECTOR_IMPORT_REPORT_ID=$(cat /proc/sys/kernel/random/uuid)\nDOCKER_IP=$(ip -j a show dev docker0 |jq -r '.[0].addr_info[0].local')\nEOF\n) &gt; .env\n\ncd ~/docker # trick to export the .env \nexport $(cat .env | grep -v \"#\" | xargs)\necho \"\"\"admin username: ${OPENCTI_ADMIN_EMAIL}\nadmin password: ${OPENCTI_ADMIN_PASSWORD}\nminio user : ${MINIO_ROOT_USER}\nminio password : ${MINIO_ROOT_PASSWORD}\"\"\"\n</code></pre>"},{"location":"development/environment/#configure-the-backend-graphql-api","title":"Configure the backend (GraphQL API)","text":"<p>We use the credentials defined in <code>~/docker/.env</code> to update the configuration of the backend.</p> <pre><code>sudo apt install -y jq moreutils\ncd ~/opencti/opencti-platform/opencti-graphql/config\njq '.app.admin.token = $newtoken' --arg newtoken ${OPENCTI_ADMIN_TOKEN} \\\ndefault.json &gt; development.json\njq '.app.admin.password = $newtoken' --arg newtoken ${OPENCTI_ADMIN_PASSWORD} \\\ndevelopment.json | sponge development.json\njq '.minio.access_key = $newtoken' --arg newtoken ${MINIO_ROOT_USER} \\\ndevelopment.json | sponge development.json\njq '.minio.secret_key = $newtoken' --arg newtoken ${MINIO_ROOT_PASSWORD} \\\ndevelopment.json | sponge development.json\n\njq '.redis.hostname = $newtoken' --arg newtoken ${DOCKER_IP} \\\ndevelopment.json | sponge development.json\njq '.rabbitmq.hostname = $newtoken' --arg newtoken ${DOCKER_IP} \\\ndevelopment.json | sponge development.json\njq '.minio.hostname = $newtoken' --arg newtoken ${DOCKER_IP} \\\ndevelopment.json | sponge development.json\njq '.elasticsearch.url = $newtoken' --arg newtoken \"http://${DOCKER_IP}:9200\" \\\ndevelopment.json | sponge development.json\n</code></pre> <p>Skip this command if you have a SMTP server or if you install local SMTP (see \"Local SMTP (Optionnal)\") </p> <pre><code>jq '.subscription_scheduler.enabled = $newtoken' --arg newtoken \"false\" \\\ndevelopment.json | sponge development.json\n</code></pre>"},{"location":"development/environment/#configure-the-backend-worker","title":"Configure the backend (worker)","text":"<pre><code>cd ~/opencti/opencti-worker/src\nsed \"s/ChangeMe/${OPENCTI_ADMIN_TOKEN}/g\" config.yml.sample &gt; config.yml\n</code></pre>"},{"location":"development/environment/#start-the-stack","title":"Start the stack !","text":""},{"location":"development/environment/#start-the-database","title":"Start the database","text":"<pre><code>cd ~/docker\n#Start the stack in background\ndocker-compose -f ./docker-compose-dev.yml up -d\n\ndocker ps\n#&gt; CONTAINER ID   IMAGE                                                  COMMAND                  CREATED       STATUS                            PORTS                                                                                                                                                 NAMES\n#&gt; 11d6b3dfda99   redis:6.2.4                                            \"docker-entrypoint.s\u2026\"   9 hours ago   Up 8 seconds                      0.0.0.0:6379-&gt;6379/tcp, :::6379-&gt;6379/tcp                                                                                                             opencti-dev-redis\n#&gt; e0dc9983e855   rabbitmq:3.8-management                                \"docker-entrypoint.s\u2026\"   9 hours ago   Up 8 seconds                      4369/tcp, 5671/tcp, 0.0.0.0:5672-&gt;5672/tcp, :::5672-&gt;5672/tcp, 15671/tcp, 15691-15692/tcp, 25672/tcp, 0.0.0.0:15672-&gt;15672/tcp, :::15672-&gt;15672/tcp   opencti-dev-rabbitmq\n#&gt; 19a620bc0b0e   docker.elastic.co/kibana/kibana:7.13.1                 \"/bin/tini -- /usr/l\u2026\"   9 hours ago   Up 8 seconds                      0.0.0.0:5601-&gt;5601/tcp, :::5601-&gt;5601/tcp                                                                                                             opencti-dev-kibana\n#&gt; 024f3be652e2   minio/minio:RELEASE.2021-06-14T01-29-23Z               \"/usr/bin/docker-ent\u2026\"   9 hours ago   Up 8 seconds (health: starting)   0.0.0.0:9000-&gt;9000/tcp, :::9000-&gt;9000/tcp                                                                                                             opencti-dev-minio\n#&gt; 4e84dcabb42e   docker.elastic.co/elasticsearch/elasticsearch:7.13.1   \"/bin/tini -- /usr/l\u2026\"   9 hours ago   Up 8 seconds                      0.0.0.0:9200-&gt;9200/tcp, :::9200-&gt;9200/tcp, 0.0.0.0:9300-&gt;9300/tcp, :::9300-&gt;9300/tcp                                                                  opencti-dev-elasticsearch\ndocker logs opencti-dev-redis\n#&gt; 1:C 11 Aug 2021 21:01:32.800 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n#&gt; 1:C 11 Aug 2021 21:01:32.800 # Redis version=6.2.4, bits=64, commit=00000000, modified=0, pid=1, just started\n#&gt; ...\n</code></pre>"},{"location":"development/environment/#start-the-frontend","title":"Start the frontend","text":"<pre><code>cd ~/opencti/opencti-platform/opencti-graphql\nsource .venv/bin/activate\n#yarn start\nexport NODE_OPTIONS=--max_old_space_size=8192\nexport NODE_ENV=development\nyarn serv --conf config/development.json\n</code></pre> <p>The first execution will create and migrate the schema.</p>"},{"location":"development/environment/#start-the-worker-backend","title":"Start the worker backend","text":"<pre><code>cd ~/opencti/opencti-worker/src\nsource .venv/bin/activate\npython worker.py\n</code></pre> <p>The web UI should be accessible on http://127.0.0.1:4000 </p>"},{"location":"development/environment/#build-for-production-use","title":"Build for production use","text":""},{"location":"development/environment/#build-the-application","title":"Build the application","text":"<pre><code>$ cd opencti-frontend\n$ yarn build\n$ cd ../opencti-graphql\n$ yarn build\n</code></pre>"},{"location":"development/environment/#start-the-production-package","title":"Start the production package","text":"<pre><code>$ yarn serv\n</code></pre>"},{"location":"development/environment/#tips","title":"Tips","text":""},{"location":"development/environment/#update-all-repositories","title":"Update all repositories","text":"<pre><code>cd ~/docker\ngit fetch upstream\ngit merge upstream/master\ngit push origin master\n\ncd ~/opencti/\ngit fetch upstream\ngit merge upstream/master\ngit push origin master\n\ncd ~/client-python\ngit fetch upstream\ngit merge upstream/master\ngit push origin master\n\ncd ~/connectors\ngit fetch upstream\ngit merge upstream/master\ngit push origin master\n\n# the hard way\ngit fetch upstream\ngit checkout master\ngit reset --hard upstream/master  git push origin master --force\n</code></pre>"},{"location":"development/environment/#working-on-the-latest-stable-version-tag","title":"Working on the latest stable version (tag)","text":"<pre><code>cd ~/opencti\nLATEST_TAG=$(git describe --abbrev=0 --tags)\necho \"Working on version ${LATEST_TAG}\"\ngit checkout tags/${LATEST_TAG} -b ${LATEST_TAG}-branch\n\ncd ~/client-python &amp;&amp; git checkout tags/${LATEST_TAG} -b ${LATEST_TAG}-branch\ncd ~/connectors &amp;&amp; git checkout tags/${LATEST_TAG} -b ${LATEST_TAG}-branch\ncd ~/docker &amp;&amp; git checkout tags/${LATEST_TAG} -b ${LATEST_TAG}-branch\n</code></pre>"},{"location":"development/environment/#testing-a-connector-in-the-docker-stack","title":"Testing a connector in the docker stack","text":"<p>put the conf of the connector in a separate file:</p> <pre><code>docker-compose -f ./docker-compose-dev.yml -f ./docker-compose-connectors.yml up\n</code></pre>"},{"location":"development/environment/#other-docker-commands","title":"Other docker commands","text":""},{"location":"usage/dashboards/","title":"Platform","text":""},{"location":"usage/data-model/","title":"Data model","text":""},{"location":"usage/import-export/","title":"Import &amp; Export","text":""},{"location":"usage/import-export/#import-knowledge","title":"Import knowledge","text":""},{"location":"usage/import-export/#introduction","title":"Introduction","text":"<p>Before setting up OpenCTI in a production environment, it is highly recommended to first define the requirements for your platform. A knowledge database is only as good as the information's quality, hence sometime it is better to have less data, but of high quality than a lot of mixed quality data. By first thinking about the concept behind your OpenCTI you avoid simply pumping any kind of information into OpenCTI resulting in a \"Data Swamp\".</p> <p>Here are some possible requirements for an OpenCTI instance:</p> <ol> <li>I want to store my own analysis reports and correlate my findings with other reports</li> <li>I want to visualize information and query my knowledge base for new leads</li> <li>I want to share knowledge with others</li> </ol>"},{"location":"usage/import-export/#base-dataset","title":"Base dataset","text":"<p>Before we will start importing reports and SDOs, we have prepare the rest of the system, so that the ingested data can be easily migrated into knowledge. For this we first have to import a base dataset for the \"surrounding\" entities like Attack Patterns, sectors, countries and so on. To do this, we have to add a few connectors to import the necessary files.</p> <p>After those connectors have run, the necessary SDOs are imported which are needed to sufficiently describe observables and indicators.</p>"},{"location":"usage/import-export/#importing-threat-knowledge","title":"Importing Threat knowledge","text":"<p>The basic idea behind importing threat intelligence is that once an analysis on a certain threat is finished a report is written which summarizes the findings. Thus knowledge which is about to be imported comes always as a report.</p> <p>if you are aiming for a high quality knowledge management system, this is the point where you should first evaluate which sources you are using and what kind of information you want to import.</p>"},{"location":"usage/import-export/#manual-import-attached-report","title":"Manual import - Attached Report","text":"<p>One of the two ways of manually importing reports with the support of an internal import file connector. One is with the support of the ImportReport connector which extracts relevant information from the attached files to reports.</p> <p>This approach will be shown with ESET's report on FontOnLake. To properly import the knowledge from this report, please follow the upcoming description.</p> <p>1) [Reports List] Create new report and specify the details like the TLP defintion, labels or external references. We will add the link to the overview as well as to the PDF report as external reference.</p> <p>2) [Report Entities] Since the malware is new, we have to first create that malware entity, otherwise the import report parser won't recognize it later on</p> <p></p> <p>Create Report</p> <p></p> <p>Add new malware</p> <p>3) [Report Entities] Select the newly created malware</p> <p>4) [Report Overview] Import the external reference to the PDF report</p> <p></p> <p></p> <p>5) [Report Files &amp; History] Run the ImportReport parser on the newly imported PDF file</p> <p>6) [Report Files &amp; History] After the parsing process is finished, the mouse over show you the details of the parsed results</p> <p></p> <p></p> <p>7) [Report Observables] Remove observables the parser wrongly classified</p> <p>8) [Report Entities] Remove entities the parser wrongly classified</p> <p></p> <p></p> <p>10) [Report Overview] Imported result</p> <p>11) [Report Knowledge] Mitre ATT&amp;CK mapping</p> <p></p> <p>Final imported report</p> <p></p> <p>MITRE ATT&amp;CK mapping</p>"},{"location":"usage/import-export/#manual-import-stix-file","title":"Manual import - STIX File","text":"<p>Using the ImportFileStix connector, it is possible to import STIX bundles containing any kinds of STIX objects into a report. For this doing this, there are two approaches:</p> <p>a) STIX bundle contains a report</p> <p>Go to the \"Data Import\" section and upload the STIX JSON file. If the STIX JSON file contains a Report object, then this report will be created and all information will be attached to this report.</p> <p>1) [Data import] Launching STIX import connector</p> <p>2) [Report overview] After the STIX JSON file is imported, look for the report in the reports overview and select it. </p> <p></p> <p>Import launch</p> <p></p> <p>b) STIX bundle doesn't contain a report</p> <p>Create a report and attach the STIX JSON file as shown in the above example, then launch the import of the STIX objects which will be referenced to the current report.</p>"},{"location":"usage/import-export/#automatic-connectors","title":"Automatic Connectors","text":"<p>Besides manually importing threat reports, it is possible to use other external import connectors to automatically import reports from external sources. Have a look at the different existing connectors available for different threat intel platforms.</p>  \u26a0\ufe0f As mentioned above, it is highly recommended to evaluate the amount and quality of data about to imported. It is possible that the knowledge management approach of the external service is different to your own, so we really recommend to test and evaluate if those two approaches are compatible before you automatically import external knowledge into your production environment.   <p>OpenCTI has a growing number of connectors, available in the dedicated Github repository. The connectors with type <code>EXTERNAL_IMPORT</code> allow you to automatically import CTI data from external services (ie. AlienVault, MISP, TheHive, etc.).</p>"},{"location":"usage/import-export/#importing-knowledge-via-clients-api","title":"Importing Knowledge via Clients / API","text":"<p>For instance, in the Python library, you can use the methods:</p> <pre><code>from pycti import OpenCTIApiClient\n# Variables\napi_url = \"&lt;https://demo.opencti.io&gt;\"\napi_token = \"2b4f29e3-5ea8-4890-8cf5-a76f61f1e2b2\"\n# OpenCTI initialization\nopencti_api_client = OpenCTIApiClient(api_url, api_token)\n# File to import\nfile_to_import = \"./test.json\"\n# Import the bundle\nopencti_api_client.stix2.import_bundle_from_file(file_to_import)\n</code></pre>"},{"location":"usage/import-export/#export-knowledge","title":"Export knowledge","text":"<p>TODO</p>"},{"location":"usage/introduction/","title":"Introduction","text":"<p>This guide aims to give you a full overview of the OpenCTI features and workflows. The platform can be used in various contexts to handle threats management use cases from a technical to a more strategic level.</p> <p></p>"},{"location":"usage/introduction/#knowledge-graph","title":"Knowledge graph","text":"<p>OpenCTI relies on a knowledge graph with a data model based on the STIX 2.1 standard.</p>"},{"location":"usage/knowledge/","title":"Create knowledge","text":""},{"location":"usage/knowledge/#creating-an-entity-from-any-page","title":"Creating an entity from any page","text":"<p>The knowledge on the OpenCTI platform can be added by manually creating new entities or relationships.</p> <p>In each list of entities, you can add new entities of the corresponding type by clicking on the \"+\" button on the bottom right of the page. For instance, if you are in the reports section, you will only be able to create reports. </p> <p></p> <p>A menu will appear and need to be filled out with information on the new entity, as shown in the image below. Only the name and the description are mandatory fields.</p> <p></p> <p>Labels and authors can be chosen from the scrolling menu, or created directly from this window, using the small \"+\" button, as shown below. In this example, you can see the temporary window for creating a new \"author\" while creating a new \"intrusion set\".</p> <p>New marking levels cannot be added from this menu directly. Adding and editig marking levels is available in the \"Settings\" menu. Admin level-rights are required to edit the list of marking levels.</p> <p></p> <p>The creation menu contains the bare minimum of fields necessary to create the entity. More fields are available for modification once the entity is created, in the \"editing\" mode (see below for more informaiton on editing)</p>  \ud83d\udca1 If you are looking for the whole OpenCTI data model (entities, properties), please refer to the dedicated documentation, which you can find here : [https://www.notion.so/luatix/Data-model-4427344d93a74fe194d5a52ce4a41a8d](https://www.notion.so/Data-model-a84f286a4e1641728ee3951120d45448)"},{"location":"usage/knowledge/#creating-an-entity-within-the-knowledge-tab-of-a-report","title":"Creating an entity within the knowledge tab of a report","text":"<p>Reports are a specific entity in the platform, allowing to trace back the source of a relation between two entities. The knowledge tab of a report is specific to this entity and different from the knwoledge tab of all other entities. </p> <p>The use of this tab is documented in a dedicated page. Please refer to the Adding entities and relations within a report section.</p>"},{"location":"usage/knowledge/#editing-the-knowledge","title":"Editing the knowledge","text":"<p>You can edit any entity at any time using the three vertical dots right of the name of the entity, or the \"pen\" button at the bottom left of the page.</p> <p></p> <p>The editing mode allows the user to modify any of  the fields characterizing an entity, by giving access to two menus: </p> <ul> <li>the \"overview\" menu is the same than the one for the creating of the entity. It allows to modify most of the \"basic information\" on the entity, except fields such as STIX IDS and the date of creation.</li> <li>the \"details\" menu is only accessible from the editing mode and allows to edit details on the entity, such as its motivations for an intrusion set etc.</li> </ul> <p></p> <p>A few fields are specific and can only be edited by clicking on the small orange \"+\" next to tem, which is dedicated to this field. The fields are :</p> <ul> <li>aliases</li> <li>labels</li> <li>external references (URL)</li> <li>notes</li> <li>for some entities, the \"originates from\" in the \"details\" section can also be edited only using such a \"+\" button</li> </ul> <p></p> <p></p>"},{"location":"usage/knowledge/#duplicate-alert-while-creating-a-new-entity","title":"Duplicate alert while creating a new entity","text":"<p>The platform warns you of potential duplicates when you create a new entity. The platform will give a warning if others entities with the same string already exists. </p> <p></p> <p>The alert about duplicates is cliquable. Doing so will open a temporary scrolling menu, displaying all entities already containing this string. Entities can be of different types than the one currently being created. For instance, on the image below, malware containing the \"APT1\" string are also shown.</p> <p></p> <p>It is not possible to directly click on the entity of your choice if it already exists. You will need to abandon the creation you are currently doing by closing the window without validating the creation and afterwards search for the desired entity.</p> <p>You can chose to ignore the alert by closing simply closing the temporary menu and continue adding information in the creation menu. </p>  \ud83d\udca1 \u26a0\ufe0f If the new entity has exactly the same name and the same type as one already existing in the platform, will will be automatically merged at creation.   <p>For any other case (same name but different type, or different name, but the result appeared in the alert because the string exists in the other entity), no merge will be done, and your new entity will exists along the others.</p> <p>To have more information on managing duplicates from the dedicated menu, refer to the page Managing duplicates</p>"},{"location":"usage/notifications/","title":"Platform","text":""},{"location":"usage/platform/","title":"Platform","text":""},{"location":"usage/platform/#introduction","title":"Introduction","text":"<p>The following chapter aims at giving the reader a step-by-step description of what is available on the platform and the meaning of the different tabs and entries.</p> <p>When the user connects to the platform, the home page is the <code>Dashboard</code>. This <code>Dashboard</code> contains several visuals summarizing the types and quantity of data recently imported into the platform. It is described below.</p> <p>The left side panel allows the user to navigate through different windows and access different views and categories of knowledge. These windows are detailed in the different pages linked below.</p>  \ud83d\udc49 If you are looking for the full list of possible entities or relations, please refer to the page [Data model](https://www.notion.so/Data-model-a84f286a4e1641728ee3951120d45448)."},{"location":"usage/platform/#general-information-on-browsing","title":"General information on browsing","text":""},{"location":"usage/platform/#description-of-the-welcome-dashboard","title":"Description of the welcome <code>Dashboard</code>","text":"<p>The welcome <code>Dashboard</code> gives any visitor on the OpenCTI platform an outlook on the live of the platform. The widgets which are displayed cannot be changed, suppressed, resized or moved around. They cannot be clicked except for one (ingested analysis). They are the following:</p> <ul> <li>Total entities: indicates the number of all entities present in the platform, with an indication the added entities in the last 24 hours.</li> <li>Total relationships: indicates the number of all relationships created in the platform, with an indication of added relationships in the last 24 hours.</li> <li>Total reports: indicates the number of total reports in the platform and the number of newly ingested reports in the last 24 hours.</li> <li>Total observables: indicates the number of total observables in the platform and the number of newly ingested observables in the last 24 hours.</li> </ul> <p>The numbers indicating the variation only give how many new objects were added to the platform manually or using connectors. It compares the number of objects at D-1 and at D and establishes the variation number, therefore the variation will never be bellow 0.</p> <ul> <li>Top labels: indicates which are the top labels given to entities during the last 3 months. The top 9 labels are shown, with the number of entities having that label.</li> <li>Ingested entities: indicates how many entities were ingested and when over the last year.</li> <li>Top ten active entities (last 3 months): name and list of the entities with the greatest number of relations created to it in the platform over the last 3 months. The type of the entity and the exact number of relations is displayed if the mouse is moved over one bar. The entities can be any entity.</li> <li>Targeted countries: the map can be zoomed in and out, and display targeted countries in the world over the last 3 months. The intensity of the targeting, meaning the number of relations \"targets\" towards these countries, is reflect by 3 colors. Orange is for heavy targeting, pale orange of medium and yellow for low.</li> <li>Last ingested analysis: display the list of the last 8 objects belonging o the analysis section which have been created (manually or by a connector) in the platform. This included reports but also notes, opinions and external references. These can be clicked to access directly the page of the analysis.</li> <li>Observable distribution: indicates the 10 top observable types in the platform and the absolute number of entities for each type. As for the top 10 active entities, the value is displayed when the mouse is run over.</li> </ul> <p></p>"},{"location":"usage/platform/#presentation-of-a-typical-page-in-opencti","title":"Presentation of a typical page in OpenCTI","text":"<p>Although there are many different entities in OpenCTI and many different tabs, most of them are quite similar and only have minor differences from the other, mostly due to some of their characteristics, which requires specific fields or do not require some fields which are necessary for the other. </p> <p>In this part will only be detailed a general outline of a \"typical\" OpenCTI page. The specifies of the different entities will be detailed in the corresponding pages below (Activities and Knowledge).</p> <p>Entities are usually presented as such:</p> <ul> <li>an <code>Overview</code> tab, general page on the entity. Just as the welcome dashboard gives an overview of the whole platform, the <code>Overview</code> page of the entity gives an idea of the activity regading this entity. You can find general information on the entity such as the ID of the entity, the confidence level, the markings, the author and the creator, dates, description etc. as well as widgets that show the general activity on the entity, such as last relations created, latest reports mentionning the entity, most recent history and external references.</li> </ul> <p>Below are two images showing an \"overview\" tab of an intrusion set.</p> <p></p> <p><code>Overview</code> tab of an intrusion set (top part)</p> <p></p> <p><code>Overview</code> tab of an intrusion set (bottom part)</p> <ul> <li> <p>A <code>Knowledge</code> tab, which is the central part of the entity. The <code>Knowledge</code> tab is different for a <code>Report</code> entity than for all the other tabs.</p> <ul> <li><code>Knowledge</code> tabs of any entity except for reports gather all the entities which have been at some point linked to the entity the user is looking at (for instance, as shown in the following capture, the <code>Knowledge</code> tab of Intrusion set APT29) gives access to the list of all entities APT29 is attributed to, all victims the intrusion set has targeted, all its campaigns, TTPs, malwares etc. . For entities to appear in theses tabs under <code>Knowledge</code>, they need to have been linked to the entity directly or have to be computed with the inference engine (to come).</li> </ul> <p></p> <ul> <li>The <code>Knowledge</code> tab of reports is the place to integrate and link together entities. For more information on how to integrate information in OpenCTI using the knowledge tab of a report, please refer to the part Update the knowledge</li> </ul> </li> <li> <p>The <code>Analysis</code> tab contains the list of all the reports in which the entity has been identified. The list can be ordered only by dates.</p> </li> </ul> <p>Example of the list of reports in which the attack pattern \"data obfuscation\" has been identified.</p> <p></p> <ul> <li>The <code>Files</code> tab</li> </ul> <p>The file tab contains documents that are associated to the object and were either :</p> <ul> <li>Uploaded to the platform : for instance the PDF document containing the text of the report</li> <li>Generated from the platform to be downloaded : a JSON or CSV file containing information on the object and generatedby the user.</li> </ul> <p></p> <ul> <li>The <code>History</code> tab</li> </ul> <p>This tab display the history of change of the element, update of attributes, creation of relations, ...</p> <p>Because of the volumes of information the history is written in a specific index by the history connector (https://www.notion.so/luatix/History-17503579a70c467ba02ec11350c593bf) that consume the redis stream to rebuild the history for the UI.</p> <p></p> <p>Less frequent tabs are the following:</p> <ul> <li>The <code>Indicators</code> tab (for all the threats and the entities in arsenal - except the courses of action -)</li> <li>The <code>Observables</code> tab (for reports, observed data</li> <li>the <code>Entities</code> tab (for reports and observed data)</li> <li>the <code>Sightings</code> tab (for Indicators and observables)</li> </ul>"}]}